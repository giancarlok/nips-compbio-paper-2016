{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn \n",
    "import scipy\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import KFold, train_test_split, cross_val_score, StratifiedKFold, LabelKFold, ShuffleSplit\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from mhcflurry.amino_acid import common_amino_acids\n",
    "from mhcflurry import dataset\n",
    "from mhcflurry.dataset import Dataset\n",
    "import matplotlib.pyplot as plt \n",
    "% matplotlib inline\n",
    "import numpy as np\n",
    "import math \n",
    "from mhcflurry import peptide_encoding, amino_acid\n",
    "import statsmodels.api as sm\n",
    "from keras import models, layers, optimizers\n",
    "from keras.optimizers import Adam \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Input, merge, GlobalAveragePooling1D, Convolution1D, AveragePooling1D, Activation, Flatten\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Model\n",
    "from keras.engine import topology\n",
    "import seaborn as sns\n",
    "from keras.layers.core import Lambda\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = Dataset.from_csv(\"bdata.2009.mhci.public.1.txt\")\n",
    "ds_h = ds.slice(ds.alleles == 'HLA-A0201')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_table(\"bdata.2009.mhci.public.1.txt\")\n",
    "\n",
    "df['log_meas']=1-np.log(df['meas'])/math.log(50000)\n",
    "df['peptide_length'] = df['sequence'].str.len()\n",
    "\n",
    "\n",
    "max_len=df['sequence'].str.len().max()\n",
    "n_peptides = df['sequence'].count()\n",
    "\n",
    "def amino_acid_hotshot_encoding(s):\n",
    "    return common_amino_acids.hotshot_encoding([s],len(s)).flatten().astype(int)\n",
    "df['hotshot_encoded_peptides'] = df.sequence.apply(lambda seq: amino_acid_hotshot_encoding(seq))\n",
    "\n",
    "def amino_acid_index_encoding(s, maxlen):\n",
    "    a = 1+common_amino_acids.index_encoding([s],len(s)).flatten()\n",
    "    return np.concatenate([a, np.zeros(maxlen-len(a),dtype=int)])\n",
    "df['index_encoded_peptides'] = df.sequence.apply(lambda seq: amino_acid_index_encoding(seq, max_len))\n",
    "\n",
    "def new_index_encoding(x):\n",
    "    y = np.zeros(len(x))\n",
    "    for i in range(len(x)):\n",
    "        if x[i] != 0: \n",
    "            y[i] = x[i]+i*20\n",
    "    return y\n",
    "\n",
    "df['new_index_encoding'] = df.index_encoded_peptides.apply(lambda seq: new_index_encoding(seq))    \n",
    "def measured_affinity_less_than(Y,k):\n",
    "    IC50 = 50000**(1-Y)\n",
    "    return (IC50 < k).astype(int) \n",
    "\n",
    "def affinity_label(Y):\n",
    "    return measured_affinity_less_than(Y,50) + measured_affinity_less_than(Y,500) + measured_affinity_less_than(Y,5000) + measured_affinity_less_than(Y,50000)\n",
    "\n",
    "df['affinity_label'] = affinity_label(df['log_meas'])\n",
    "df_h = df[df['mhc']=='HLA-A-0201'][['hotshot_encoded_peptides','index_encoded_peptides','log_meas','peptide_length','new_index_encoding']]\n",
    "X = np.array(list(df_h['index_encoded_peptides']))\n",
    "X_new = np.array(list(df_h['new_index_encoding']))\n",
    "y = np.array(list(df_h['log_meas']))\n",
    "y[y<0]=0\n",
    "\n",
    "def first_and_last_three(Y):\n",
    "    k = np.count_nonzero(Y)\n",
    "    return np.concatenate([Y[:3],Y[-3+k:k]])\n",
    "def first_and_last_four(Y):\n",
    "    k = np.count_nonzero(Y)\n",
    "    return np.concatenate([Y[:4],Y[-4+k:k]])\n",
    "def first_and_last_two(Y):\n",
    "    k = np.count_nonzero(Y)\n",
    "    return np.concatenate([Y[:2],Y[-2+k:k]])\n",
    "def cut_the_zeros(Y):\n",
    "    k = np.count_nonzero(Y)\n",
    "    return Y[:k]\n",
    "\n",
    "X_44 = np.apply_along_axis(first_and_last_four,1,X)\n",
    "X_33 = np.apply_along_axis(first_and_last_three,1,X)\n",
    "X_22 = np.apply_along_axis(first_and_last_two,1,X)\n",
    "\n",
    "nine_mers = np.array(list(df_h[df_h['peptide_length']==9]['index_encoded_peptides']))\n",
    "nine_mers_new = np.array(list(df_h[df_h['peptide_length']==9]['new_index_encoding']))\n",
    "X_9 = np.apply_along_axis(cut_the_zeros,1,nine_mers)\n",
    "X_9_new = np.apply_along_axis(cut_the_zeros,1,nine_mers_new)\n",
    "y_9 = np.array(list(df_h[df_h['peptide_length']==9]['log_meas']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-- 2 3 4]\n",
      " [5 -- 7 8]\n",
      " [9 10 -- 12]]\n"
     ]
    }
   ],
   "source": [
    "def regroup_together(affinities, weights , original_indices):\n",
    "    affinities = affinities.ravel()\n",
    "    weights = weights.ravel()\n",
    "    \n",
    "    assert affinities.shape == weights.shape, \"%s should be %s\" % (affinities.shape, weights.shape)\n",
    "    assert affinities.shape == original_indices.shape\n",
    "    assert len(affinities) == len(affinities.ravel())\n",
    "    \n",
    "    weighted_affinities = (affinities * weights)\n",
    "    index_set = set(original_indices)\n",
    "    n_indices = len(index_set)\n",
    "    result_order = {original_index: i for (i, original_index) in enumerate(sorted(index_set))}\n",
    "    result = np.zeros(n_indices)\n",
    "    for i, x in enumerate(weighted_affinities):\n",
    "        result_idx = result_order[original_indices[i]]\n",
    "        result[result_idx] += x\n",
    "    return result\n",
    "\n",
    "def slicing(dataset, index, i):\n",
    "    return dataset.slice(index).kmer_index_encoding()[i]\n",
    "\n",
    "def label_transform(array):\n",
    "    result = 1-np.log(array)/math.log(50000)\n",
    "    result[result<0]=0\n",
    "    return result\n",
    "\n",
    "def index_to_hotshot_encoding(index_encoded_nine_mer):\n",
    "    result = np.zeros((9,21))\n",
    "    for position, amino_acid in enumerate(index_encoded_nine_mer):\n",
    "        result[position][amino_acid]= 1\n",
    "    return result.flatten()\n",
    "\n",
    "def real_labels(dataset,index):\n",
    "    \n",
    "    y = label_transform(slicing(dataset,index,1))\n",
    "    weights = slicing(dataset,index,2)\n",
    "    original_indices = slicing(dataset,index,3)\n",
    "    \n",
    "    return regroup_together(y, weights , original_indices)\n",
    "\n",
    "def fit(model,dataset,index, neural_network = False, hotshot = False): # to be left out or modified \n",
    "    \n",
    "    X = slicing(dataset,index,0)\n",
    "    \n",
    "    if (hotshot == True):\n",
    "        X = np.apply_along_axis(index_to_hotshot_encoding, 1, X)\n",
    "        \n",
    "    y = label_transform(slicing(dataset,index,1))\n",
    "    weights = slicing(dataset,index,2)\n",
    "    \n",
    "    if (neural_network == True):\n",
    "        model.fit(X, y, sample_weight = weights, batch_size = 16, nb_epoch = 1)\n",
    "    else: \n",
    "        model.fit(X, y, sample_weight = weights)\n",
    "        \n",
    "        \n",
    "def fit_new(model,dataset,index, neural_network = False):\n",
    "    X = slicing(dataset,index,0)\n",
    "    y = label_transform(slicing(dataset,index,1))\n",
    "    weights = slicing(dataset,index,2)\n",
    "    X_new = np.apply_along_axis(new_index_encoding, 1, X) \n",
    "    \n",
    "    if (neural_network == True):\n",
    "        model.fit(X_new, y, sample_weight = weights, batch_size = 16, nb_epoch = 1)\n",
    "    else: \n",
    "        model.fit(X_new, y, sample_weight = weights)\n",
    "        \n",
    "        \n",
    "def predict(model, dataset, index, hotshot = False):\n",
    "    \n",
    "    X = slicing(dataset,index,0)\n",
    "    \n",
    "    if (hotshot == True):\n",
    "        X = np.apply_along_axis(index_to_hotshot_encoding, 1, X)\n",
    "        \n",
    "    weights = slicing(dataset,index,2)\n",
    "    original_indices = slicing(dataset,index,3)\n",
    "    \n",
    "    return regroup_together(model.predict(X), weights , original_indices)\n",
    "\n",
    "def AUC(model, dataset, index, hotshot = False):\n",
    "        \n",
    "    real_affinity = measured_affinity_less_than(real_labels(dataset,index),500)\n",
    "    predicted_affinity = predict(model, dataset, index, hotshot = hotshot)\n",
    "    \n",
    "    return roc_auc_score(real_affinity, predicted_affinity)\n",
    "\n",
    "def AUC_simple(model, features, labels, index):\n",
    "    real_affinity = measured_affinity_less_than(labels[index],500)\n",
    "    predicted_affinity = model.predict(features[index])\n",
    "    \n",
    "    return roc_auc_score(real_affinity, predicted_affinity)\n",
    "\n",
    "def AUC_simple_average(model_1, model_2, features, labels, index):\n",
    "    real_affinity = measured_affinity_less_than(labels[index],500)\n",
    "    predicted_affinity_1 = model_1.predict(features[index])\n",
    "    predicted_affinity_2 = model_2.predict(features[index])\n",
    "    predicted_affinity = 0.5* predicted_affinity_1 + 0.5* predicted_affinity_2\n",
    "    \n",
    "    return roc_auc_score(real_affinity, predicted_affinity)\n",
    "def split_by_length(X,index,length=9):\n",
    "    length_idx = np.array([i for i in index if (np.count_nonzero(X[i])==length)])\n",
    "    non_length_idx = np.array([i for i in index if (np.count_nonzero(X[i])!=length)])\n",
    "    return index, length_idx, non_length_idx\n",
    "from numpy import ma \n",
    "\n",
    "array_test = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12]])\n",
    "position = [[1,0,0,0], [0,1,0,0], [0,0,1,0]]\n",
    "values = 0\n",
    "mx = ma.masked_array(array_test, mask=position, fill_value =0)\n",
    "print(mx)\n",
    "def sum_character_deletion(model,array,length): \n",
    "    result = np.zeros(len(array))\n",
    "    for i in range(length):\n",
    "        position_matrix = np.zeros((len(array),length))\n",
    "        position_matrix[:,i] = 1 \n",
    "        mx = ma.masked_array(array, mask=position_matrix)\n",
    "        result = result + model.predict(mx)\n",
    "        \n",
    "    return result / length\n",
    "        \n",
    "def random_dropout_prediction_by_lentgh(model,array,length):\n",
    "    array_of_lengths = np.apply_along_axis(np.count_nonzero,1,array)\n",
    "    #print(\"array shape\", array.shape, \"array of lengths shape\", array_of_lengths.shape)\n",
    "    bool_array = (array_of_lengths == length)\n",
    "    #print(\"bool_array shape\", bool_array.shape)\n",
    "    result = np.zeros(len(array))\n",
    "    #print(\"result shape\", result.shape)\n",
    "    for i in range(length):\n",
    "        position_matrix = np.zeros(array.shape)\n",
    "        position_matrix[:,i] = 1 \n",
    "        print(\"array shape\", array.shape, \"position_matrix shape\", position_matrix.shape)\n",
    "        mx = ma.masked_array(array, mask=position_matrix)\n",
    "        result[bool_array] = result[bool_array] + model.predict(mx)\n",
    "    \n",
    "    #print(\"result[bool_array] shape\", result[bool_array].shape, \"model prediction shape\", model.predict(array[bool_array]).shape)\n",
    "    return result/length\n",
    "\n",
    "def random_dropout_array_prediction(model,array):\n",
    "    array_of_lengths = np.apply_along_axis(np.count_nonzero,1,array)\n",
    "    result = np.zeros(len(array))\n",
    "    for length in np.unique(array_of_lengths):\n",
    "        result = result + random_dropout_prediction_by_lentgh(model,array,length)\n",
    "    return result\n",
    "\n",
    "def AUC_random_dropout(model, features, labels, index):\n",
    "    real_affinity = measured_affinity_less_than(labels[index],500)\n",
    "    predicted_affinity = random_dropout_array_prediction(model, features[index])\n",
    "    \n",
    "    return roc_auc_score(real_affinity, predicted_affinity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on 9 mers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 4s - loss: 0.0990     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 3s - loss: 0.0938     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0955     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0961     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.1471     \n",
      "test AUC : 0.833540529666 0.866757282822 0.796538359693 0.765706513702 0.776751539787 0 0\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 4s - loss: 0.0594     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0709     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0797     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0808     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0750     \n",
      "test AUC : 0.911822915055 0.929677908572 0.858503818947 0.79070333268 0.780453562229 0 1\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 5s - loss: 0.0416     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 4s - loss: 0.0586     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0728     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0775     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0501     \n",
      "test AUC : 0.939285456365 0.94992726635 0.882990814582 0.829749954434 0.784626719902 0 2\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 6s - loss: 0.0348     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 4s - loss: 0.0524     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 3s - loss: 0.0656     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0756     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0409     \n",
      "test AUC : 0.948564585074 0.955811298304 0.898621671533 0.873997977901 0.788674356144 0 3\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 6s - loss: 0.0314     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 4s - loss: 0.0471     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 3s - loss: 0.0572     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0747     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0373     \n",
      "test AUC : 0.953568247549 0.958127426604 0.908764834742 0.889149962 0.793911866762 0 4\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 6s - loss: 0.0294     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 4s - loss: 0.0446     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 3s - loss: 0.0516     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0730     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0343     \n",
      "test AUC : 0.956903162796 0.95996726126 0.91843084457 0.901472555513 0.802689769488 0 5\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 6s - loss: 0.0282     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 4s - loss: 0.0413     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 3s - loss: 0.0491     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0704     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0330     \n",
      "test AUC : 0.958698291189 0.96037047736 0.925386107357 0.907122739325 0.817731707401 0 6\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 6s - loss: 0.0281     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 3s - loss: 0.0394     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0475     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0673     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0314     \n",
      "test AUC : 0.959664634251 0.960290521928 0.932658612662 0.914433932741 0.840954031645 0 7\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 5s - loss: 0.0273     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 4s - loss: 0.0379     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0451     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0616     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0298     \n",
      "test AUC : 0.960665366746 0.961285236273 0.936524844646 0.916204128795 0.856354479396 0 8\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 6s - loss: 0.0272     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 4s - loss: 0.0361     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0433     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0602     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0291     \n",
      "test AUC : 0.961003242924 0.960085904803 0.939275139535 0.920061763421 0.862971006269 0 9\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 5s - loss: 0.0266     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 4s - loss: 0.0348     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0428     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0582     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0292     \n",
      "test AUC : 0.961218176879 0.960981749528 0.942789739569 0.922825814084 0.867303215068 0 10\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 6s - loss: 0.0267     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 4s - loss: 0.0334     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0404     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0565     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0277     \n",
      "test AUC : 0.961380666949 0.961158855107 0.94549446846 0.927016166472 0.869017528294 0 11\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 5s - loss: 0.0264     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 4s - loss: 0.0326     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 3s - loss: 0.0396     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0549     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0279     \n",
      "test AUC : 0.961274059707 0.96081668025 0.948180713031 0.929511119823 0.877079271082 0 12\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 5s - loss: 0.0262     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 4s - loss: 0.0313     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0382     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0539     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0283     \n",
      "test AUC : 0.961539718075 0.96183288799 0.948799292953 0.933944777449 0.878456567866 0 13\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 5s - loss: 0.0260     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 4s - loss: 0.0314     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0384     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0529     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0277     \n",
      "test AUC : 0.96153885834 0.96161279562 0.947418557226 0.934935193114 0.882159450044 0 14\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 5s - loss: 0.0259     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 4s - loss: 0.0311     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0373     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0516     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0272     \n",
      "test AUC : 0.961361752761 0.961985920966 0.947414258547 0.936825752183 0.88661374133 0 15\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 5s - loss: 0.0254     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 4s - loss: 0.0304     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0361     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0511     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0269     \n",
      "test AUC : 0.961103832014 0.961204421105 0.95072939987 0.938491920203 0.887905064532 0 16\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 5s - loss: 0.0254     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 4s - loss: 0.0301     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0352     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0489     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0272     \n",
      "test AUC : 0.961186366653 0.961543157019 0.951142073064 0.941373754673 0.891742065498 0 17\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 5s - loss: 0.0250     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 4s - loss: 0.0291     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0350     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0486     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0261     \n",
      "test AUC : 0.961206140577 0.960937903001 0.950040751478 0.9404383621 0.894423581522 0 18\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 5s - loss: 0.0248     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 4s - loss: 0.0292     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0333     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0487     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0268     \n",
      "test AUC : 0.960974011906 0.961578406187 0.95256837479 0.943010691675 0.895111370178 0 19\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 5s - loss: 0.0252     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 4s - loss: 0.0285     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0331     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0472     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0256     \n",
      "test AUC : 0.961424513475 0.96096283534 0.952228779141 0.944102556167 0.897474783948 0 20\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 5s - loss: 0.0248     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 3s - loss: 0.0284     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0324     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0467     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0259     \n",
      "test AUC : 0.961108130694 0.961515215605 0.952340544797 0.944302014877 0.898118726078 0 21\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 5s - loss: 0.0247     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 4s - loss: 0.0279     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0330     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0467     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0260     \n",
      "test AUC : 0.96131876597 0.961541437547 0.950864378394 0.946763438531 0.898626829948 0 22\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 5s - loss: 0.0246     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 4s - loss: 0.0283     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0323     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0458     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0264     \n",
      "test AUC : 0.960881160437 0.961457183437 0.952307874836 0.945372385973 0.901869753462 0 23\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 5s - loss: 0.0247     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 3s - loss: 0.0274     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 3s - loss: 0.0314     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0448     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0257     \n",
      "test AUC : 0.960877721494 0.961080619147 0.953094533112 0.947142582027 0.902125095001 0 24\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 6s - loss: 0.0249     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 3s - loss: 0.0272     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0320     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0453     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0260     \n",
      "test AUC : 0.961035053149 0.960649891501 0.953527839965 0.946802986378 0.906363592595 0 25\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 5s - loss: 0.0244     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 4s - loss: 0.0274     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0313     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0451     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0254     \n",
      "test AUC : 0.960961115868 0.961301571253 0.95065116391 0.94760082122 0.904654437784 0 26\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 5s - loss: 0.0242     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 4s - loss: 0.0269     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0309     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0443     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0251     \n",
      "test AUC : 0.960986907943 0.960947360095 0.951472211619 0.948019512564 0.90734799011 0 27\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 4s - loss: 0.0242     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 3s - loss: 0.0263     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0299     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0437     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0261     \n",
      "test AUC : 0.960540705052 0.960299979022 0.953634447207 0.948476892021 0.909387283476 0 28\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 5s - loss: 0.0242     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 3s - loss: 0.0262     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0301     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0439     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0256     \n",
      "test AUC : 0.960974011906 0.961246548161 0.952735593407 0.948264537273 0.911811738489 0 29\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 5s - loss: 0.0240     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 3s - loss: 0.0260     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0293     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0432     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0255     \n",
      "test AUC : 0.96083731391 0.961131343561 0.954371240805 0.949011647701 0.910988971309 0 30\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 5s - loss: 0.0240     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 3s - loss: 0.0257     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0295     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0426     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0253     \n",
      "test AUC : 0.961207860049 0.961646325317 0.954335991636 0.949648282076 0.911755855661 0 31\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 5s - loss: 0.0232     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 3s - loss: 0.0251     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0290     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0428     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0248     \n",
      "test AUC : 0.960930165379 0.961016998697 0.954446037821 0.949087304453 0.91185472528 0 32\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 5s - loss: 0.0235     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 3s - loss: 0.0251     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0291     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0417     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0250     \n",
      "test AUC : 0.961207000313 0.961066003638 0.952472944114 0.950398401579 0.914898190084 0 33\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 5s - loss: 0.0234     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 3s - loss: 0.0251     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0286     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0413     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0253     \n",
      "test AUC : 0.96059056973 0.960526949279 0.953330960462 0.950402700258 0.916364039658 0 34\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 5s - loss: 0.0237     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 3s - loss: 0.0250     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0282     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0412     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0252     \n",
      "test AUC : 0.961034193413 0.961378947477 0.952040496996 0.948697844126 0.917126195463 0 35\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 3s - loss: 0.0229     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0252     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0283     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0413     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0250     \n",
      "test AUC : 0.9608682644 0.960785729761 0.954411648389 0.949431198781 0.916712232665 0 36\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 3s - loss: 0.0235     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0239     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0277     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0402     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0248     \n",
      "test AUC : 0.961084058091 0.960979170321 0.954250018054 0.94821381286 0.91677499338 0 37\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 5s - loss: 0.0224     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 3s - loss: 0.0240     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0276     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0403     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0252     \n",
      "test AUC : 0.960923287492 0.960764236365 0.95413567319 0.950775825604 0.918967319722 0 38\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 5s - loss: 0.0225     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 3s - loss: 0.0242     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0272     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0401     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0252     \n",
      "test AUC : 0.961341119101 0.960883739644 0.954367801862 0.950676955985 0.919584610041 0 39\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 5s - loss: 0.0225     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 3s - loss: 0.0238     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0270     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0403     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0249     \n",
      "test AUC : 0.961511346793 0.961269761028 0.952966432475 0.951571081238 0.920570727027 0 40\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 4s - loss: 0.0225     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 3s - loss: 0.0237     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0268     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0389     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0248     \n",
      "test AUC : 0.961201841898 0.9611562759 0.95483721762 0.950679535192 0.918518537624 0 41\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 4s - loss: 0.0223     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 3s - loss: 0.0229     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0267     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0394     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0249     \n",
      "test AUC : 0.96094220168 0.960886318852 0.954563821629 0.950725960927 0.919997283235 0 42\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 4s - loss: 0.0218     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 3s - loss: 0.0230     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0264     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0391     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0245     \n",
      "test AUC : 0.961085777562 0.961262883141 0.952775571123 0.951158408044 0.920746113134 0 43\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 4s - loss: 0.0214     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 3s - loss: 0.0233     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0265     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0388     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0249     \n",
      "test AUC : 0.960784010289 0.960808082892 0.953914721085 0.951229766117 0.921212949685 0 44\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 4s - loss: 0.0211     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 3s - loss: 0.0227     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0263     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0387     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0242     \n",
      "test AUC : 0.960941341944 0.960446134112 0.953368788839 0.952083483787 0.921949743283 0 45\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 4s - loss: 0.0210     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 3s - loss: 0.0220     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0264     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0381     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0247     \n",
      "test AUC : 0.960252693552 0.960334368455 0.954840656563 0.951191937741 0.922592825677 0 46\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 4s - loss: 0.0213     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0224     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0260     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0386     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0242     \n",
      "test AUC : 0.960671384897 0.960533827166 0.952420500229 0.951166145667 0.92363912417 0 47\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 3s - loss: 0.0204     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0222     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0258     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0386     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0247     \n",
      "test AUC : 0.96073242614 0.959988754655 0.95330258918 0.951712937649 0.924248676867 0 48\n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 3s - loss: 0.0205     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 2s - loss: 0.0219     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 1s - loss: 0.0260     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0377     \n",
      "Epoch 1/1\n",
      "4640/4640 [==============================] - 0s - loss: 0.0247     \n",
      "test AUC : 0.960854508627 0.960636135728 0.953740194713 0.951797191759 0.924008810573 0 49\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0914     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0927     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.1073     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.1178     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.1260     \n",
      "test AUC : 0.883276894354 0.885778664778 0.805884246443 0.784664048585 0.784604819846 1 0\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0538     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0728     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0833     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0936     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0679     \n",
      "test AUC : 0.930292924741 0.939161784588 0.856879332175 0.796371595957 0.79066160218 1 1\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0391     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0628     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0779     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0817     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0500     \n",
      "test AUC : 0.944088070559 0.949551707118 0.883378613275 0.809440545934 0.794051374493 1 2\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0341     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0560     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0730     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0785     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0415     \n",
      "test AUC : 0.948830661602 0.954734650958 0.90208802764 0.834180132621 0.798113264233 1 3\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0320     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0516     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0662     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0764     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0373     \n",
      "test AUC : 0.952743191914 0.956067726775 0.912100259662 0.877049722097 0.80056052705 1 4\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0303     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0479     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0588     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0752     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0342     \n",
      "test AUC : 0.955182729243 0.95921800897 0.923865318998 0.89823386768 0.801941672568 1 5\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0290     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0451     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0538     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0740     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0329     \n",
      "test AUC : 0.957180197 0.960624906114 0.931719564798 0.906734479281 0.803864460611 1 6\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0288     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0424     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0513     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0734     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0316     \n",
      "test AUC : 0.957960471255 0.960652374514 0.937986652074 0.913610163308 0.806967531492 1 7\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0282     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0398     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0484     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0726     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0307     \n",
      "test AUC : 0.958689242258 0.961050666323 0.94062104337 0.91795532093 0.811918710702 1 8\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0280     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0383     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0474     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0710     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0304     \n",
      "test AUC : 0.958691817421 0.961613768536 0.944438292667 0.921565698835 0.821209038821 1 9\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0275     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0360     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0448     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0691     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0300     \n",
      "test AUC : 0.959169080882 0.961216335114 0.946888130647 0.92496491341 0.837696087899 1 10\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0271     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0350     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0440     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0650     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0289     \n",
      "test AUC : 0.95988926801 0.96190991223 0.947878709844 0.928978733449 0.85770424258 1 11\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0272     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0342     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0429     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0614     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0284     \n",
      "test AUC : 0.959812013133 0.961938239018 0.950722547694 0.931222558424 0.870943153287 1 12\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0268     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0333     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0415     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0603     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0288     \n",
      "test AUC : 0.959828322496 0.961743385051 0.950682203481 0.934801175991 0.879809437971 1 13\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0266     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0332     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0400     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0580     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0284     \n",
      "test AUC : 0.959551921715 0.961756260864 0.952901993605 0.937480203438 0.885828451254 1 14\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0264     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0319     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0387     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0565     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0282     \n",
      "test AUC : 0.959997424837 0.962307345651 0.953584411683 0.94051374493 0.8901444237 1 15\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0262     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0313     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0386     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0558     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0281     \n",
      "test AUC : 0.959934762549 0.962109916522 0.954115753557 0.941178995257 0.894362539969 1 16\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0259     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0307     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0374     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0547     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0276     \n",
      "test AUC : 0.960482413786 0.962097040709 0.955075430803 0.944759329599 0.898007253375 1 17\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0264     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0302     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0362     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0536     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0283     \n",
      "test AUC : 0.960021459688 0.961960557093 0.955660851091 0.946338762634 0.900830489925 1 18\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0262     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0296     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0352     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0524     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0278     \n",
      "test AUC : 0.960628339664 0.962097040709 0.956184467478 0.947822056267 0.903542136097 1 19\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0255     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0291     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0351     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0535     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0274     \n",
      "test AUC : 0.960412884397 0.962143393635 0.956108929376 0.948543960171 0.906727612181 1 20\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 6s - loss: 0.0258     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 6s - loss: 0.0294     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0342     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0520     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0273     \n",
      "test AUC : 0.960687568403 0.962612931608 0.95753986137 0.948013476684 0.909571450031 1 21\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 6s - loss: 0.0252     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0288     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0332     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0510     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0273     \n",
      "test AUC : 0.961011180497 0.96227301015 0.957383634842 0.949598060044 0.911421275135 1 22\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 6s - loss: 0.0254     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0284     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0332     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0496     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0271     \n",
      "test AUC : 0.960988862422 0.962139960085 0.957035987897 0.950544861478 0.914842807786 1 23\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 6s - loss: 0.0252     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0282     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0330     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0492     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0266     \n",
      "test AUC : 0.960890147857 0.961979441619 0.957748449538 0.950945728449 0.917175046675 1 24\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 7s - loss: 0.0253     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0274     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0324     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0476     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0272     \n",
      "test AUC : 0.960890147857 0.962104766197 0.958461769566 0.951036717526 0.919660078542 1 25\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0249     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0276     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0315     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0469     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0263     \n",
      "test AUC : 0.960828343956 0.961781154102 0.958478078929 0.95187622052 0.920311594669 1 26\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 7s - loss: 0.0250     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0274     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0322     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0466     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0268     \n",
      "test AUC : 0.960824910406 0.962424944741 0.958453185691 0.952765509989 0.921721925363 1 27\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 5s - loss: 0.0244     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0269     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0319     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0466     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0264     \n",
      "test AUC : 0.960786282967 0.962528809631 0.958706410009 0.953005858495 0.924413828623 1 28\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 7s - loss: 0.0246     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0268     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0310     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0452     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0263     \n",
      "test AUC : 0.960650657739 0.961880727054 0.958356187901 0.953637631709 0.924649885191 1 29\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 845s - loss: 0.0246   \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 5s - loss: 0.0265     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0311     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0459     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0263     \n",
      "test AUC : 0.960746797142 0.96270563746 0.958236013648 0.953959527028 0.925507414322 1 30\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 5s - loss: 0.0242     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0261     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0308     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0442     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0261     \n",
      "test AUC : 0.960967402734 0.962441254104 0.958697826134 0.953536341982 0.926394987017 1 31\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0246     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0256     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0308     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0433     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0259     \n",
      "test AUC : 0.960770831992 0.962621515483 0.958800832636 0.95415266422 0.927448228503 1 32\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0242     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0258     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0300     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0439     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0264     \n",
      "test AUC : 0.961087576987 0.96258117127 0.959011137578 0.954647953819 0.928168415631 1 33\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0237     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0259     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0298     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0440     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0255     \n",
      "test AUC : 0.961381145518 0.962039528745 0.95921114187 0.954452241464 0.928023348141 1 34\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0241     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0255     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0300     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0438     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0260     \n",
      "test AUC : 0.96080602588 0.96179574669 0.959308998047 0.955193029893 0.928702332668 1 35\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 5s - loss: 0.0238     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0252     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0295     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0427     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0260     \n",
      "test AUC : 0.96135968583 0.961741668276 0.959854074122 0.954903753299 0.928891177922 1 36\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0233     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0246     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0299     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0424     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0257     \n",
      "test AUC : 0.960813751368 0.962183737848 0.958719285822 0.955766432756 0.929720380266 1 37\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0239     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0246     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0298     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0416     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0261     \n",
      "test AUC : 0.960534775424 0.961970857744 0.958842035237 0.955985321573 0.930292066353 1 38\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0228     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0247     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0294     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0423     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0255     \n",
      "test AUC : 0.96045322861 0.962279877251 0.959515011052 0.956341552394 0.931032854782 1 39\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0231     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0241     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0289     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0410     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0260     \n",
      "test AUC : 0.960956243696 0.962002618082 0.958102105195 0.955376724822 0.932107555956 1 40\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0229     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0236     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0287     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0404     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0256     \n",
      "test AUC : 0.960731346166 0.962798343312 0.959564797528 0.956209360716 0.93218566922 1 41\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0226     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0233     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0280     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0409     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0251     \n",
      "test AUC : 0.960685851628 0.962434387004 0.959478958776 0.956672889976 0.932938475075 1 42\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0224     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0236     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0281     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0403     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0260     \n",
      "test AUC : 0.960758814567 0.961951973218 0.95957080624 0.957001652396 0.933361660121 1 43\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0224     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0229     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0283     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0411     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0254     \n",
      "test AUC : 0.960707311316 0.962327946952 0.958729586472 0.957014528209 0.93419601279 1 44\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0219     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0226     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0272     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0401     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0251     \n",
      "test AUC : 0.960836069444 0.961897894805 0.958142449409 0.957174188287 0.933513594712 1 45\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0221     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0225     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0269     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0404     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0251     \n",
      "test AUC : 0.960488422498 0.962451554754 0.95956050559 0.957108092448 0.93341402176 1 46\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0220     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0220     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0270     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0397     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0253     \n",
      "test AUC : 0.960612030301 0.961620635636 0.959685830168 0.957842013777 0.934551385223 1 47\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0216     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0219     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0273     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0389     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0248     \n",
      "test AUC : 0.960988862422 0.961621494023 0.959769093757 0.957575913646 0.934761690165 1 48\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0214     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0218     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0270     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0402     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0251     \n",
      "test AUC : 0.960607738363 0.962174295586 0.959220584133 0.957196506363 0.934692160776 1 49\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0843     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0947     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.1011     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0958     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0994     \n",
      "test AUC : 0.90277673904 0.896225385142 0.813236124686 0.775128065601 0.790147781557 2 0\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0490     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0704     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0814     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0785     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0500     \n",
      "test AUC : 0.933517641203 0.935385649604 0.868572327514 0.796148962709 0.792673418318 2 1\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0384     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0595     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0754     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0765     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0391     \n",
      "test AUC : 0.941501163529 0.940937236465 0.888562510369 0.825119855992 0.797919831235 2 2\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0347     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0535     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0676     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0755     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0341     \n",
      "test AUC : 0.946226631628 0.947835027264 0.902620283666 0.866256444113 0.802371072605 2 3\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0312     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0493     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0595     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0736     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0319     \n",
      "test AUC : 0.94929298504 0.952139269353 0.915569115021 0.890386676879 0.807969939937 2 4\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0299     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0449     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0528     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0726     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0299     \n",
      "test AUC : 0.950236875156 0.954489538551 0.922586396463 0.902104066894 0.818965658045 2 5\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0285     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0421     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0503     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0701     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0296     \n",
      "test AUC : 0.95151086892 0.95472723037 0.928842892155 0.908420307908 0.835140736767 2 6\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0284     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0396     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0476     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0670     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0288     \n",
      "test AUC : 0.952367934901 0.955327692343 0.9331462746 0.912668673078 0.855397409546 2 7\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0273     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0383     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0467     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0643     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0280     \n",
      "test AUC : 0.952165058701 0.956524318065 0.936145575708 0.916067709072 0.866451583509 2 8\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0269     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0373     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0446     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0605     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0280     \n",
      "test AUC : 0.952742740084 0.957126069506 0.93936752485 0.91973323499 0.872885166053 2 9\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0270     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0366     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0441     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0590     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0273     \n",
      "test AUC : 0.953445069979 0.956836369169 0.940828921206 0.921836786097 0.879164872158 2 10\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 6s - loss: 0.0263     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0344     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0424     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0576     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0271     \n",
      "test AUC : 0.954255715134 0.957202577903 0.944906217038 0.923770127511 0.883175975332 2 11\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0261     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0335     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0419     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0557     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0265     \n",
      "test AUC : 0.954158575259 0.95668249273 0.944676691846 0.929524590573 0.88714409626 2 12\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0263     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0323     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0401     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0554     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0266     \n",
      "test AUC : 0.954348556785 0.957535260485 0.949345423379 0.933261467018 0.889490067233 2 13\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 5s - loss: 0.0262     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0326     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0392     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0538     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0262     \n",
      "test AUC : 0.955031974493 0.957277367011 0.950311664264 0.936443872494 0.892822050924 2 14\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0258     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0310     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0377     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0525     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0260     \n",
      "test AUC : 0.954847150836 0.956854421713 0.951392237922 0.938940281327 0.895787396058 2 15\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0258     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0311     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0376     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0523     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0258     \n",
      "test AUC : 0.955013921949 0.957212033997 0.952881142915 0.941092832195 0.898206866672 2 16\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0256     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0301     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0367     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0521     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0260     \n",
      "test AUC : 0.955535726413 0.957371927951 0.952845897474 0.941994599711 0.900675766868 2 17\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0249     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0296     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0358     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0511     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0257     \n",
      "test AUC : 0.955401621806 0.957173349976 0.953405526313 0.944435991269 0.901803620996 2 18\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0254     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0284     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0352     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0499     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0259     \n",
      "test AUC : 0.955616533035 0.95723524441 0.954929676748 0.945234601396 0.905628181223 2 19\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0254     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0283     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0347     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0495     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0254     \n",
      "test AUC : 0.955773848054 0.958143889085 0.955338867727 0.945324004467 0.907699925469 2 20\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0253     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0286     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0348     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0481     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0253     \n",
      "test AUC : 0.955401621806 0.958131424234 0.954278065902 0.946922944009 0.910854822307 2 21\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0245     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0279     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0340     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0476     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0255     \n",
      "test AUC : 0.955750207819 0.958215239613 0.955595041912 0.94767169473 0.912664374853 2 22\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0246     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0275     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0332     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0466     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0252     \n",
      "test AUC : 0.955692181787 0.958064801753 0.955836602133 0.948705847563 0.914351857822 2 23\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0245     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0272     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0327     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0457     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0252     \n",
      "test AUC : 0.955678427469 0.958596062311 0.955212499925 0.948963741037 0.915781447315 2 24\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0246     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0271     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0324     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0448     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0248     \n",
      "test AUC : 0.955876145799 0.958527290717 0.956392792393 0.949526808456 0.917578105188 2 25\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0239     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0268     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0317     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0455     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0251     \n",
      "test AUC : 0.955536156235 0.958620992013 0.955156623005 0.94994545553 0.918256365026 2 26\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0235     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0267     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0313     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0438     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0252     \n",
      "test AUC : 0.955812532076 0.958386308951 0.956617159716 0.950719135954 0.919721199961 2 27\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0240     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0261     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0311     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0439     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0249     \n",
      "test AUC : 0.956199372287 0.958211801033 0.955679287114 0.950929748958 0.920996913015 2 28\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0241     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0258     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0308     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0431     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0245     \n",
      "test AUC : 0.955960391001 0.958897797676 0.955745479772 0.950516259754 0.921615857354 2 29\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 4s - loss: 0.0235     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0258     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0307     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0428     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0247     \n",
      "test AUC : 0.956029162594 0.958786043837 0.956805421952 0.95075696033 0.922449712922 2 30\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0234     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0259     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0305     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0431     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0245     \n",
      "test AUC : 0.956234617729 0.958579729057 0.956272442105 0.950113945933 0.923129692049 2 31\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0229     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0254     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0309     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0425     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0245     \n",
      "test AUC : 0.956266424591 0.958461957704 0.956078162354 0.949930841567 0.92372628562 2 32\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0229     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0259     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0290     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0415     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0245     \n",
      "test AUC : 0.956583633564 0.9579470304 0.955746339417 0.951998287587 0.924659000353 2 33\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0234     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0250     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0299     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0416     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0246     \n",
      "test AUC : 0.95597242603 0.95824446754 0.956840667394 0.950932327893 0.925461049059 2 34\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0229     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0245     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0297     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0414     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0243     \n",
      "test AUC : 0.955845628405 0.958080275361 0.956857860292 0.950722574533 0.925866801459 2 35\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0227     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0240     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0291     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0413     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0244     \n",
      "test AUC : 0.956666159476 0.957848171234 0.956243214178 0.950086437296 0.926373991959 2 36\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0221     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0245     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0285     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0403     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0242     \n",
      "test AUC : 0.956252670272 0.958431010487 0.955954373486 0.951861604046 0.92413891518 2 37\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0224     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0240     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0287     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0408     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0244     \n",
      "test AUC : 0.956446950023 0.95748540108 0.956532054869 0.95121171249 0.927041076413 2 38\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0223     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0232     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0283     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0404     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0240     \n",
      "test AUC : 0.956765018641 0.957932416436 0.955082693543 0.951850428662 0.927402986922 2 39\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0219     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0229     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0283     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0398     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0240     \n",
      "test AUC : 0.956573317825 0.958852236495 0.956289635003 0.953025563261 0.92833999988 2 40\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0215     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0236     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0287     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0394     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0247     \n",
      "test AUC : 0.956402248487 0.958455940189 0.956360985531 0.952452180102 0.929863290669 2 41\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0216     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0229     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0280     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0403     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0239     \n",
      "test AUC : 0.956637791194 0.958106924354 0.956065267681 0.95242896969 0.929789361206 2 42\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0215     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0230     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0280     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0391     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0238     \n",
      "test AUC : 0.956715159236 0.957934135726 0.955969847095 0.952727266475 0.930090236927 2 43\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0212     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0226     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0276     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0396     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0245     \n",
      "test AUC : 0.957103718738 0.958285730496 0.955960391001 0.952753055823 0.92904490871 2 44\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0211     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0227     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0278     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0383     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0241     \n",
      "test AUC : 0.956765878286 0.958179134527 0.9561211446 0.952803774873 0.929944956936 2 45\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0208     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0222     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0268     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0385     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0241     \n",
      "test AUC : 0.957108876607 0.958012363413 0.955506498486 0.952495162348 0.928560928623 2 46\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0205     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0219     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0266     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0380     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0236     \n",
      "test AUC : 0.956845825263 0.957792294315 0.955484147718 0.952410057502 0.929714572099 2 47\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0204     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0216     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0264     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0382     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0244     \n",
      "test AUC : 0.956893965379 0.957734698106 0.955342306307 0.951246098287 0.93041604235 2 48\n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 3s - loss: 0.0204     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 2s - loss: 0.0215     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 1s - loss: 0.0265     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0377     \n",
      "Epoch 1/1\n",
      "4641/4641 [==============================] - 0s - loss: 0.0239     \n",
      "test AUC : 0.957618646042 0.957848171234 0.955705076461 0.952516653471 0.930560462695 2 49\n"
     ]
    }
   ],
   "source": [
    "folds = 3\n",
    "batch_size_nn = 16\n",
    "batch_size_lstm = 16\n",
    "hidden = 50\n",
    "dropout_probability = 0.25\n",
    "\n",
    "n_epochs = 50\n",
    "epoch = 0\n",
    "\n",
    "\n",
    "\n",
    "nn_8_aucs = np.zeros((2, folds,n_epochs))\n",
    "nn_6_aucs = np.zeros((2, folds,n_epochs))\n",
    "nn_4_aucs = np.zeros((2, folds,n_epochs))\n",
    "nn_2_aucs = np.zeros((2, folds,n_epochs))\n",
    "nn_aucs = np.zeros((2, folds,n_epochs))\n",
    "\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(KFold(len(X_9),folds, shuffle=True)):\n",
    "    \n",
    "    list_index = train_idx, test_idx\n",
    "\n",
    "    # nn_8    \n",
    "    sequence = Input( shape= (9, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 9, output_dim= 32)(sequence)\n",
    "    \n",
    "    z_0 = GlobalAveragePooling1D()(embedded)\n",
    "    z_1 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 2, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    z_2 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 3, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    z_3 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 4, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    z_4 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 5, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    z_5 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 6, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    z_6 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 7, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    z_7 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 8, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    z_8 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 9, border_mode='valid', activation='sigmoid')(embedded))\n",
    "\n",
    "    z = merge([z_0,z_1,z_2,z_3,z_4,z_5,z_6,z_7,z_8], mode = 'concat', concat_axis=-1)\n",
    "    hidden_layer = Dense(10, init='glorot_uniform', activation = 'sigmoid')(z)\n",
    "    \n",
    "    \n",
    "    after_dp = Dropout(dropout_probability)(hidden_layer)\n",
    "    output = Dense(1, init='glorot_uniform', activation = 'sigmoid')(after_dp)\n",
    "    nn_8 = Model(input = sequence, output = output)\n",
    "    nn_8.compile(optimizer = 'adam', loss='mean_squared_error')\n",
    "\n",
    "    #nn_6\n",
    "    sequence = Input( shape= (9, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 9, output_dim= 32)(sequence)\n",
    "    \n",
    "    z_0 = GlobalAveragePooling1D()(embedded)\n",
    "    z_1 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 2, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    z_2 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 3, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    z_3 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 4, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    z_4 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 5, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    z_5 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 6, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    z_6 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 7, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    \n",
    "    z = merge([z_0,z_1,z_2,z_3,z_4,z_5,z_6], mode = 'concat', concat_axis=-1)\n",
    "    hidden_layer = Dense(10, init='glorot_uniform', activation = 'sigmoid')(z)\n",
    "    \n",
    "    after_dp = Dropout(dropout_probability)(hidden_layer)\n",
    "    output = Dense(1, init='glorot_uniform', activation = 'sigmoid')(after_dp)\n",
    "    nn_6 = Model(input = sequence, output = output)\n",
    "    nn_6.compile(optimizer = 'adam', loss='mean_squared_error')\n",
    "    \n",
    "    # nn_4\n",
    "    sequence = Input( shape= (9, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 9, output_dim= 32)(sequence)\n",
    "    \n",
    "    z_0 = GlobalAveragePooling1D()(embedded)\n",
    "    z_1 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 2, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    z_2 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 3, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    z_3 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 4, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    z_4 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 5, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    \n",
    "    z = merge([z_0,z_1,z_2,z_3,z_4], mode = 'concat', concat_axis=-1)\n",
    "    hidden_layer = Dense(10, init='glorot_uniform', activation = 'sigmoid')(z)\n",
    "    \n",
    "    after_dp = Dropout(dropout_probability)(hidden_layer)\n",
    "    output = Dense(1, init='glorot_uniform', activation = 'sigmoid')(after_dp)\n",
    "    nn_4 = Model(input = sequence, output = output)\n",
    "    nn_4.compile(optimizer = 'adam', loss='mean_squared_error')\n",
    "    \n",
    "    # nn_2\n",
    "    sequence = Input( shape= (9, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 9, output_dim= 32)(sequence)\n",
    "    \n",
    "    z_0 = GlobalAveragePooling1D()(embedded)\n",
    "    z_1 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 2, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    z_2 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 3, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    \n",
    "    z = merge([z_0,z_1,z_2], mode = 'concat', concat_axis=-1)\n",
    "    hidden_layer = Dense(10, init='glorot_uniform', activation = 'sigmoid')(z)\n",
    "    \n",
    "    after_dp = Dropout(dropout_probability)(hidden_layer)\n",
    "    output = Dense(1, init='glorot_uniform', activation = 'sigmoid')(after_dp)\n",
    "    nn_2 = Model(input = sequence, output = output)\n",
    "    nn_2.compile(optimizer = 'adam', loss='mean_squared_error')\n",
    "    \n",
    "    \n",
    "    #nn\n",
    "    sequence = Input( shape= (9, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 9, output_dim= 32)(sequence)\n",
    "    \n",
    "    z = Flatten()(embedded)\n",
    "    \n",
    "    hidden_layer = Dense(10, init='glorot_uniform', activation = 'sigmoid')(z)\n",
    "    \n",
    "    after_dp = Dropout(dropout_probability)(hidden_layer)\n",
    "    output = Dense(1, init='glorot_uniform', activation = 'sigmoid')(after_dp)\n",
    "    nn = Model(input = sequence, output = output)\n",
    "    nn.compile(optimizer = 'adam', loss='mean_squared_error')\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        \n",
    "        #nn\n",
    "        \n",
    "\n",
    "            \n",
    "            \n",
    "        #deep_nn\n",
    "        nn_8.fit(X_9[train_idx],y_9[train_idx], batch_size = 16, nb_epoch = 1)\n",
    "        for k, index in enumerate([train_idx,test_idx]):\n",
    "            nn_8_aucs[k][i][epoch] = AUC_simple(nn_8, X_9, y_9, index)\n",
    "            \n",
    "            \n",
    "        nn_6.fit(X_9[train_idx],y_9[train_idx], batch_size = 16, nb_epoch = 1)\n",
    "        for k, index in enumerate([train_idx,test_idx]):\n",
    "            nn_6_aucs[k][i][epoch] = AUC_simple(nn_6, X_9, y_9, index)\n",
    "            \n",
    "        nn_4.fit(X_9[train_idx],y_9[train_idx], batch_size = 16, nb_epoch = 1)\n",
    "        for k, index in enumerate([train_idx,test_idx]):\n",
    "            nn_4_aucs[k][i][epoch] = AUC_simple(nn_4, X_9, y_9, index)\n",
    "        \n",
    "        nn_2.fit(X_9[train_idx],y_9[train_idx], batch_size = 16, nb_epoch = 1)\n",
    "        for k, index in enumerate([train_idx,test_idx]):\n",
    "            nn_2_aucs[k][i][epoch] = AUC_simple(nn_2, X_9, y_9, index)\n",
    "            \n",
    "        nn.fit(X_9[train_idx],y_9[train_idx], batch_size = 16, nb_epoch = 1)\n",
    "        for k, index in enumerate([train_idx,test_idx]):\n",
    "            nn_aucs[k][i][epoch] = AUC_simple(nn, X_9, y_9, index)\n",
    " \n",
    "    \n",
    "        \n",
    "        print(\"test AUC :\",  nn_aucs[1][i][epoch], nn_8_aucs[1][i][epoch], nn_6_aucs[1][i][epoch], nn_4_aucs[1][i][epoch], nn_2_aucs[1][i][epoch] , i, epoch)  \n",
    "      \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x13880a080>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAAGJCAYAAAC+bPjgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nREKGEhMREREJGf8HzEgNS2S54g4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11763feb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot( np.arange(0,n_epochs,1), nn_aucs[1,:,:].mean(axis=0),color='r',marker='*', linestyle='-', label =\"test NN \")\n",
    "plt.plot( np.arange(0,n_epochs,1), nn_8_aucs[1,:,:].mean(axis=0),color='b',marker='*', linestyle='-', label =\"test NN_8 \")\n",
    "plt.plot( np.arange(0,n_epochs,1), nn_6_aucs[1,:,:].mean(axis=0),color='navy',marker='*', linestyle='-', label =\"test NN_6 \")\n",
    "plt.plot( np.arange(0,n_epochs,1), nn_4_aucs[1,:,:].mean(axis=0),color='green',marker='*', linestyle='-', label =\"test NN_4 \")\n",
    "plt.plot( np.arange(0,n_epochs,1), nn_2_aucs[1,:,:].mean(axis=0),color='orange',marker='*', linestyle='-', label =\"test NN_2 \")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.title (\"AUC Performance trained and tested on 9 mers\")\n",
    "plt.legend(loc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
