{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn \n",
    "import scipy\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import KFold, train_test_split, cross_val_score, StratifiedKFold, LabelKFold, ShuffleSplit\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from mhcflurry.amino_acid import common_amino_acids\n",
    "from mhcflurry import dataset\n",
    "from mhcflurry.dataset import Dataset\n",
    "import matplotlib.pyplot as plt \n",
    "% matplotlib inline\n",
    "import numpy as np\n",
    "import math \n",
    "from mhcflurry import peptide_encoding, amino_acid\n",
    "import statsmodels.api as sm\n",
    "from keras import models, layers, optimizers\n",
    "from keras.optimizers import Adam \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Input, merge, GlobalAveragePooling1D, Convolution1D, AveragePooling1D, Activation, Flatten\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Model\n",
    "from keras.engine import topology\n",
    "import seaborn as sns\n",
    "from keras.layers.core import Lambda\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = Dataset.from_csv(\"bdata.2009.mhci.public.1.txt\")\n",
    "ds_h = ds.slice(ds.alleles == 'HLA-A0201')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_table(\"bdata.2009.mhci.public.1.txt\")\n",
    "\n",
    "df['log_meas']=1-np.log(df['meas'])/math.log(50000)\n",
    "df['peptide_length'] = df['sequence'].str.len()\n",
    "\n",
    "\n",
    "max_len=df['sequence'].str.len().max()\n",
    "n_peptides = df['sequence'].count()\n",
    "\n",
    "def amino_acid_hotshot_encoding(s):\n",
    "    return common_amino_acids.hotshot_encoding([s],len(s)).flatten().astype(int)\n",
    "df['hotshot_encoded_peptides'] = df.sequence.apply(lambda seq: amino_acid_hotshot_encoding(seq))\n",
    "\n",
    "def amino_acid_index_encoding(s, maxlen):\n",
    "    a = 1+common_amino_acids.index_encoding([s],len(s)).flatten()\n",
    "    return np.concatenate([a, np.zeros(maxlen-len(a),dtype=int)])\n",
    "df['index_encoded_peptides'] = df.sequence.apply(lambda seq: amino_acid_index_encoding(seq, max_len))\n",
    "\n",
    "def new_index_encoding(x):\n",
    "    y = np.zeros(len(x))\n",
    "    for i in range(len(x)):\n",
    "        if x[i] != 0: \n",
    "            y[i] = x[i]+i*20\n",
    "    return y\n",
    "\n",
    "df['new_index_encoding'] = df.index_encoded_peptides.apply(lambda seq: new_index_encoding(seq))    \n",
    "def measured_affinity_less_than(Y,k):\n",
    "    IC50 = 50000**(1-Y)\n",
    "    return (IC50 < k).astype(int) \n",
    "\n",
    "def affinity_label(Y):\n",
    "    return measured_affinity_less_than(Y,50) + measured_affinity_less_than(Y,500) + measured_affinity_less_than(Y,5000) + measured_affinity_less_than(Y,50000)\n",
    "\n",
    "df['affinity_label'] = affinity_label(df['log_meas'])\n",
    "df_h = df[df['mhc']=='HLA-A-0201'][['hotshot_encoded_peptides','index_encoded_peptides','log_meas','peptide_length','new_index_encoding']]\n",
    "X = np.array(list(df_h['index_encoded_peptides']))\n",
    "X_new = np.array(list(df_h['new_index_encoding']))\n",
    "y = np.array(list(df_h['log_meas']))\n",
    "y[y<0]=0\n",
    "\n",
    "def first_and_last_three(Y):\n",
    "    k = np.count_nonzero(Y)\n",
    "    return np.concatenate([Y[:3],Y[-3+k:k]])\n",
    "def first_and_last_four(Y):\n",
    "    k = np.count_nonzero(Y)\n",
    "    return np.concatenate([Y[:4],Y[-4+k:k]])\n",
    "def first_and_last_two(Y):\n",
    "    k = np.count_nonzero(Y)\n",
    "    return np.concatenate([Y[:2],Y[-2+k:k]])\n",
    "def cut_the_zeros(Y):\n",
    "    k = np.count_nonzero(Y)\n",
    "    return Y[:k]\n",
    "\n",
    "X_44 = np.apply_along_axis(first_and_last_four,1,X)\n",
    "X_33 = np.apply_along_axis(first_and_last_three,1,X)\n",
    "X_22 = np.apply_along_axis(first_and_last_two,1,X)\n",
    "\n",
    "nine_mers = np.array(list(df_h[df_h['peptide_length']==9]['index_encoded_peptides']))\n",
    "nine_mers_new = np.array(list(df_h[df_h['peptide_length']==9]['new_index_encoding']))\n",
    "X_9 = np.apply_along_axis(cut_the_zeros,1,nine_mers)\n",
    "X_9_new = np.apply_along_axis(cut_the_zeros,1,nine_mers_new)\n",
    "y_9 = np.array(list(df_h[df_h['peptide_length']==9]['log_meas']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-- 2 3 4]\n",
      " [5 -- 7 8]\n",
      " [9 10 -- 12]]\n"
     ]
    }
   ],
   "source": [
    "def regroup_together(affinities, weights , original_indices):\n",
    "    affinities = affinities.ravel()\n",
    "    weights = weights.ravel()\n",
    "    \n",
    "    assert affinities.shape == weights.shape, \"%s should be %s\" % (affinities.shape, weights.shape)\n",
    "    assert affinities.shape == original_indices.shape\n",
    "    assert len(affinities) == len(affinities.ravel())\n",
    "    \n",
    "    weighted_affinities = (affinities * weights)\n",
    "    index_set = set(original_indices)\n",
    "    n_indices = len(index_set)\n",
    "    result_order = {original_index: i for (i, original_index) in enumerate(sorted(index_set))}\n",
    "    result = np.zeros(n_indices)\n",
    "    for i, x in enumerate(weighted_affinities):\n",
    "        result_idx = result_order[original_indices[i]]\n",
    "        result[result_idx] += x\n",
    "    return result\n",
    "\n",
    "def slicing(dataset, index, i):\n",
    "    return dataset.slice(index).kmer_index_encoding()[i]\n",
    "\n",
    "def label_transform(array):\n",
    "    result = 1-np.log(array)/math.log(50000)\n",
    "    result[result<0]=0\n",
    "    return result\n",
    "\n",
    "def index_to_hotshot_encoding(index_encoded_nine_mer):\n",
    "    result = np.zeros((9,21))\n",
    "    for position, amino_acid in enumerate(index_encoded_nine_mer):\n",
    "        result[position][amino_acid]= 1\n",
    "    return result.flatten()\n",
    "\n",
    "def real_labels(dataset,index):\n",
    "    \n",
    "    y = label_transform(slicing(dataset,index,1))\n",
    "    weights = slicing(dataset,index,2)\n",
    "    original_indices = slicing(dataset,index,3)\n",
    "    \n",
    "    return regroup_together(y, weights , original_indices)\n",
    "\n",
    "def fit(model,dataset,index, neural_network = False, hotshot = False): # to be left out or modified \n",
    "    \n",
    "    X = slicing(dataset,index,0)\n",
    "    \n",
    "    if (hotshot == True):\n",
    "        X = np.apply_along_axis(index_to_hotshot_encoding, 1, X)\n",
    "        \n",
    "    y = label_transform(slicing(dataset,index,1))\n",
    "    weights = slicing(dataset,index,2)\n",
    "    \n",
    "    if (neural_network == True):\n",
    "        model.fit(X, y, sample_weight = weights, batch_size = 16, nb_epoch = 1)\n",
    "    else: \n",
    "        model.fit(X, y, sample_weight = weights)\n",
    "        \n",
    "        \n",
    "def fit_new(model,dataset,index, neural_network = False):\n",
    "    X = slicing(dataset,index,0)\n",
    "    y = label_transform(slicing(dataset,index,1))\n",
    "    weights = slicing(dataset,index,2)\n",
    "    X_new = np.apply_along_axis(new_index_encoding, 1, X) \n",
    "    \n",
    "    if (neural_network == True):\n",
    "        model.fit(X_new, y, sample_weight = weights, batch_size = 16, nb_epoch = 1)\n",
    "    else: \n",
    "        model.fit(X_new, y, sample_weight = weights)\n",
    "        \n",
    "        \n",
    "def predict(model, dataset, index, hotshot = False):\n",
    "    \n",
    "    X = slicing(dataset,index,0)\n",
    "    \n",
    "    if (hotshot == True):\n",
    "        X = np.apply_along_axis(index_to_hotshot_encoding, 1, X)\n",
    "        \n",
    "    weights = slicing(dataset,index,2)\n",
    "    original_indices = slicing(dataset,index,3)\n",
    "    \n",
    "    return regroup_together(model.predict(X), weights , original_indices)\n",
    "\n",
    "def AUC(model, dataset, index, hotshot = False):\n",
    "        \n",
    "    real_affinity = measured_affinity_less_than(real_labels(dataset,index),500)\n",
    "    predicted_affinity = predict(model, dataset, index, hotshot = hotshot)\n",
    "    \n",
    "    return roc_auc_score(real_affinity, predicted_affinity)\n",
    "\n",
    "def AUC_simple(model, features, labels, index):\n",
    "    real_affinity = measured_affinity_less_than(labels[index],500)\n",
    "    predicted_affinity = model.predict(features[index])\n",
    "    \n",
    "    return roc_auc_score(real_affinity, predicted_affinity)\n",
    "\n",
    "def AUC_simple_average(model_1, model_2, features, labels, index):\n",
    "    real_affinity = measured_affinity_less_than(labels[index],500)\n",
    "    predicted_affinity_1 = model_1.predict(features[index])\n",
    "    predicted_affinity_2 = model_2.predict(features[index])\n",
    "    predicted_affinity = 0.5* predicted_affinity_1 + 0.5* predicted_affinity_2\n",
    "    \n",
    "    return roc_auc_score(real_affinity, predicted_affinity)\n",
    "def split_by_length(X,index,length=9):\n",
    "    length_idx = np.array([i for i in index if (np.count_nonzero(X[i])==length)])\n",
    "    non_length_idx = np.array([i for i in index if (np.count_nonzero(X[i])!=length)])\n",
    "    return index, length_idx, non_length_idx\n",
    "from numpy import ma \n",
    "\n",
    "array_test = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12]])\n",
    "position = [[1,0,0,0], [0,1,0,0], [0,0,1,0]]\n",
    "values = 0\n",
    "mx = ma.masked_array(array_test, mask=position, fill_value =0)\n",
    "print(mx)\n",
    "def sum_character_deletion(model,array,length): \n",
    "    result = np.zeros(len(array))\n",
    "    for i in range(length):\n",
    "        position_matrix = np.zeros((len(array),length))\n",
    "        position_matrix[:,i] = 1 \n",
    "        mx = ma.masked_array(array, mask=position_matrix)\n",
    "        result = result + model.predict(mx)\n",
    "        \n",
    "    return result / length\n",
    "        \n",
    "def random_dropout_prediction_by_lentgh(model,array,length):\n",
    "    array_of_lengths = np.apply_along_axis(np.count_nonzero,1,array)\n",
    "    #print(\"array shape\", array.shape, \"array of lengths shape\", array_of_lengths.shape)\n",
    "    bool_array = (array_of_lengths == length)\n",
    "    #print(\"bool_array shape\", bool_array.shape)\n",
    "    result = np.zeros(len(array))\n",
    "    #print(\"result shape\", result.shape)\n",
    "    for i in range(length):\n",
    "        position_matrix = np.zeros(array.shape)\n",
    "        position_matrix[:,i] = 1 \n",
    "        print(\"array shape\", array.shape, \"position_matrix shape\", position_matrix.shape)\n",
    "        mx = ma.masked_array(array, mask=position_matrix)\n",
    "        result[bool_array] = result[bool_array] + model.predict(mx)\n",
    "    \n",
    "    #print(\"result[bool_array] shape\", result[bool_array].shape, \"model prediction shape\", model.predict(array[bool_array]).shape)\n",
    "    return result/length\n",
    "\n",
    "def random_dropout_array_prediction(model,array):\n",
    "    array_of_lengths = np.apply_along_axis(np.count_nonzero,1,array)\n",
    "    result = np.zeros(len(array))\n",
    "    for length in np.unique(array_of_lengths):\n",
    "        result = result + random_dropout_prediction_by_lentgh(model,array,length)\n",
    "    return result\n",
    "\n",
    "def AUC_random_dropout(model, features, labels, index):\n",
    "    real_affinity = measured_affinity_less_than(labels[index],500)\n",
    "    predicted_affinity = random_dropout_array_prediction(model, features[index])\n",
    "    \n",
    "    return roc_auc_score(real_affinity, predicted_affinity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â Training on 9 mers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "folds = 3\n",
    "batch_size_nn = 16\n",
    "batch_size_lstm = 16\n",
    "hidden = 50\n",
    "dropout_probability = 0.25\n",
    "\n",
    "n_epochs = 50\n",
    "epoch = 0\n",
    "\n",
    "\n",
    "\n",
    "nn_8_aucs = np.zeros((2, folds,n_epochs))\n",
    "nn_6_aucs = np.zeros((2, folds,n_epochs))\n",
    "nn_4_aucs = np.zeros((2, folds,n_epochs))\n",
    "nn_2_aucs = np.zeros((2, folds,n_epochs))\n",
    "nn_aucs = np.zeros((2, folds,n_epochs))\n",
    "\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(KFold(len(X_9),folds, shuffle=True)):\n",
    "    \n",
    "    list_index = train_idx, test_idx\n",
    "\n",
    "    # nn_8    \n",
    "    sequence = Input( shape= (9, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 9, output_dim= 32)(sequence)\n",
    "    \n",
    "    z_0 = GlobalAveragePooling1D()(embedded)\n",
    "    z_1 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 2, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    z_2 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 3, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    z_3 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 4, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    z_4 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 5, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    z_5 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 6, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    z_6 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 7, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    z_7 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 8, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    z_8 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 9, border_mode='valid', activation='sigmoid')(embedded))\n",
    "\n",
    "    z = merge([z_0,z_1,z_2,z_3,z_4,z_5,z_6,z_7,z_8], mode = 'concat', concat_axis=-1)\n",
    "    hidden_layer = Dense(10, init='glorot_uniform', activation = 'sigmoid')(z)\n",
    "    \n",
    "    \n",
    "    after_dp = Dropout(dropout_probability)(hidden_layer)\n",
    "    output = Dense(1, init='glorot_uniform', activation = 'sigmoid')(after_dp)\n",
    "    nn_8 = Model(input = sequence, output = output)\n",
    "    nn_8.compile(optimizer = 'adam', loss='mean_squared_error')\n",
    "\n",
    "    #nn_6\n",
    "    sequence = Input( shape= (9, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 9, output_dim= 32)(sequence)\n",
    "    \n",
    "    z_0 = GlobalAveragePooling1D()(embedded)\n",
    "    z_1 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 2, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    z_2 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 3, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    z_3 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 4, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    z_4 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 5, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    z_5 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 6, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    z_6 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 7, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    \n",
    "    z = merge([z_0,z_1,z_2,z_3,z_4,z_5,z_6], mode = 'concat', concat_axis=-1)\n",
    "    hidden_layer = Dense(10, init='glorot_uniform', activation = 'sigmoid')(z)\n",
    "    \n",
    "    after_dp = Dropout(dropout_probability)(hidden_layer)\n",
    "    output = Dense(1, init='glorot_uniform', activation = 'sigmoid')(after_dp)\n",
    "    nn_6 = Model(input = sequence, output = output)\n",
    "    nn_6.compile(optimizer = 'adam', loss='mean_squared_error')\n",
    "    \n",
    "    # nn_4\n",
    "    sequence = Input( shape= (9, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 9, output_dim= 32)(sequence)\n",
    "    \n",
    "    z_0 = GlobalAveragePooling1D()(embedded)\n",
    "    z_1 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 2, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    z_2 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 3, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    z_3 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 4, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    z_4 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 5, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    \n",
    "    z = merge([z_0,z_1,z_2,z_3,z_4], mode = 'concat', concat_axis=-1)\n",
    "    hidden_layer = Dense(10, init='glorot_uniform', activation = 'sigmoid')(z)\n",
    "    \n",
    "    after_dp = Dropout(dropout_probability)(hidden_layer)\n",
    "    output = Dense(1, init='glorot_uniform', activation = 'sigmoid')(after_dp)\n",
    "    nn_4 = Model(input = sequence, output = output)\n",
    "    nn_4.compile(optimizer = 'adam', loss='mean_squared_error')\n",
    "    \n",
    "    # nn_2\n",
    "    sequence = Input( shape= (9, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 9, output_dim= 32)(sequence)\n",
    "    \n",
    "    z_0 = GlobalAveragePooling1D()(embedded)\n",
    "    z_1 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 2, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    z_2 = GlobalAveragePooling1D()(Convolution1D(nb_filter = 32, input_shape = (9, 32), filter_length = 3, border_mode='valid', activation='sigmoid')(embedded))\n",
    "    \n",
    "    z = merge([z_0,z_1,z_2], mode = 'concat', concat_axis=-1)\n",
    "    hidden_layer = Dense(10, init='glorot_uniform', activation = 'sigmoid')(z)\n",
    "    \n",
    "    after_dp = Dropout(dropout_probability)(hidden_layer)\n",
    "    output = Dense(1, init='glorot_uniform', activation = 'sigmoid')(after_dp)\n",
    "    nn_2 = Model(input = sequence, output = output)\n",
    "    nn_2.compile(optimizer = 'adam', loss='mean_squared_error')\n",
    "    \n",
    "    \n",
    "    #nn\n",
    "    sequence = Input( shape= (9, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 9, output_dim= 32)(sequence)\n",
    "    \n",
    "    z = Flatten()(embedded)\n",
    "    \n",
    "    hidden_layer = Dense(10, init='glorot_uniform', activation = 'sigmoid')(z)\n",
    "    \n",
    "    after_dp = Dropout(dropout_probability)(hidden_layer)\n",
    "    output = Dense(1, init='glorot_uniform', activation = 'sigmoid')(after_dp)\n",
    "    nn = Model(input = sequence, output = output)\n",
    "    nn.compile(optimizer = 'adam', loss='mean_squared_error')\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        \n",
    "        #nn\n",
    "        \n",
    "\n",
    "            \n",
    "            \n",
    "        #deep_nn\n",
    "        nn_8.fit(X_9[train_idx],y_9[train_idx], batch_size = 16, nb_epoch = 1)\n",
    "        for k, index in enumerate([train_idx,test_idx]):\n",
    "            nn_8_aucs[k][i][epoch] = AUC_simple(nn_8, X_9, y_9, index)\n",
    "            \n",
    "            \n",
    "        nn_6.fit(X_9[train_idx],y_9[train_idx], batch_size = 16, nb_epoch = 1)\n",
    "        for k, index in enumerate([train_idx,test_idx]):\n",
    "            nn_6_aucs[k][i][epoch] = AUC_simple(nn_6, X_9, y_9, index)\n",
    "            \n",
    "        nn_4.fit(X_9[train_idx],y_9[train_idx], batch_size = 16, nb_epoch = 1)\n",
    "        for k, index in enumerate([train_idx,test_idx]):\n",
    "            nn_4_aucs[k][i][epoch] = AUC_simple(nn_4, X_9, y_9, index)\n",
    "        \n",
    "        nn_2.fit(X_9[train_idx],y_9[train_idx], batch_size = 16, nb_epoch = 1)\n",
    "        for k, index in enumerate([train_idx,test_idx]):\n",
    "            nn_2_aucs[k][i][epoch] = AUC_simple(nn_2, X_9, y_9, index)\n",
    "            \n",
    "        nn.fit(X_9[train_idx],y_9[train_idx], batch_size = 16, nb_epoch = 1)\n",
    "        for k, index in enumerate([train_idx,test_idx]):\n",
    "            nn_aucs[k][i][epoch] = AUC_simple(nn, X_9, y_9, index)\n",
    " \n",
    "    \n",
    "        \n",
    "        print(\"test AUC :\",  nn_aucs[1][i][epoch], nn_8_aucs[1][i][epoch], nn_6_aucs[1][i][epoch], nn_4_aucs[1][i][epoch], nn_2_aucs[1][i][epoch] , i, epoch)  \n",
    "      \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot( np.arange(0,n_epochs,1), nn_aucs[1,:,:].mean(axis=0),color='r',marker='*', linestyle='-', label =\"test NN \")\n",
    "plt.plot( np.arange(0,n_epochs,1), nn_8_aucs[1,:,:].mean(axis=0),color='b',marker='*', linestyle='-', label =\"test NN_8 \")\n",
    "plt.plot( np.arange(0,n_epochs,1), nn_6_aucs[1,:,:].mean(axis=0),color='navy',marker='*', linestyle='-', label =\"test NN_6 \")\n",
    "plt.plot( np.arange(0,n_epochs,1), nn_4_aucs[1,:,:].mean(axis=0),color='green',marker='*', linestyle='-', label =\"test NN_4 \")\n",
    "plt.plot( np.arange(0,n_epochs,1), nn_2_aucs[1,:,:].mean(axis=0),color='orange',marker='*', linestyle='-', label =\"test NN_2 \")\n",
    "plt.legend(loc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
