{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn \n",
    "import scipy\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import KFold, train_test_split, cross_val_score, StratifiedKFold, LabelKFold, ShuffleSplit\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from mhcflurry.amino_acid import common_amino_acids\n",
    "from mhcflurry import dataset\n",
    "from mhcflurry.dataset import Dataset\n",
    "import matplotlib.pyplot as plt \n",
    "% matplotlib inline\n",
    "import numpy as np\n",
    "import math \n",
    "from mhcflurry import peptide_encoding, amino_acid\n",
    "import statsmodels.api as sm\n",
    "from keras import models, layers, optimizers\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.models import Sequential\n",
    "from keras.utils.layer_utils import layer_from_config\n",
    "from keras.layers import Dense, Dropout, TimeDistributed, Embedding, LSTM, Input, merge, Convolution1D, AveragePooling1D, Activation, Flatten\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Model\n",
    "from keras.engine import topology\n",
    "import seaborn as sns\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_table(\"bdata.2009.mhci.public.1.txt\")\n",
    "\n",
    "df['log_meas']=1-np.log(df['meas'])/math.log(50000)\n",
    "df['peptide_length'] = df['sequence'].str.len()\n",
    "\n",
    "\n",
    "max_len=df['sequence'].str.len().max()\n",
    "n_peptides = df['sequence'].count()\n",
    "\n",
    "def amino_acid_hotshot_encoding(s):\n",
    "    return common_amino_acids.hotshot_encoding([s],len(s)).flatten().astype(int)\n",
    "df['hotshot_encoded_peptides'] = df.sequence.apply(lambda seq: amino_acid_hotshot_encoding(seq))\n",
    "\n",
    "def amino_acid_index_encoding(s, maxlen):\n",
    "    a = 1+common_amino_acids.index_encoding([s],len(s)).flatten()\n",
    "    return np.concatenate([a, np.zeros(maxlen-len(a),dtype=int)])\n",
    "df['index_encoded_peptides'] = df.sequence.apply(lambda seq: amino_acid_index_encoding(seq, max_len))\n",
    "\n",
    "def measured_affinity_less_than(Y,k):\n",
    "    IC50 = 50000**(1-Y)\n",
    "    return (IC50 < k).astype(int) \n",
    "\n",
    "def affinity_label(Y):\n",
    "    return measured_affinity_less_than(Y,50) + measured_affinity_less_than(Y,500) + measured_affinity_less_than(Y,5000) + measured_affinity_less_than(Y,50000)\n",
    "\n",
    "df['affinity_label'] = affinity_label(df['log_meas'])\n",
    "df_h = df[df['mhc']=='HLA-A-0201'][['hotshot_encoded_peptides','index_encoded_peptides','log_meas','peptide_length']]\n",
    "X = np.array(list(df_h['index_encoded_peptides']))\n",
    "y = np.array(list(df_h['log_meas']))\n",
    "y[y<0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folds = 3\n",
    "batch_size_nn = 16\n",
    "batch_size_lstm = 16\n",
    "hidden = 50\n",
    "dropout_probability = 0.25\n",
    "\n",
    "n_epochs = 50\n",
    "epoch = 0\n",
    "\n",
    "train_lstm_lr_1_0_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_1_0_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_1_1_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_1_1_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_1_2_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_1_2_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_1_3_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_1_3_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_1_4_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_1_4_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "#-----------------------\n",
    "\n",
    "train_lstm_lr_10_0_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_10_0_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_10_1_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_10_1_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_10_2_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_10_2_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_10_3_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_10_3_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_10_4_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_10_4_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "#---------------------------\n",
    "\n",
    "train_lstm_lr_100_0_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_100_0_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_100_1_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_100_1_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_100_2_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_100_2_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_100_3_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_100_3_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_100_4_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_100_4_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "#-----------------------------------------\n",
    "\n",
    "train_lstm_lr_1000_0_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_1000_0_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_1000_1_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_1000_1_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_1000_2_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_1000_2_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_1000_3_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_1000_3_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_1000_4_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_1000_4_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(KFold(len(df_h),folds, shuffle=True)):\n",
    " \n",
    "    \n",
    "    \n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_1_0 = Model(input = sequence, output = output)\n",
    "    adam_lr_1_0 = Adam(lr = 0.05)\n",
    "    lstm_lr_1_0.compile(optimizer = adam_lr_1_0 , loss='mean_squared_error')\n",
    "    \n",
    "    \n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_1_1 = Model(input = sequence, output = output)\n",
    "    adam_lr_1_1 = Adam(lr = 0.05)\n",
    "    lstm_lr_1_1.compile(optimizer = adam_lr_1_1 , loss='mean_squared_error')\n",
    "    \n",
    "    \n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_1_2 = Model(input = sequence, output = output)\n",
    "    adam_lr_1_2 = Adam(lr = 0.05)\n",
    "    lstm_lr_1_2.compile(optimizer = adam_lr_1_2 , loss='mean_squared_error')\n",
    "    \n",
    "    \n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_1_3 = Model(input = sequence, output = output)\n",
    "    adam_lr_1_3 = Adam(lr = 0.05)\n",
    "    lstm_lr_1_3.compile(optimizer = adam_lr_1_3 , loss='mean_squared_error')\n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_1_4 = Model(input = sequence, output = output)\n",
    "    adam_lr_1_4 = Adam(lr = 0.05)\n",
    "    lstm_lr_1_4.compile(optimizer = adam_lr_1_4 , loss='mean_squared_error')\n",
    "    \n",
    "    \n",
    "    #-------------------------------------------------------------------------\n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_10_0 = Model(input = sequence, output = output)\n",
    "    adam_lr_10_0 = Adam(lr = 0.01)\n",
    "    lstm_lr_10_0.compile(optimizer = adam_lr_10_0 , loss='mean_squared_error')\n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_10_1 = Model(input = sequence, output = output)\n",
    "    adam_lr_10_1 = Adam(lr = 0.01)\n",
    "    lstm_lr_10_1.compile(optimizer = adam_lr_10_1 , loss='mean_squared_error')\n",
    "    \n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_10_2 = Model(input = sequence, output = output)\n",
    "    adam_lr_10_2 = Adam(lr = 0.01)\n",
    "    lstm_lr_10_2.compile(optimizer = adam_lr_10_2 , loss='mean_squared_error')\n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_10_3 = Model(input = sequence, output = output)\n",
    "    adam_lr_10_3 = Adam(lr = 0.01)\n",
    "    lstm_lr_10_3.compile(optimizer = adam_lr_10_3 , loss='mean_squared_error')\n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_10_4 = Model(input = sequence, output = output)\n",
    "    adam_lr_10_4 = Adam(lr = 0.01)\n",
    "    lstm_lr_10_4.compile(optimizer = adam_lr_10_4 , loss='mean_squared_error')\n",
    "    \n",
    "    \n",
    "    #---------------------------------------------------------------------------------\n",
    "\n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_100_0 = Model(input = sequence, output = output)\n",
    "    adam_lr_100_0 = Adam(lr = 0.005)\n",
    "    lstm_lr_100_0.compile(optimizer = adam_lr_100_0 , loss='mean_squared_error')\n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_100_1 = Model(input = sequence, output = output)\n",
    "    adam_lr_100_1 = Adam(lr = 0.005)\n",
    "    lstm_lr_100_1.compile(optimizer = adam_lr_100_1 , loss='mean_squared_error')\n",
    "    \n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_100_2 = Model(input = sequence, output = output)\n",
    "    adam_lr_100_2 = Adam(lr = 0.005)\n",
    "    lstm_lr_100_2.compile(optimizer = adam_lr_100_2 , loss='mean_squared_error')\n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_100_3 = Model(input = sequence, output = output)\n",
    "    adam_lr_100_3 = Adam(lr = 0.005)\n",
    "    lstm_lr_100_3.compile(optimizer = adam_lr_100_3 , loss='mean_squared_error')\n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_100_4 = Model(input = sequence, output = output)\n",
    "    adam_lr_100_4 = Adam(lr = 0.005)\n",
    "    lstm_lr_100_4.compile(optimizer = adam_lr_100_4 , loss='mean_squared_error')\n",
    "    \n",
    "    \n",
    "    #------------------------------------------------------------------------------\n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_1000_0 = Model(input = sequence, output = output)\n",
    "    adam_lr_1000_0 = Adam(lr = 0.001)\n",
    "    lstm_lr_1000_0.compile(optimizer = adam_lr_1000_0 , loss='mean_squared_error')\n",
    "    \n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_1000_1 = Model(input = sequence, output = output)\n",
    "    adam_lr_1000_1 = Adam(lr = 0.001)\n",
    "    lstm_lr_1000_1.compile(optimizer = adam_lr_1000_1 , loss='mean_squared_error')\n",
    "    \n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_1000_2 = Model(input = sequence, output = output)\n",
    "    adam_lr_1000_2 = Adam(lr = 0.001)\n",
    "    lstm_lr_1000_2.compile(optimizer = adam_lr_1000_2 , loss='mean_squared_error')\n",
    "    \n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_1000_3 = Model(input = sequence, output = output)\n",
    "    adam_lr_1000_3 = Adam(lr = 0.001)\n",
    "    lstm_lr_1000_3.compile(optimizer = adam_lr_1000_3 , loss='mean_squared_error')\n",
    "    \n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_1000_4 = Model(input = sequence, output = output)\n",
    "    adam_lr_1000_4 = Adam(lr = 0.001)\n",
    "    lstm_lr_1000_4.compile(optimizer = adam_lr_1000_4 , loss='mean_squared_error')\n",
    "\n",
    "    \n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        \n",
    "\n",
    "        adam_lr_1_0.lr.set_value(0.05)\n",
    "        lstm_lr_1_0.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_1_0_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_1_0.predict(X[train_idx]))\n",
    "        test_lstm_lr_1_0_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_1_0.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_1_0_aucs[i][epoch]=train_lstm_lr_1_0_auc\n",
    "        test_lstm_lr_1_0_aucs[i][epoch]=test_lstm_lr_1_0_auc\n",
    "        print(\"LSTM LR = 0.1*t^0 \", train_lstm_lr_1_0_auc, test_lstm_lr_1_0_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_1_0.lr.get_value() )\n",
    "        \n",
    "        \n",
    "        adam_lr_1_1.lr.set_value(0.05*(epoch+1)**(-1))\n",
    "        lstm_lr_1_1.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_1_1_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_1_1.predict(X[train_idx]))\n",
    "        test_lstm_lr_1_1_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_1_1.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_1_1_aucs[i][epoch]=train_lstm_lr_1_1_auc\n",
    "        test_lstm_lr_1_1_aucs[i][epoch]=test_lstm_lr_1_1_auc\n",
    "        print(\"LSTM LR = 0.05*t^(-1) \", train_lstm_lr_1_1_auc, test_lstm_lr_1_1_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_1_1.lr.get_value() )\n",
    "        \n",
    "        \n",
    "        \n",
    "        adam_lr_1_2.lr.set_value(0.05*(epoch+1)**(-2))\n",
    "        lstm_lr_1_2.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_1_2_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_1_2.predict(X[train_idx]))\n",
    "        test_lstm_lr_1_2_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_1_2.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_1_2_aucs[i][epoch]=train_lstm_lr_1_2_auc\n",
    "        test_lstm_lr_1_2_aucs[i][epoch]=test_lstm_lr_1_2_auc\n",
    "        print(\"LSTM LR = 0.05*t^(-2) \", train_lstm_lr_1_2_auc, test_lstm_lr_1_2_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_1_2.lr.get_value() )\n",
    "        \n",
    "        \n",
    "        adam_lr_1_3.lr.set_value(0.05*(epoch+1)**(-3))\n",
    "        lstm_lr_1_3.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_1_3_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_1_3.predict(X[train_idx]))\n",
    "        test_lstm_lr_1_3_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_1_3.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_1_3_aucs[i][epoch]=train_lstm_lr_1_3_auc\n",
    "        test_lstm_lr_1_3_aucs[i][epoch]=test_lstm_lr_1_3_auc\n",
    "        print(\"LSTM LR = 0.05*t^(-3) \", train_lstm_lr_1_3_auc, test_lstm_lr_1_3_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_1_3.lr.get_value() )\n",
    "        \n",
    "        \n",
    "        \n",
    "        adam_lr_1_4.lr.set_value(0.05*(epoch+1)**(-4))\n",
    "        lstm_lr_1_4.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_1_4_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_1_4.predict(X[train_idx]))\n",
    "        test_lstm_lr_1_4_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_1_4.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_1_4_aucs[i][epoch]=train_lstm_lr_1_4_auc\n",
    "        test_lstm_lr_1_4_aucs[i][epoch]=test_lstm_lr_1_4_auc\n",
    "        print(\"LSTM LR = 0.05*t^(-4) \", train_lstm_lr_1_4_auc, test_lstm_lr_1_4_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_1_4.lr.get_value() )\n",
    "        \n",
    "\n",
    "    \n",
    "        #----------------------------------------\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "        adam_lr_10_0.lr.set_value(0.01)\n",
    "        lstm_lr_10_0.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_10_0_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_10_0.predict(X[train_idx]))\n",
    "        test_lstm_lr_10_0_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_10_0.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_10_0_aucs[i][epoch]=train_lstm_lr_10_0_auc\n",
    "        test_lstm_lr_10_0_aucs[i][epoch]=test_lstm_lr_10_0_auc\n",
    "        print(\"LSTM LR = 0.01): \", train_lstm_lr_10_0_auc, test_lstm_lr_10_0_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_10_0.lr.get_value() )   \n",
    "        \n",
    "        \n",
    "        \n",
    "        adam_lr_10_1.lr.set_value(0.01*(epoch+1)**(-1))\n",
    "        lstm_lr_10_1.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_10_1_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_10_1.predict(X[train_idx]))\n",
    "        test_lstm_lr_10_1_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_10_1.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_10_1_aucs[i][epoch]=train_lstm_lr_10_1_auc\n",
    "        test_lstm_lr_10_1_aucs[i][epoch]=test_lstm_lr_10_1_auc\n",
    "        print(\"LSTM LR = 0.01*t^(-1): \", train_lstm_lr_10_1_auc, test_lstm_lr_10_1_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_10_1.lr.get_value() )\n",
    "        \n",
    "        \n",
    "        \n",
    "        adam_lr_10_2.lr.set_value(0.01*(epoch+1)**(-2))\n",
    "        lstm_lr_10_2.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_10_2_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_10_2.predict(X[train_idx]))\n",
    "        test_lstm_lr_10_2_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_10_2.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_10_2_aucs[i][epoch]=train_lstm_lr_10_2_auc\n",
    "        test_lstm_lr_10_2_aucs[i][epoch]=test_lstm_lr_10_2_auc\n",
    "        print(\"LSTM LR = 0.01*t^(-2): \", train_lstm_lr_10_2_auc, test_lstm_lr_10_2_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_10_2.lr.get_value() )\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        adam_lr_10_3.lr.set_value(0.01*(epoch+1)**(-3))\n",
    "        lstm_lr_10_3.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_10_3_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_10_3.predict(X[train_idx]))\n",
    "        test_lstm_lr_10_3_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_10_3.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_10_3_aucs[i][epoch]=train_lstm_lr_10_3_auc\n",
    "        test_lstm_lr_10_3_aucs[i][epoch]=test_lstm_lr_10_3_auc\n",
    "        print(\"LSTM LR = 0.01*t^(-3): \", train_lstm_lr_10_3_auc, test_lstm_lr_10_3_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_10_3.lr.get_value() )\n",
    "        \n",
    "        adam_lr_10_4.lr.set_value(0.01*(epoch+1)**(-4))\n",
    "        lstm_lr_10_4.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_10_4_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_10_4.predict(X[train_idx]))\n",
    "        test_lstm_lr_10_4_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_10_4.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_10_4_aucs[i][epoch]=train_lstm_lr_10_4_auc\n",
    "        test_lstm_lr_10_4_aucs[i][epoch]=test_lstm_lr_10_4_auc\n",
    "        print(\"LSTM LR = 0.01*t^(-4): \", train_lstm_lr_10_4_auc, test_lstm_lr_10_4_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_10_4.lr.get_value() )\n",
    "\n",
    "        \n",
    "        #-----------------------------------------------------------------\n",
    "        \n",
    "        \n",
    "        adam_lr_100_0.lr.set_value(0.005)\n",
    "        lstm_lr_100_0.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_100_0_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_100_0.predict(X[train_idx]))\n",
    "        test_lstm_lr_100_0_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_100_0.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_100_0_aucs[i][epoch]=train_lstm_lr_100_0_auc\n",
    "        test_lstm_lr_100_0_aucs[i][epoch]=test_lstm_lr_100_0_auc\n",
    "        print(\"LSTM LR = 0.005: \", train_lstm_lr_100_0_auc, test_lstm_lr_100_0_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_100_0.lr.get_value() )\n",
    "        \n",
    "        adam_lr_100_1.lr.set_value(0.005*(epoch+1)**(-1))\n",
    "        lstm_lr_100_1.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_100_1_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_100_1.predict(X[train_idx]))\n",
    "        test_lstm_lr_100_1_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_100_1.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_100_1_aucs[i][epoch]=train_lstm_lr_100_1_auc\n",
    "        test_lstm_lr_100_1_aucs[i][epoch]=test_lstm_lr_100_1_auc\n",
    "        print(\"LSTM LR = 0.005*t^{-1}: \", train_lstm_lr_100_1_auc, test_lstm_lr_100_1_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_100_1.lr.get_value() )\n",
    "        \n",
    "        adam_lr_100_2.lr.set_value(0.005*(epoch+1)**(-2))\n",
    "        lstm_lr_100_2.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_100_2_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_100_2.predict(X[train_idx]))\n",
    "        test_lstm_lr_100_2_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_100_2.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_100_2_aucs[i][epoch]=train_lstm_lr_100_2_auc\n",
    "        test_lstm_lr_100_2_aucs[i][epoch]=test_lstm_lr_100_2_auc\n",
    "        print(\"LSTM LR = 0.005*t^{-2}: \", train_lstm_lr_100_2_auc, test_lstm_lr_100_2_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_100_2.lr.get_value() )\n",
    "        \n",
    "        adam_lr_100_3.lr.set_value(0.005*(epoch+1)**(-3))\n",
    "        lstm_lr_100_3.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_100_3_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_100_3.predict(X[train_idx]))\n",
    "        test_lstm_lr_100_3_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_100_3.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_100_3_aucs[i][epoch]=train_lstm_lr_100_3_auc\n",
    "        test_lstm_lr_100_3_aucs[i][epoch]=test_lstm_lr_100_3_auc\n",
    "        print(\"LSTM LR = 0.005*t^{-3}: \", train_lstm_lr_100_3_auc, test_lstm_lr_100_3_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_100_3.lr.get_value() )\n",
    "        \n",
    "        \n",
    "        adam_lr_100_4.lr.set_value(0.005*(epoch+1)**(-4))\n",
    "        lstm_lr_100_4.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_100_4_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_100_4.predict(X[train_idx]))\n",
    "        test_lstm_lr_100_4_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_100_4.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_100_4_aucs[i][epoch]=train_lstm_lr_100_4_auc\n",
    "        test_lstm_lr_100_4_aucs[i][epoch]=test_lstm_lr_100_4_auc\n",
    "        print(\"LSTM LR = 0.005*t^{-4}: \", train_lstm_lr_100_4_auc, test_lstm_lr_100_4_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_100_4.lr.get_value() )\n",
    "        \n",
    "        \n",
    "        #-------------------------------------------------------------------\n",
    "        \n",
    "        adam_lr_1000_0.lr.set_value(0.001)\n",
    "        lstm_lr_1000_0.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_1000_0_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_1000_0.predict(X[train_idx]))\n",
    "        test_lstm_lr_1000_0_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_1000_0.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_1000_0_aucs[i][epoch]=train_lstm_lr_1000_0_auc\n",
    "        test_lstm_lr_1000_0_aucs[i][epoch]=test_lstm_lr_1000_0_auc\n",
    "        print(\"LSTM LR = 0.001: \", train_lstm_lr_1000_0_auc, test_lstm_lr_1000_0_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_1000_0.lr.get_value() )\n",
    "        \n",
    "        adam_lr_1000_1.lr.set_value(0.001*(epoch+1)**(-1))\n",
    "        lstm_lr_1000_1.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_1000_1_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_1000_1.predict(X[train_idx]))\n",
    "        test_lstm_lr_1000_1_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_1000_1.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_1000_1_aucs[i][epoch]=train_lstm_lr_1000_1_auc\n",
    "        test_lstm_lr_1000_1_aucs[i][epoch]=test_lstm_lr_1000_1_auc\n",
    "        print(\"LSTM LR = 0.001*t^{-1}: \", train_lstm_lr_1000_1_auc, test_lstm_lr_1000_1_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_1000_1.lr.get_value() )\n",
    "\n",
    "        adam_lr_1000_2.lr.set_value(0.001*(epoch+1)**(-2))\n",
    "        lstm_lr_1000_2.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_1000_2_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_1000_2.predict(X[train_idx]))\n",
    "        test_lstm_lr_1000_2_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_1000_2.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_1000_2_aucs[i][epoch]=train_lstm_lr_1000_2_auc\n",
    "        test_lstm_lr_1000_2_aucs[i][epoch]=test_lstm_lr_1000_2_auc\n",
    "        print(\"LSTM LR = 0.001*t^{-2}: \", train_lstm_lr_1000_2_auc, test_lstm_lr_1000_2_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_1000_2.lr.get_value() )\n",
    "        \n",
    "        adam_lr_1000_3.lr.set_value(0.001*(epoch+1)**(-3))\n",
    "        lstm_lr_1000_3.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_1000_3_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_1000_3.predict(X[train_idx]))\n",
    "        test_lstm_lr_1000_3_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_1000_3.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_1000_3_aucs[i][epoch]=train_lstm_lr_1000_3_auc\n",
    "        test_lstm_lr_1000_3_aucs[i][epoch]=test_lstm_lr_1000_3_auc\n",
    "        print(\"LSTM LR = 0.001*t^{-3}: \", train_lstm_lr_1000_3_auc, test_lstm_lr_1000_3_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_1000_3.lr.get_value() )\n",
    "        \n",
    "        adam_lr_1000_4.lr.set_value(0.001*(epoch+1)**(-4))\n",
    "        lstm_lr_1000_4.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_1000_4_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_1000_4.predict(X[train_idx]))\n",
    "        test_lstm_lr_1000_4_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_1000_4.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_1000_4_aucs[i][epoch]=train_lstm_lr_1000_4_auc\n",
    "        test_lstm_lr_1000_4_aucs[i][epoch]=test_lstm_lr_1000_4_auc\n",
    "        print(\"LSTM LR = 0.001*t^{-4}: \", train_lstm_lr_1000_4_auc, test_lstm_lr_1000_4_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_1000_4.lr.get_value() )\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_lstm_lr_100_aucs_mean = np.mean(train_lstm_lr_100_aucs, axis=0)\n",
    "test_lstm_lr_100_aucs_mean = np.mean(test_lstm_lr_100_aucs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "S_1 = pd.Series( [test_lstm_lr_1_0_aucs[0][26],\n",
    "test_lstm_lr_1_1_aucs[0][26],\n",
    "test_lstm_lr_1_2_aucs[0][26],\n",
    "test_lstm_lr_1_3_aucs[0][26],\n",
    "test_lstm_lr_1_4_aucs[0][26]], index = ['t^0','1/t','1/t^2','1/t^3','1/t^4'])\n",
    "\n",
    "S_10 = pd.Series([test_lstm_lr_10_0_aucs[0][26],\n",
    "test_lstm_lr_10_1_aucs[0][26],\n",
    "test_lstm_lr_10_2_aucs[0][26],\n",
    "test_lstm_lr_10_3_aucs[0][26],\n",
    "test_lstm_lr_10_4_aucs[0][26]], index = ['t^0','1/t','1/t^2','1/t^3','1/t^4'])\n",
    "\n",
    "S_100 = pd.Series([test_lstm_lr_100_0_aucs[0][26],\n",
    "test_lstm_lr_100_1_aucs[0][26],\n",
    "test_lstm_lr_100_2_aucs[0][26],\n",
    "test_lstm_lr_100_3_aucs[0][26],\n",
    "test_lstm_lr_100_4_aucs[0][26]], index = ['t^0','1/t','1/t^2','1/t^3','1/t^4'])\n",
    "\n",
    "S_1000 = pd.Series([test_lstm_lr_1000_0_aucs[0][26],\n",
    "test_lstm_lr_1000_1_aucs[0][26],\n",
    "test_lstm_lr_1000_2_aucs[0][26],\n",
    "test_lstm_lr_1000_3_aucs[0][26],\n",
    "test_lstm_lr_1000_4_aucs[0][26]], index = ['t^0','1/t','1/t^2','1/t^3','1/t^4'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1cf492550>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAckAAAFRCAYAAAAfClZfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cf4b0e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = {'LR = 0.05': S_1,\n",
    "     'LR = 0.01': S_10,\n",
    "     'LR = 0.005': S_100,\n",
    "     'LR = 0.001': S_1000}\n",
    "data_frame = pd.DataFrame(d) \n",
    "blu = sns.light_palette(\"navy\", as_cmap= True)\n",
    "sns.heatmap(data_frame, cmap= blu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_lstm_lr_100_aucs_mean = np.mean(train_lstm_lr_100_aucs, axis=0)\n",
    "test_lstm_lr_100_aucs_mean = np.mean(test_lstm_lr_100_aucs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0435     \n",
      "LSTM LR = 0.01):  0.940990814785 0.930967040099 0\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 13s - loss: 0.0438    \n",
      "LSTM LR = 0.01*t^(-1):  0.937532948759 0.922154117588 0\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0432    \n",
      "LSTM LR = 0.01*t^(-2):  0.929175861509 0.918217304062 0\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 13s - loss: 0.0463    \n",
      "LSTM LR = 0.005:  0.939585056077 0.929127529356 0\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0465    \n",
      "LSTM LR = 0.005*t^{-1}:  0.934451844333 0.929129129129 0\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 13s - loss: 0.0463    \n",
      "LSTM LR = 0.005*t^{-2}:  0.937604471843 0.926465735142 0\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0316    \n",
      "LSTM LR = 0.01):  0.949514385768 0.936568532002 1\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0291    \n",
      "LSTM LR = 0.01*t^(-1):  0.954137527887 0.940878778322 1\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0281    \n",
      "LSTM LR = 0.01*t^(-2):  0.953435171202 0.942495920578 1\n",
      "current learning rate:  0.0024999999441206455\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0309    \n",
      "LSTM LR = 0.005:  0.946711891263 0.937242265096 1\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0300    \n",
      "LSTM LR = 0.005*t^{-1}:  0.949532211521 0.940605445628 1\n",
      "current learning rate:  0.0024999999441206455\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0290    \n",
      "LSTM LR = 0.005*t^{-2}:  0.947860551993 0.937805842372 1\n",
      "current learning rate:  0.0012499999720603228\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0294    \n",
      "LSTM LR = 0.01):  0.951120134023 0.934978357353 2\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0253    \n",
      "LSTM LR = 0.01*t^(-1):  0.95927519607 0.941306603407 2\n",
      "current learning rate:  0.0033333334140479565\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0245    \n",
      "LSTM LR = 0.01*t^(-2):  0.955839557217 0.943336487172 2\n",
      "current learning rate:  0.0011111111380159855\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0281    \n",
      "LSTM LR = 0.005:  0.95301846671 0.939160164731 2\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0272    \n",
      "LSTM LR = 0.005*t^{-1}:  0.951518902726 0.939878691477 2\n",
      "current learning rate:  0.0016666667070239782\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0264    \n",
      "LSTM LR = 0.005*t^{-2}:  0.951202990765 0.942048441135 2\n",
      "current learning rate:  0.0005555555690079927\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0269    \n",
      "LSTM LR = 0.01):  0.953791796302 0.932606579182 3\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0231    \n",
      "LSTM LR = 0.01*t^(-1):  0.963802497256 0.943769340116 3\n",
      "current learning rate:  0.0024999999441206455\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0239    \n",
      "LSTM LR = 0.01*t^(-2):  0.957724465571 0.944391880465 3\n",
      "current learning rate:  0.0006249999860301614\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0266    \n",
      "LSTM LR = 0.005:  0.956598032015 0.941626558065 3\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0254    \n",
      "LSTM LR = 0.005*t^{-1}:  0.954440455657 0.943636330394 3\n",
      "current learning rate:  0.0012499999720603228\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0255    \n",
      "LSTM LR = 0.005*t^{-2}:  0.952912942652 0.944046786513 3\n",
      "current learning rate:  0.0003124999930150807\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0257    \n",
      "LSTM LR = 0.01):  0.959941020965 0.932868484923 4\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0214    \n",
      "LSTM LR = 0.01*t^(-1):  0.966197310182 0.946317550427 4\n",
      "current learning rate:  0.0020000000949949026\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0226    \n",
      "LSTM LR = 0.01*t^(-2):  0.958258798027 0.944204478451 4\n",
      "current learning rate:  0.00039999998989515007\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0240    \n",
      "LSTM LR = 0.005:  0.958681224365 0.93543680667 4\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0245    \n",
      "LSTM LR = 0.005*t^{-1}:  0.957723475252 0.947230792436 4\n",
      "current learning rate:  0.0010000000474974513\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 14s - loss: 0.0254    \n",
      "LSTM LR = 0.005*t^{-2}:  0.953114087572 0.943592907976 4\n",
      "current learning rate:  0.00019999999494757503\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0242    \n",
      "LSTM LR = 0.01):  0.964012885159 0.934545504409 5\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 16s - loss: 0.0197    \n",
      "LSTM LR = 0.01*t^(-1):  0.969048110278 0.943920632962 5\n",
      "current learning rate:  0.0016666667070239782\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 16s - loss: 0.0223    \n",
      "LSTM LR = 0.01*t^(-2):  0.959519474911 0.94605473053 5\n",
      "current learning rate:  0.00027777778450399637\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 16s - loss: 0.0231    \n",
      "LSTM LR = 0.005:  0.964097282398 0.941503604061 5\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 15s - loss: 0.0239    \n",
      "LSTM LR = 0.005*t^{-1}:  0.959326307566 0.947568116061 5\n",
      "current learning rate:  0.0008333333535119891\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 16s - loss: 0.0250    \n",
      "LSTM LR = 0.005*t^{-2}:  0.953841092213 0.944758457087 5\n",
      "current learning rate:  0.00013888889225199819\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 16s - loss: 0.0236    \n",
      "LSTM LR = 0.01):  0.963144814989 0.93154387264 6\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 16s - loss: 0.0187    \n",
      "LSTM LR = 0.01*t^(-1):  0.971281060962 0.943026131154 6\n",
      "current learning rate:  0.0014285714132711291\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 15s - loss: 0.0222    \n",
      "LSTM LR = 0.01*t^(-2):  0.959732998825 0.94551583547 6\n",
      "current learning rate:  0.0002040816325461492\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 16s - loss: 0.0216    \n",
      "LSTM LR = 0.005:  0.966667381898 0.939760765332 6\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 15s - loss: 0.0230    \n",
      "LSTM LR = 0.005*t^{-1}:  0.960301607344 0.948306754243 6\n",
      "current learning rate:  0.0007142857066355646\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 16s - loss: 0.0248    \n",
      "LSTM LR = 0.005*t^{-2}:  0.954043007381 0.944646930035 6\n",
      "current learning rate:  0.0001020408162730746\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 16s - loss: 0.0219    \n",
      "LSTM LR = 0.01):  0.966583644871 0.92911450263 7\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 15s - loss: 0.0177    \n",
      "LSTM LR = 0.01*t^(-1):  0.973804065262 0.943076409743 7\n",
      "current learning rate:  0.0012499999720603228\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0220    \n",
      "LSTM LR = 0.01*t^(-2):  0.960086267843 0.945548288014 7\n",
      "current learning rate:  0.00015624999650754035\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0202    \n",
      "LSTM LR = 0.005:  0.970346419307 0.940933627692 7\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0225    \n",
      "LSTM LR = 0.005*t^{-1}:  0.9606828804 0.947031049314 7\n",
      "current learning rate:  0.0006249999860301614\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 18s - loss: 0.0246    \n",
      "LSTM LR = 0.005*t^{-2}:  0.954205749906 0.944537688373 7\n",
      "current learning rate:  7.812499825377017e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0216    \n",
      "LSTM LR = 0.01):  0.971290634052 0.935280028887 8\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0166    \n",
      "LSTM LR = 0.01*t^(-1):  0.975962631939 0.941775108442 8\n",
      "current learning rate:  0.0011111111380159855\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0217    \n",
      "LSTM LR = 0.01*t^(-2):  0.960329886471 0.945647473958 8\n",
      "current learning rate:  0.00012345678987912834\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0191    \n",
      "LSTM LR = 0.005:  0.974386208149 0.942493635188 8\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0221    \n",
      "LSTM LR = 0.005*t^{-1}:  0.961307001835 0.94677462851 8\n",
      "current learning rate:  0.0005555555690079927\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 14s - loss: 0.0245    \n",
      "LSTM LR = 0.005*t^{-2}:  0.954470110228 0.944875011998 8\n",
      "current learning rate:  6.172839493956417e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0194    \n",
      "LSTM LR = 0.01):  0.970117325367 0.927091017959 9\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0160    \n",
      "LSTM LR = 0.01*t^(-1):  0.97760480195 0.940384219836 9\n",
      "current learning rate:  0.0010000000474974513\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0217    \n",
      "LSTM LR = 0.01*t^(-2):  0.96055138796 0.945772256275 9\n",
      "current learning rate:  9.999999747378752e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0176    \n",
      "LSTM LR = 0.005:  0.975942935582 0.940536426838 9\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0214    \n",
      "LSTM LR = 0.005*t^{-1}:  0.96239987456 0.946962487602 9\n",
      "current learning rate:  0.0005000000237487257\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0243    \n",
      "LSTM LR = 0.005*t^{-2}:  0.954558523764 0.944848044391 9\n",
      "current learning rate:  4.999999873689376e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0191    \n",
      "LSTM LR = 0.01):  0.975238378187 0.933098395199 10\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0149    \n",
      "LSTM LR = 0.01*t^(-1):  0.978291533592 0.939399673646 10\n",
      "current learning rate:  0.0009090909152291715\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0215    \n",
      "LSTM LR = 0.01*t^(-2):  0.960747801353 0.945811107912 10\n",
      "current learning rate:  8.264462667284533e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0161    \n",
      "LSTM LR = 0.005:  0.978825315871 0.938604814861 10\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0213    \n",
      "LSTM LR = 0.005*t^{-1}:  0.963318120924 0.948049419282 10\n",
      "current learning rate:  0.00045454545761458576\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0243    \n",
      "LSTM LR = 0.005*t^{-2}:  0.954592744808 0.944784510538 10\n",
      "current learning rate:  4.132231333642267e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0188    \n",
      "LSTM LR = 0.01):  0.975559901958 0.931870226391 11\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0144    \n",
      "LSTM LR = 0.01*t^(-1):  0.980172810775 0.940013986589 11\n",
      "current learning rate:  0.0008333333535119891\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0215    \n",
      "LSTM LR = 0.01*t^(-2):  0.960873902052 0.945858186954 11\n",
      "current learning rate:  6.944444612599909e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 14s - loss: 0.0143    \n",
      "LSTM LR = 0.005:  0.981933929176 0.939450409313 11\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 10s - loss: 0.0209    \n",
      "LSTM LR = 0.005*t^{-1}:  0.964014865798 0.948720866986 11\n",
      "current learning rate:  0.00041666667675599456\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 10s - loss: 0.0243    \n",
      "LSTM LR = 0.005*t^{-2}:  0.954688420688 0.944892838044 11\n",
      "current learning rate:  3.4722223062999547e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0188    \n",
      "LSTM LR = 0.01):  0.976154643911 0.933142274695 12\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0139     \n",
      "LSTM LR = 0.01*t^(-1):  0.981225850643 0.939082918535 12\n",
      "current learning rate:  0.0007692307699471712\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0213     \n",
      "LSTM LR = 0.01*t^(-2):  0.960972273801 0.945786425695 12\n",
      "current learning rate:  5.917159796808846e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 10s - loss: 0.0131    \n",
      "LSTM LR = 0.005:  0.984191527816 0.936921396282 12\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0206     \n",
      "LSTM LR = 0.005*t^{-1}:  0.964887997601 0.948082785982 12\n",
      "current learning rate:  0.0003846153849735856\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0241     \n",
      "LSTM LR = 0.005*t^{-2}:  0.954805883599 0.945039560108 12\n",
      "current learning rate:  2.958579898404423e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0182     \n",
      "LSTM LR = 0.01):  0.975972645171 0.931122446648 13\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0131     \n",
      "LSTM LR = 0.01*t^(-1):  0.982661814101 0.938469976826 13\n",
      "current learning rate:  0.0007142857066355646\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 10s - loss: 0.0214    \n",
      "LSTM LR = 0.01*t^(-2):  0.961062833029 0.945730205091 13\n",
      "current learning rate:  5.10204081365373e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0125     \n",
      "LSTM LR = 0.005:  0.985906101194 0.935183128334 13\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0201     \n",
      "LSTM LR = 0.005*t^{-1}:  0.96509970593 0.947681928504 13\n",
      "current learning rate:  0.0003571428533177823\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0243     \n",
      "LSTM LR = 0.005*t^{-2}:  0.954861341498 0.945036360561 13\n",
      "current learning rate:  2.551020406826865e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0170     \n",
      "LSTM LR = 0.01):  0.976649583653 0.931925989917 14\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0127     \n",
      "LSTM LR = 0.01*t^(-1):  0.983340183044 0.937575475018 14\n",
      "current learning rate:  0.0006666666595265269\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0213     \n",
      "LSTM LR = 0.01*t^(-2):  0.961144809487 0.945760600783 14\n",
      "current learning rate:  4.444444493856281e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0117     \n",
      "LSTM LR = 0.005:  0.98764257164 0.936348677445 14\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0199     \n",
      "LSTM LR = 0.005*t^{-1}:  0.965726138111 0.947492698178 14\n",
      "current learning rate:  0.00033333332976326346\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0241     \n",
      "LSTM LR = 0.005*t^{-2}:  0.954946508986 0.945097151946 14\n",
      "current learning rate:  2.2222222469281405e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0169     \n",
      "LSTM LR = 0.01):  0.97902326976 0.927660080171 15\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0123     \n",
      "LSTM LR = 0.01*t^(-1):  0.984303543969 0.937403156581 15\n",
      "current learning rate:  0.0006249999860301614\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0213     \n",
      "LSTM LR = 0.01*t^(-2):  0.961251103794 0.945818421161 15\n",
      "current learning rate:  3.9062499126885086e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0104     \n",
      "LSTM LR = 0.005:  0.988801520691 0.935447776544 15\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0195     \n",
      "LSTM LR = 0.005*t^{-1}:  0.965397792137 0.945994396223 15\n",
      "current learning rate:  0.0003124999930150807\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0242     \n",
      "LSTM LR = 0.005*t^{-2}:  0.955000426388 0.945175769377 15\n",
      "current learning rate:  1.9531249563442543e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0163     \n",
      "LSTM LR = 0.01):  0.97843237905 0.928613087974 16\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0116     \n",
      "LSTM LR = 0.01*t^(-1):  0.985144215295 0.936888943738 16\n",
      "current learning rate:  0.0005882352706976235\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0211     \n",
      "LSTM LR = 0.01*t^(-2):  0.961300399704 0.945826191488 16\n",
      "current learning rate:  3.4602075174916536e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0102     \n",
      "LSTM LR = 0.005:  0.987781216388 0.935291455839 16\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 10s - loss: 0.0195    \n",
      "LSTM LR = 0.005*t^{-1}:  0.966679485804 0.948127579634 16\n",
      "current learning rate:  0.00029411763534881175\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0241     \n",
      "LSTM LR = 0.005*t^{-2}:  0.955063036595 0.945250273104 16\n",
      "current learning rate:  1.7301037587458268e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0176     \n",
      "LSTM LR = 0.01):  0.977372296909 0.923018452242 17\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0117     \n",
      "LSTM LR = 0.01*t^(-1):  0.985761074387 0.936068945658 17\n",
      "current learning rate:  0.0005555555690079927\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0214     \n",
      "LSTM LR = 0.01*t^(-2):  0.961353326786 0.945789168164 17\n",
      "current learning rate:  3.0864197469782084e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0097    \n",
      "LSTM LR = 0.005:  0.988826443735 0.934725593173 17\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0192     \n",
      "LSTM LR = 0.005*t^{-1}:  0.967164907474 0.94722759289 17\n",
      "current learning rate:  0.00027777778450399637\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 10s - loss: 0.0242    \n",
      "LSTM LR = 0.005*t^{-2}:  0.955113047736 0.945300780232 17\n",
      "current learning rate:  1.5432098734891042e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 10s - loss: 0.0170    \n",
      "LSTM LR = 0.01):  0.976758628847 0.928589776992 18\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 10s - loss: 0.0113    \n",
      "LSTM LR = 0.01*t^(-1):  0.986127052506 0.934977443197 18\n",
      "current learning rate:  0.0005263157654553652\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 10s - loss: 0.0212    \n",
      "LSTM LR = 0.01*t^(-2):  0.961398001205 0.945766314259 18\n",
      "current learning rate:  2.770083119685296e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 10s - loss: 0.0094    \n",
      "LSTM LR = 0.005:  0.990519890295 0.932301708101 18\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 10s - loss: 0.0190    \n",
      "LSTM LR = 0.005*t^{-1}:  0.967930809669 0.947896298125 18\n",
      "current learning rate:  0.0002631578827276826\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 10s - loss: 0.0244    \n",
      "LSTM LR = 0.005*t^{-2}:  0.955142372201 0.945301008771 18\n",
      "current learning rate:  1.385041559842648e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 10s - loss: 0.0170    \n",
      "LSTM LR = 0.01):  0.975978256982 0.921949803685 19\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 10s - loss: 0.0107    \n",
      "LSTM LR = 0.01*t^(-1):  0.986833260435 0.935266316545 19\n",
      "current learning rate:  0.0005000000237487257\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 10s - loss: 0.0213    \n",
      "LSTM LR = 0.01*t^(-2):  0.961441685304 0.945753058995 19\n",
      "current learning rate:  2.499999936844688e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 10s - loss: 0.0088    \n",
      "LSTM LR = 0.005:  0.990444075825 0.935158446117 19\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 10s - loss: 0.0188    \n",
      "LSTM LR = 0.005*t^{-1}:  0.968070224665 0.94771392397 19\n",
      "current learning rate:  0.0002500000118743628\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 10s - loss: 0.0241    \n",
      "LSTM LR = 0.005*t^{-2}:  0.955168560653 0.94532523391 19\n",
      "current learning rate:  1.249999968422344e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 13s - loss: 0.0169    \n",
      "LSTM LR = 0.01):  0.977831255038 0.929975637738 20\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 10s - loss: 0.0106    \n",
      "LSTM LR = 0.01*t^(-1):  0.987337113053 0.932900937467 20\n",
      "current learning rate:  0.0004761904710903764\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0209     \n",
      "LSTM LR = 0.01*t^(-2):  0.961488560433 0.94579236771 20\n",
      "current learning rate:  2.2675736545352265e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0084     \n",
      "LSTM LR = 0.005:  0.990354066775 0.932778897619 20\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0186     \n",
      "LSTM LR = 0.005*t^{-1}:  0.968327927839 0.947345519035 20\n",
      "current learning rate:  0.0002380952355451882\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0243     \n",
      "LSTM LR = 0.005*t^{-2}:  0.955200580988 0.945360428922 20\n",
      "current learning rate:  1.1337868272676133e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 10s - loss: 0.0158    \n",
      "LSTM LR = 0.01):  0.977807597402 0.929849027109 21\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 10s - loss: 0.0101    \n",
      "LSTM LR = 0.01*t^(-1):  0.987753817545 0.93367019988 21\n",
      "current learning rate:  0.00045454545761458576\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0210     \n",
      "LSTM LR = 0.01*t^(-2):  0.961550840534 0.945822991942 21\n",
      "current learning rate:  2.0661156668211333e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0083     \n",
      "LSTM LR = 0.005:  0.99068582385 0.933847546176 21\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0184     \n",
      "LSTM LR = 0.005*t^{-1}:  0.968704249296 0.946859187955 21\n",
      "current learning rate:  0.00022727272880729288\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0240     \n",
      "LSTM LR = 0.005*t^{-2}:  0.955175657944 0.945253929729 21\n",
      "current learning rate:  1.0330578334105667e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0168     \n",
      "LSTM LR = 0.01):  0.978054847202 0.926865678464 22\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0099     \n",
      "LSTM LR = 0.01*t^(-1):  0.988339976727 0.933254258825 22\n",
      "current learning rate:  0.00043478261795826256\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0209     \n",
      "LSTM LR = 0.01*t^(-2):  0.961590233248 0.945829391035 22\n",
      "current learning rate:  1.8903590898844413e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0085     \n",
      "LSTM LR = 0.005:  0.99182909284 0.932761071574 22\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0184     \n",
      "LSTM LR = 0.005*t^{-1}:  0.969275993827 0.947079956669 22\n",
      "current learning rate:  0.00021739130897913128\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0240     \n",
      "LSTM LR = 0.005*t^{-2}:  0.955204652302 0.945277240711 22\n",
      "current learning rate:  9.451795449422207e-06\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0173     \n",
      "LSTM LR = 0.01):  0.977997078557 0.927085075944 23\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0097     \n",
      "LSTM LR = 0.01*t^(-1):  0.988781769316 0.932760614496 23\n",
      "current learning rate:  0.00041666667675599456\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0211     \n",
      "LSTM LR = 0.01*t^(-2):  0.961624454293 0.945838304057 23\n",
      "current learning rate:  1.7361111531499773e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0083     \n",
      "LSTM LR = 0.005:  0.992069080296 0.933883198267 23\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0181     \n",
      "LSTM LR = 0.005*t^{-1}:  0.969552623109 0.947563088202 23\n",
      "current learning rate:  0.00020833333837799728\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0241     \n",
      "LSTM LR = 0.005*t^{-2}:  0.955247511134 0.945354029829 23\n",
      "current learning rate:  8.680555765749887e-06\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 10s - loss: 0.0173    \n",
      "LSTM LR = 0.01):  0.979204938394 0.928743355227 24\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0095     \n",
      "LSTM LR = 0.01*t^(-1):  0.98920331537 0.932068598279 24\n",
      "current learning rate:  0.00039999998989515007\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0210     \n",
      "LSTM LR = 0.01*t^(-2):  0.961644810863 0.94582573441 24\n",
      "current learning rate:  1.5999999959603883e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0077     \n",
      "LSTM LR = 0.005:  0.991308514823 0.934349874989 24\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0181     \n",
      "LSTM LR = 0.005*t^{-1}:  0.969612372393 0.947077671279 24\n",
      "current learning rate:  0.00019999999494757503\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0241     \n",
      "LSTM LR = 0.005*t^{-2}:  0.955265722012 0.945372312952 24\n",
      "current learning rate:  7.999999979801942e-06\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 9s - loss: 0.0443     \n",
      "LSTM LR = 0.01):  0.933213094235 0.931181059497 0\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 9s - loss: 0.0433     \n",
      "LSTM LR = 0.01*t^(-1):  0.93727250776 0.936461322847 0\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 9s - loss: 0.0425     \n",
      "LSTM LR = 0.01*t^(-2):  0.936369482564 0.938354571545 0\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 9s - loss: 0.0479     \n",
      "LSTM LR = 0.005:  0.936058637168 0.939331916865 0\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 9s - loss: 0.0496     \n",
      "LSTM LR = 0.005*t^{-1}:  0.932770709326 0.936561523866 0\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 9s - loss: 0.0469     \n",
      "LSTM LR = 0.005*t^{-2}:  0.930555480891 0.935217729106 0\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 10s - loss: 0.0319    \n",
      "LSTM LR = 0.01):  0.948800274525 0.943433772192 1\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 9s - loss: 0.0292     \n",
      "LSTM LR = 0.01*t^(-1):  0.950775943131 0.947621514106 1\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 10s - loss: 0.0272    \n",
      "LSTM LR = 0.01*t^(-2):  0.952813657621 0.947775669519 1\n",
      "current learning rate:  0.0024999999441206455\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 9s - loss: 0.0310     \n",
      "LSTM LR = 0.005:  0.946845941191 0.944144208425 1\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 9s - loss: 0.0298     \n",
      "LSTM LR = 0.005*t^{-1}:  0.947654273617 0.948558779019 1\n",
      "current learning rate:  0.0024999999441206455\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 9s - loss: 0.0290     \n",
      "LSTM LR = 0.005*t^{-2}:  0.947446576702 0.947108396801 1\n",
      "current learning rate:  0.0012499999720603228\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 10s - loss: 0.0285    \n",
      "LSTM LR = 0.01):  0.951889465147 0.94141785983 2\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 9s - loss: 0.0253     \n",
      "LSTM LR = 0.01*t^(-1):  0.958024391872 0.949131356268 2\n",
      "current learning rate:  0.0033333334140479565\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 9s - loss: 0.0246     \n",
      "LSTM LR = 0.01*t^(-2):  0.956669910076 0.949630379363 2\n",
      "current learning rate:  0.0011111111380159855\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 9s - loss: 0.0279     \n",
      "LSTM LR = 0.005:  0.950241329368 0.943526705884 2\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 9s - loss: 0.0269     \n",
      "LSTM LR = 0.005*t^{-1}:  0.953531553132 0.950377812896 2\n",
      "current learning rate:  0.0016666667070239782\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 9s - loss: 0.0268     \n",
      "LSTM LR = 0.005*t^{-2}:  0.949856398499 0.948094991447 2\n",
      "current learning rate:  0.0005555555690079927\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 9s - loss: 0.0263     \n",
      "LSTM LR = 0.01):  0.95728129722 0.939146049481 3\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 9s - loss: 0.0233     \n",
      "LSTM LR = 0.01*t^(-1):  0.962517678597 0.949934726194 3\n",
      "current learning rate:  0.0024999999441206455\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 12s - loss: 0.0229    \n",
      "LSTM LR = 0.01*t^(-2):  0.95725581809 0.950138651783 3\n",
      "current learning rate:  0.0006249999860301614\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 12s - loss: 0.0264    \n",
      "LSTM LR = 0.005:  0.951563892253 0.947387638321 3\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 11s - loss: 0.0253    \n",
      "LSTM LR = 0.005*t^{-1}:  0.954683545835 0.951410654165 3\n",
      "current learning rate:  0.0012499999720603228\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 11s - loss: 0.0258    \n",
      "LSTM LR = 0.005*t^{-2}:  0.951017462892 0.948435895132 3\n",
      "current learning rate:  0.0003124999930150807\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 12s - loss: 0.0255    \n",
      "LSTM LR = 0.01):  0.963432743382 0.94412835244 4\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 11s - loss: 0.0215    \n",
      "LSTM LR = 0.01*t^(-1):  0.964816064194 0.948695757114 4\n",
      "current learning rate:  0.0020000000949949026\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 11s - loss: 0.0225    \n",
      "LSTM LR = 0.01*t^(-2):  0.95877667021 0.950612569568 4\n",
      "current learning rate:  0.00039999998989515007\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 11s - loss: 0.0250    \n",
      "LSTM LR = 0.005:  0.957607430095 0.947359449903 4\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 11s - loss: 0.0240    \n",
      "LSTM LR = 0.005*t^{-1}:  0.957445371623 0.950879919099 4\n",
      "current learning rate:  0.0010000000474974513\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 11s - loss: 0.0254    \n",
      "LSTM LR = 0.005*t^{-2}:  0.951714079129 0.948923907126 4\n",
      "current learning rate:  0.00019999999494757503\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 12s - loss: 0.0232    \n",
      "LSTM LR = 0.01):  0.966213552523 0.943887429551 5\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 11s - loss: 0.0201    \n",
      "LSTM LR = 0.01*t^(-1):  0.967293307691 0.948244301975 5\n",
      "current learning rate:  0.0016666667070239782\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 11s - loss: 0.0216    \n",
      "LSTM LR = 0.01*t^(-2):  0.959932022799 0.950128081126 5\n",
      "current learning rate:  0.00027777778450399637\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 11s - loss: 0.0229    \n",
      "LSTM LR = 0.005:  0.965914074739 0.947801655717 5\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 11s - loss: 0.0235    \n",
      "LSTM LR = 0.005*t^{-1}:  0.958715296304 0.95098034034 5\n",
      "current learning rate:  0.0008333333535119891\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 11s - loss: 0.0253    \n",
      "LSTM LR = 0.005*t^{-2}:  0.952059923332 0.94908687142 5\n",
      "current learning rate:  0.00013888889225199819\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 12s - loss: 0.0220    \n",
      "LSTM LR = 0.01):  0.96653554154 0.942200088441 6\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 11s - loss: 0.0189    \n",
      "LSTM LR = 0.01*t^(-1):  0.970470863298 0.94827645439 6\n",
      "current learning rate:  0.0014285714132711291\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 11s - loss: 0.0216    \n",
      "LSTM LR = 0.01*t^(-2):  0.960031923391 0.950340375153 6\n",
      "current learning rate:  0.0002040816325461492\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 11s - loss: 0.0216    \n",
      "LSTM LR = 0.005:  0.968069553211 0.941416538497 6\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 11s - loss: 0.0227    \n",
      "LSTM LR = 0.005*t^{-1}:  0.959702934613 0.951347670668 6\n",
      "current learning rate:  0.0007142857066355646\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 11s - loss: 0.0248    \n",
      "LSTM LR = 0.005*t^{-2}:  0.952341593724 0.949159544687 6\n",
      "current learning rate:  0.0001020408162730746\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 12s - loss: 0.0222    \n",
      "LSTM LR = 0.01):  0.966982742285 0.941253574203 7\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 764s - loss: 0.0181   \n",
      "LSTM LR = 0.01*t^(-1):  0.972588039077 0.947350200578 7\n",
      "current learning rate:  0.0012499999720603228\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 12s - loss: 0.0213    \n",
      "LSTM LR = 0.01*t^(-2):  0.96055785745 0.950302937409 7\n",
      "current learning rate:  0.00015624999650754035\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 12s - loss: 0.0203    \n",
      "LSTM LR = 0.005:  0.970729014492 0.945975574735 7\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 10s - loss: 0.0223    \n",
      "LSTM LR = 0.005*t^{-1}:  0.960069106123 0.951798685363 7\n",
      "current learning rate:  0.0006249999860301614\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 12s - loss: 0.0246    \n",
      "LSTM LR = 0.005*t^{-2}:  0.952709277181 0.949239265057 7\n",
      "current learning rate:  7.812499825377017e-05\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 13s - loss: 0.0201    \n",
      "LSTM LR = 0.01):  0.969981327997 0.938471729659 8\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "5664/6377 [=========================>....] - ETA: 1s - loss: 0.0169"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d7c6643c086e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0madam_lr_10_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0mlstm_lr_10_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/giancarlokerg/anaconda/lib/python3.5/site-packages/Keras-1.0.5-py3.5.egg/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1080\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/giancarlokerg/anaconda/lib/python3.5/site-packages/Keras-1.0.5-py3.5.egg/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[1;32m    799\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/giancarlokerg/anaconda/lib/python3.5/site-packages/Keras-1.0.5-py3.5.egg/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/giancarlokerg/anaconda/lib/python3.5/site-packages/Theano-0.8.2-py3.5.egg/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/giancarlokerg/anaconda/lib/python3.5/site-packages/Theano-0.8.2-py3.5.egg/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    949\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[1;32m    950\u001b[0m                  allow_gc=allow_gc):\n\u001b[0;32m--> 951\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/giancarlokerg/anaconda/lib/python3.5/site-packages/Theano-0.8.2-py3.5.egg/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(node, args, outs)\u001b[0m\n\u001b[1;32m    938\u001b[0m                         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                         \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m                         self, node)\n\u001b[0m\u001b[1;32m    941\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/Users/giancarlokerg/.theano/compiledir_Darwin-15.2.0-x86_64-i386-64bit-i386-3.5.1-64/scan_perform/mod.cpp:6635)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/giancarlokerg/anaconda/lib/python3.5/site-packages/Theano-0.8.2-py3.5.egg/theano/tensor/type.py\u001b[0m in \u001b[0;36mvalue_zeros\u001b[0;34m(self, shape)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mvalue_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m         \"\"\"\n\u001b[1;32m    631\u001b[0m         \u001b[0mCreate\u001b[0m \u001b[0man\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mof\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "folds = 3\n",
    "batch_size_nn = 16\n",
    "batch_size_lstm = 16\n",
    "hidden = 50\n",
    "dropout_probability = 0.25\n",
    "\n",
    "n_epochs = 25\n",
    "epoch = 0\n",
    "\n",
    "\n",
    "#-----------------------\n",
    "\n",
    "train_lstm_lr_10_0_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_10_0_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_10_1_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_10_1_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_10_2_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_10_2_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "\n",
    "\n",
    "#---------------------------\n",
    "\n",
    "train_lstm_lr_100_0_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_100_0_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_100_1_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_100_1_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_100_2_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_100_2_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(KFold(len(df_h),folds, shuffle=True)):\n",
    " \n",
    "    \n",
    "    \n",
    "    \n",
    " \n",
    "    \n",
    "    \n",
    "    #-------------------------------------------------------------------------\n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_10_0 = Model(input = sequence, output = output)\n",
    "    adam_lr_10_0 = Adam(lr = 0.01)\n",
    "    lstm_lr_10_0.compile(optimizer = adam_lr_10_0 , loss='mean_squared_error')\n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_10_1 = Model(input = sequence, output = output)\n",
    "    adam_lr_10_1 = Adam(lr = 0.01)\n",
    "    lstm_lr_10_1.compile(optimizer = adam_lr_10_1 , loss='mean_squared_error')\n",
    "    \n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_10_2 = Model(input = sequence, output = output)\n",
    "    adam_lr_10_2 = Adam(lr = 0.01)\n",
    "    lstm_lr_10_2.compile(optimizer = adam_lr_10_2 , loss='mean_squared_error')\n",
    "    \n",
    "   \n",
    "    \n",
    "    #---------------------------------------------------------------------------------\n",
    "\n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_100_0 = Model(input = sequence, output = output)\n",
    "    adam_lr_100_0 = Adam(lr = 0.005)\n",
    "    lstm_lr_100_0.compile(optimizer = adam_lr_100_0 , loss='mean_squared_error')\n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_100_1 = Model(input = sequence, output = output)\n",
    "    adam_lr_100_1 = Adam(lr = 0.005)\n",
    "    lstm_lr_100_1.compile(optimizer = adam_lr_100_1 , loss='mean_squared_error')\n",
    "    \n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_100_2 = Model(input = sequence, output = output)\n",
    "    adam_lr_100_2 = Adam(lr = 0.005)\n",
    "    lstm_lr_100_2.compile(optimizer = adam_lr_100_2 , loss='mean_squared_error')\n",
    "    \n",
    "   \n",
    "    \n",
    "   \n",
    "\n",
    "    \n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        \n",
    "\n",
    "       \n",
    "        \n",
    "\n",
    "    \n",
    "        #----------------------------------------\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "        adam_lr_10_0.lr.set_value(0.01)\n",
    "        lstm_lr_10_0.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_10_0_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_10_0.predict(X[train_idx]))\n",
    "        test_lstm_lr_10_0_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_10_0.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_10_0_aucs[i][epoch]=train_lstm_lr_10_0_auc\n",
    "        test_lstm_lr_10_0_aucs[i][epoch]=test_lstm_lr_10_0_auc\n",
    "        print(\"LSTM LR = 0.01): \", train_lstm_lr_10_0_auc, test_lstm_lr_10_0_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_10_0.lr.get_value() )   \n",
    "        \n",
    "        \n",
    "        \n",
    "        adam_lr_10_1.lr.set_value(0.01*(epoch+1)**(-1))\n",
    "        lstm_lr_10_1.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_10_1_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_10_1.predict(X[train_idx]))\n",
    "        test_lstm_lr_10_1_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_10_1.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_10_1_aucs[i][epoch]=train_lstm_lr_10_1_auc\n",
    "        test_lstm_lr_10_1_aucs[i][epoch]=test_lstm_lr_10_1_auc\n",
    "        print(\"LSTM LR = 0.01*t^(-1): \", train_lstm_lr_10_1_auc, test_lstm_lr_10_1_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_10_1.lr.get_value() )\n",
    "        \n",
    "        \n",
    "        \n",
    "        adam_lr_10_2.lr.set_value(0.01*(epoch+1)**(-2))\n",
    "        lstm_lr_10_2.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_10_2_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_10_2.predict(X[train_idx]))\n",
    "        test_lstm_lr_10_2_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_10_2.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_10_2_aucs[i][epoch]=train_lstm_lr_10_2_auc\n",
    "        test_lstm_lr_10_2_aucs[i][epoch]=test_lstm_lr_10_2_auc\n",
    "        print(\"LSTM LR = 0.01*t^(-2): \", train_lstm_lr_10_2_auc, test_lstm_lr_10_2_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_10_2.lr.get_value() )\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    " \n",
    "\n",
    "        \n",
    "        #-----------------------------------------------------------------\n",
    "        \n",
    "        \n",
    "        adam_lr_100_0.lr.set_value(0.005)\n",
    "        lstm_lr_100_0.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_100_0_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_100_0.predict(X[train_idx]))\n",
    "        test_lstm_lr_100_0_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_100_0.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_100_0_aucs[i][epoch]=train_lstm_lr_100_0_auc\n",
    "        test_lstm_lr_100_0_aucs[i][epoch]=test_lstm_lr_100_0_auc\n",
    "        print(\"LSTM LR = 0.005: \", train_lstm_lr_100_0_auc, test_lstm_lr_100_0_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_100_0.lr.get_value() )\n",
    "        \n",
    "        adam_lr_100_1.lr.set_value(0.005*(epoch+1)**(-1))\n",
    "        lstm_lr_100_1.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_100_1_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_100_1.predict(X[train_idx]))\n",
    "        test_lstm_lr_100_1_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_100_1.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_100_1_aucs[i][epoch]=train_lstm_lr_100_1_auc\n",
    "        test_lstm_lr_100_1_aucs[i][epoch]=test_lstm_lr_100_1_auc\n",
    "        print(\"LSTM LR = 0.005*t^{-1}: \", train_lstm_lr_100_1_auc, test_lstm_lr_100_1_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_100_1.lr.get_value() )\n",
    "        \n",
    "        adam_lr_100_2.lr.set_value(0.005*(epoch+1)**(-2))\n",
    "        lstm_lr_100_2.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_100_2_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_100_2.predict(X[train_idx]))\n",
    "        test_lstm_lr_100_2_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_100_2.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_100_2_aucs[i][epoch]=train_lstm_lr_100_2_auc\n",
    "        test_lstm_lr_100_2_aucs[i][epoch]=test_lstm_lr_100_2_auc\n",
    "        print(\"LSTM LR = 0.005*t^{-2}: \", train_lstm_lr_100_2_auc, test_lstm_lr_100_2_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_100_2.lr.get_value() )\n",
    "        \n",
    "        \n",
    "        \n",
    "        #-------------------------------------------------------------------\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "S_10 = pd.Series([test_lstm_lr_10_0_aucs[0][24],\n",
    "test_lstm_lr_10_1_aucs[0][24],\n",
    "test_lstm_lr_10_2_aucs[0][24]], index = ['t^0','1/t','1/t^2'])\n",
    "\n",
    "S_100 = pd.Series([test_lstm_lr_100_0_aucs[0][24],\n",
    "test_lstm_lr_100_1_aucs[0][24],\n",
    "test_lstm_lr_100_2_aucs[0][24]], index = ['t^0','1/t','1/t^2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x188b79320>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAckAAAFRCAYAAAAfClZfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x188a559e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = {\n",
    "     'LR = 0.01': S_10,\n",
    "     'LR = 0.005': S_100}\n",
    "\n",
    "data_frame = pd.DataFrame(d) \n",
    "blu = sns.light_palette(\"navy\", as_cmap= True)\n",
    "sns.heatmap(data_frame, cmap= blu, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x188419208>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAFVCAYAAAAUiG2GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXdcVtUbwL/vZCMbRUWcgHuWintPRFNTf5qmlTbN0rSp\nZYmjsrJcOSrLkQtHaooTAXPkAgcioggKCMjmnff3x4UXcCFLke7387mfu8597jnPfd/znOdMmSAI\nAhISEhISEhLPJPKnHQEJCQkJCQmJkiMZcgkJCQkJiWcYyZBLSEhISEg8w0iGXEJCQkJC4hlGMuQS\nEhISEhLPMJIhl5CQkJCQeIZRFhVAEARmzZrF5cuXUavVfPXVV9SsWdN0PyAggFWrVmFra4ufnx9D\nhw4FYMiQIVhbWwNQo0YN5syZw40bN5gxYwZyuZz69eszc+bMckqWhISEhITEf4MiDXlgYCBarZb1\n69dz9uxZ/P39Wbx4MQApKSn88MMPbNu2DWtra8aNG0f79u1xcnIC4Lfffisky9/fn/fee4/WrVsz\nc+ZMAgMD6dGjRzkkS0JCQkJC4r9BkVXrp06domPHjgA0a9aMsLAw072YmBi8vb2xsbFBJpPRpEkT\nzpw5w6VLl8jKymLChAmMGzeOc+fOARAeHk7r1q0B6NSpE6GhoeWRJgkJCQkJif8MRXrkGRkZ2NjY\n5D+gVGI0GpHL5Xh4eBAZGUlycjIWFhaEhoZSu3ZtLCwsmDBhAsOGDSM6OprXXnuN3bt3U3ASOSsr\nK9LT08snVRISEhISEv8RijTk1tbWZGZmms7zjDiAra0tM2bM4O2338bOzo5GjRphb29PrVq1cHd3\nB8DDwwM7OzsSExNRKBQmOZmZmdja2j7y3YIgIJPJSpQwCQkJCQmJ/wJFGvKWLVty8OBB+vTpw5kz\nZ2jQoIHpnsFgIDw8nD/++AOtVsuECRN477332Lx5MxEREcycOZP4+HgyMjJwcXHB29ubEydO0KZN\nG44cOULbtm0f+W6ZTEZiouS1lzfOzjaSnssZScflj6TjJ4Ok5/LH2dmm6EAFKNKQ9+zZk+DgYEaM\nGAGIHdZ27txJdnY2w4YNA2Dw4MGYmZkxfvx47OzsGDp0KB9++CGjRo1CLpfj7++PXC5n+vTpfPrp\np+h0OurWrUufPn1KkEQJCQkJCQmJPGQVffUzqeRX/kgl7PJH0nH5I+n4ySDpufwprkcuTQgjISEh\nISHxDCMZcgkJCQkJiWcYyZBLSEhISEg8w0iGXEJCQkJC4hlGMuQSEs8IwVFBBEcFPe1oSEhIVDCK\nHH4mISFRMViw3x8Anzodn3JMJCQkKhKSRy4hUcHZe2kPPgtbE3LtKCHXjtL5+7YcjNj/tKMlISFR\nQZA8cgmJCkhq9l32XNzFjrAADl05gNagNd27GH+B8WvH0L1BT/o27E9Pr97Ymld5irGVkJB4mkiG\nXKJMyGu7lap9S05KVjJ7Lu5i+/mtHLl6CJ1BB0DDqo2xt7CngYsnOfocIhOvkJiRwPawrWwP24pK\nocKnTkf6eg+gj3c/qlVxe8opkZCQeJJIhlyiTJi770sUcoVkyItJUmYSuy/sZHvYVo5ePYLeqAeg\niVszBjYexMDGg6jrVJ/t57fi22QwANvPb2VgYz8uxV9k94Wd7L74F4euHODQlQNM3/4eLWu0ol+j\ngfT1HkB9lwaPer3EPUgFUolnEWmKVokST7mYmJHItwfmsf7ftWRqMwBoWaM1n/b5XMoICxAcFYSd\nnSWNHFoBot52he9gR/g2gqOOYDAaAGhevQUDGvsxoLEvdRzrFusdN+/GsOfCX+y+8Bch0UdNMus5\n1advwwH0azSAFtVbIZfLK62xKoupQ/1+7gdAwKu7yiJKlRJpitbyp7hTtEqGXKJYf8xsXTZ7LvzF\npjMbOHAlEIPRgFwmxygYATBTmvFBj4+Z5PMmKoWqPKP9zOD3cz8EmYFBjYeyM2wbIdeOmvTVskYr\nBjYZzIBGvtRy8CiT96VkJbPv8t/sCt/JwSuBZOuyAXC1qUof7/4cv34MW3Nbdkz8u0zeV1EojYEJ\njgpiwX5/Qq4dBaCN+/N81Ouzp17YqYiFLsmQlz+SIZcoNkX9MY1GIyHXjrLxzHp2hG0jQyOGbVa9\nBcOav0hsaixWaisu3g7n4JX9ZOmy8K7aiG/8vqe1+3NPKhkVjuCoIGbt+pizcWcKXW/t/hwDG/sx\noJEvNe3dyzUOWdosjlw9xO4LO9kZto10Tf53tlBZ8FyttvTw7EVTt+Y0cWuKtVnxMpCKRGkNzG/H\nVzM1YDIAaoWaF1v+j4k+b9DAxbOsolhsKmINgWTIyx/JkEsUm4f9MS/HX2LjmfVsPvMnsak3Aahh\nV5MXmg1nWIsRpgyuYPvt2pNrOHnjOL+f/BWZTMbY58bzSe9Z/7le1VFJV5m370u2nttsuvZOpym8\n3PZVqtvVeCpx0hv0bDqzgXc2vw6AhcqSbF2W6b5MJqOOY12aujWjafUW4t6tGVUs7B4or6J5i6Ux\nMMeuhTBk5QAEQaCVexsux18iNecuAN0a9GCiz5t0qdcNmUxWllF+KMFRQczeM5N/b54EoK5TPV5s\nOYrO9bribO2Ck5Uz5irzYsmDsvlWkiEvfyRDLlEs7m2/jU+PZ+vZjWw68yfncj1JGzNbfJv4Maz5\nCNp6tEcuL3r6gWPXQpgaMJmIxMu42lRlzoD5DGg86IllhE+L+LTbfHNwHr+f+BW9UY+LtSud6nWh\nUU0vsrK0TOv+4VON3/zAOYXOX2g+jLOxZzgXd5Zzufu0nNRCYWo5eNDUrTnNqjeniVszmro1x9HK\nscJ5iyU1MKdvnuKFlb5kaTNZM2Y9Pb36EHBuMyqFmmXBP3EsOgQALxdvXvN5gxeaD8dCZVHW0Qfg\n6p0r7Azbzo6wbab/38OwMbPF2doZZ2uX3K3AsU3+uZOVM6N/Gw6UzbeqbIa8ohVIQTLkEsXE7+d+\nKBQyRrUcy8Yz6zkceRCD0YBSrqRbgx4Maz6CXt59S5RxafVafjzyHQsPLUCj19DTszdzfb8p9+rk\np0FaTio/Hvme5cGLydJlUcexLh/2/BQB8Gs6BGdnG1Ye+M1Uc/G0uLf3+73xEQSB6ynRJqN+Lu4M\n52LPkJyVXCicWmGG1qABwN2+FgMb++FTpwMu1q6i8bB2fqw+Ek/bUwy/FcbgFf1Iy0lj+YjVD/w+\nZ2NPszT4J7ad24LeqMfR0pGxz0/g5bav4mrjWup4RyRcZkdYADvCtnHhdhgASrmSmnbuNHDxxNrM\nhixdJq3dnycxIyF3SxT36QkkZyWZ+lwUhbO1CwMa+dK/kS+NqjXB0cqx2PGtbIa8ohVIQTLkEkVg\nNBqJuXuDrec28ceJ37ieEl3ofssarRjWYgSDmryAk7VTmbwz6k4k0wKmEBR1GEuVJR/0+JjX2r+O\nUvHsj37M0eWw6tjPfH/oa1KyU3C1qcrUbjMY1XpMIUP2LGd+giAQm3qTs7FnOB8nGvhTN06Skp38\nyOccLR1xsXHF2cYVZ2tnXKxdcbFxxcXaJXfvytSAySjlSra9trvU8SyujiMTr+C7vA93MhP5YegS\nRrT83yPD30qNY+Wx5fx2fBV3s++iVqgZ0mwYE33epFG1xo/9XkEQuBh/gR1hAewM28blhEuA2C7f\ntX53BjQeRG/vvhyJPPTIQlceBqOB5KzkAka+gKHPSOBaUhTHrx974LOuNlVpWLURjao1oWHVRjSs\n2pj6zg0eWgi7twbvWeZARCCz98wk/PZ5QKxx+bDXZ/Rt2P8px0wy5P8ZivJkjEYj11OiiUi4zOWE\ni1xOuEREwmWuJFwmq0C7aB5jn3uZiT5vUc+5frnEVxAENp5Zz8y/PiIpK4nG1ZryzeDvaVHj2cwQ\n9AY9f55ex/z9c4hLjcXWvArvdJ7CK+0mYam2vC/8s2zIH8T8wDlkajPJ1GSQpcuiU90uJGTEk5Ae\nT2JGAgnpCbnnCaa25kdR27EO3/j9QIe6nUocp+Lo+HpyNL7L+3ArLY65vt8wvu2rj/2eTG0mf/67\njuUhi7l6JxKAjnU6M7HDG/Ro0PuBQ/wEQSDs1jl2hG1jR1iA6TkzpRndGvRkYONB9Pbqi425bXGS\n/FjkNacYBSOp2Xdp69GeC7fDCL8dxoXb4dy8G1MovEqhooGLl2jgq+YbeBcbF/x+7odKpWDjuB1l\nHs/y5m52CsevH+NYdCj/RIdyJvZf06RLBfF08eJ5j/a09WhHW4/21LCr+cTjKhny/wh51UGbJ+zg\neko0l+MvEZFwicu5W2RihGnYUR7mSnPqOTeggYsnXq7ehN8Kw8nKiepOVcnO1j2R9tukzCS+2PMp\n6079jkwmY0Lb1/iw56flkoGVB4IgsOvCTvz3fkFE4mXMlea80n4Sb3d6F3tLh4c+V9kMeVFV9AXJ\n0eVwJzORhPR4EjISxH16PBEJlwk4n98ZsG/DAXw35MdH6vFRPK6Ob6XGMXB5H26kRDOz75e82fGd\nEr3PaDSyP2IvS4MXE3T1ECB2Snu1/etsPbsJhVzBzL6zTcb7enI0II4W6OHZm4GNB9HDs1e5jxQo\n6lulZt/lwu1wLuQa9vBb57kUf/G+Ar9KrkJnzJ9t8NPen9Pds2e5xr00xKXGciw6hGPRIfxz/RiX\n4i+QZ+4UcgVNqjVFIVdSvUoNzFXmxN69iUKh5OSN42RpM01yatjV5HmPdrSt1Z62Hu1p4OJZ7n19\nJENeybl3vKsMGQKFP6G50pz6Lp54uniJm6s3DVw8qWXvgUKuMIXL+1M/jfbb4KggpgZM5uqdSKrZ\nujFn4ALscntHV6ROJwUJiTrK7L9ncirmBAq5glGtxvB+t+m4Vale5LOVzZCXBXmeYoYmnb/CdxBz\n9wY17Gqy5MWVPF+rbbHlPY6OEzMS8fu5L1cSI5jabQYf9PioRHG/l7Bb51kevJhNZzaYZucriKXa\nit5efRjQ2I9uDXpgpbYqk/eWFwajgevJ1wi/le+5n4n9l9tpt0xhFHIFTd2a0dbDh7Ye7Xneoy0O\nlsVvcy8pBWs9BEHgSmJEvuGODiXm7g1TWAuVBa1qthENskd7WtVsg7WZ9QMLOTqDjrBb5zgWHcqx\n6BCOR4eSlJVkkuVg6cBztUQ5bT3a0cStGSqFqsz7exQHyZA/gywPXsInf00HxGqgptWb4+nijaeL\nFw1cPHG3r1XIYBfF0zIyGr2GHw5/y/eHvkFr0GJv6UAdx7rsfr1irOyV98e0Na/CV3tncSAiEIAB\njQbxYc9PizX9qWTI76dgJhpwbjORiVf4+sBcZDIZ03t8zDud3nusERJ5FKXjlKxkhqwcSPit87ze\n4W1m9f2yzD2r+PR4vt7vz6/HVwHQy6sP/2s9li71u5VbT/cnxfzAOeToc0jKjudqwjWMgpGzsacL\nVU8/TrV0aQyeIAgkZyVzKy2ON/98lSxdNt6uDTl+PbRQh0x7C3ue92hniktTt+YlnqCqqEKCpcqS\nVu7PEZ0UhZO1M3+/cbBE7ymIZMgrORq9hsZz6pOWk8rLbV/F0cqx1FXiT9vIbDi1lo//+oC0nDRA\n/GM0qtaE5tVbUNPeHXcHD2raueNu7/7QMc0FKU1GoTPoSMq8Q0J6PG9vmkRiRiJ3MhMBsR30kz6z\nStSu/7R1/KwQEnWU1/98hVtpcXSq15Wfhi1/7J7hj9JxhiadoSt9+ffmKcY+N4H5g74tt+rR+YFz\nEAQBAQGFXPHUhxyWFQ+qwcvSZvFvzEnRyF0Pva9auqadu8kLbuvRnvrODRi8QuxMdm8vcYPRQGJG\nAnGpsdxKu8Wt1Fji0uKIS43ldtqt3OtxaPSa++LmbOVCp/pdTNXf9Z0bFKsQWFxi797MNeyhHIjY\nV8iwt6/dgWndPyyVZy4Z8krO4qBFzNr9Ma+2m8RXA+cX2T75OFQEI3Px9gU6/yBWp947UUlBbM2r\n4G5fSzTw9u7UtHOnpn0t3O1r4W7vjo257X3DSQxGA0mZSWInrIzCnbHyju/ktt0WrELLw0ptxdRu\nM3ij4zslzvwrgo6fFZIyk5i8+XX2XtqDk5UzPw1fTtf63Yt87mE6ztJmMfKXFwiNDmZ4i5H88MKS\ncs3ki9N/4FnkUb/lvGrp0Gui93qvp6yUK01ND9Vs3fBwqI3OqONWahy302+Z1gi4F5lMhrO1C262\nblSrUh1zpZlpsqVN47fTqV6Xsk1kMfnneigDl/UGIGjycTxdvUolTzLklZg7GXdo+20L5DIZ/7x/\npsSdgu6lIhiZghOVyJAxof1rxKTc4EbKjdx9NDGm4+sP7HkPYrtdXmZgqbZCrVCTlpNa5DjbKuZ2\n4hCp3OFRCrmSzWf/BODwO8fwrtqwVOmrCDp+lhAEgZ9DlvD5nk/RGXS83WkKM3p+8sjq0QfpWKPX\n8NKaERy8sp+Bjf1Y9uKqSjHs8WlSnN+y0WjMr5a+HkJQ5GESMuILhVHKlVSzdaOqbTXcqlSnWhU3\n0WDnGm23Km642lQt9O0L5Rcy2VOv9Sjr+BTXkEu/6GeIBfvnkJaTypf955aZEa8oeLl6F/JiHCwd\ncbB0pFn1FveFFQSBpMwkYu5eNxn7PEMfmXjFNDZeEATsLcV1vMWJSnINtY04aUneeOYHTXc5P3AO\nU7vNAGBn+LZSG3KJ4iGTyXjN5w2e92jHq+vGsejIQkKuHWXZiFW429d6LBk6g47X1r/MwSv76eHZ\niyXDV0hG/Akjl8vxdPXC09WLsc+PZ36gmIclZd7BSm3NtB4f4WzlXOwaknvzi6fN046P5JE/I1yO\nv0SXRe3wcKjNkcn/cPy2OMGDT3Vp7uSC5JWM9UY9KoWqxCXjsq4erUw6ftKk56QxbdsUtpzdiK15\nFRYO+ZGBjQfdF66gjg1GA29ufI0tZzfSsU5nfh/75zPf2ayiUJrfcmVvdigrpKr1SsqIX4ZwICKQ\nNWM20Nu7L34Bue3AftLcyQWpqBlFZdLx00AQBNb/+wcfbp9Kli6Lsc9N4Iv+cwoZ5zwdC4LA1IDJ\nrDnxC63dn+PPlwOwNrN+irGvXEi/5fKnuIa8/Hp8SJQZByL2cSAikI51u2BlY8WggL6ExB0lJO4o\nfgH9CI4NKrHs4GAFhw6VXVyfNgUNd0Ux4hKlRyaTMbLVaPa+eRjvqo349fhK+izpRkTC5ULhBEHg\n079msObELzR1a866sZskIy5R6ZEMeQVHb9Azc9fHyGVyvug3hw41OuHl4G26P6ju4FJVry9YoGbW\nrDKIqITEE6CBiyd7Xj/AuOcncPF2OL1+6sy6U79z9OoRDl0+xNx9s1kesgRPFy82vLz1sYYrSkg8\n60hV6xWcVcd+Zsb29xnTZhzfDP6BPdd28dLuEVirbMjRZyOTyfh76CEaOzUpltzgYAULFqgJCRE7\n/7Rrp+eDD7T4+Dx4+IdE6SiL6sjgYHGSH+kbiewI28aULW+RlpOKk5UzVuaWXE+6jodDbXa89jeu\ntlWLLVPScdFUlKr1svpWFfGbS23klYjU7Ls8/01ztAYdx947TZo+ld6bu6LR57B76AGup0Yz/u/R\nuFlV5++hB3G1evyMy2iEN94wZ8sWcUiHtbVAp056OnUy0Lmznjp1BCr50uFFUpYZhZ2dJY0ale63\n7OcntgcHBGQXEbLo+EDFyABLK2PL2U1MDZhMhkbUrVqhZtHQpQxuNrRE8iqjjstaTml/y2UVl7L6\nVhXtm4NkyCsVM3d9zJKji/ik9yxebvcKfTZ148rdCJb0WMELDYYD8MO/C/ny2EyaO7cgwG83lqr7\nV966F40G3nrLnG3bVDg5GXF3l3P1qpHU1PyWFjc3I506GejUSU/HjgZcXSv0z6QQ5Z1RGI2g04mb\nXg86nSx3n3+efwzTp5sjlyv46KMstFrxvrgHrVaWu89/ruC5VgsxMTLOnlWQmCh+H1dXI61bG6hT\nx4i5OZibg4WFkHssFHk+dqwFcjls2/b0M8CiZBiN4u9VqwWNRlboWKuFnBwZl++cY1pIOwDe9d5K\nU/ve5OVqgvB425UrcnbtUhIZKf526tc3MGiQnkaNjCiVAioVKJV5W+FzlUpAoaDQtXHjzJHJYMOG\nbBQKTFtxC8dP21gJQuHf+qhRliiVCpYsyUCvF68ZDLLcvbiJ12UFjsXvmHd97lw1ggBTpmhN+s97\n14OPZYW+VWSknL17lURFif+H2rWN9Oihp3Zt4yO/sdEoKyQ/OlpGUJCSGzdEOe7uRjp10uPhITox\ncrmAXE7uMabjvK3gNblc4Mcf1djYwN9/P3iOi+IgGfJKQlTSVTp+9xzVbN04MvkfJu2fwJ5rfzGp\n2Vt84ZM/+YAgCEw5+BZrL62hfx1fVvb+Dbns4V0fMjJg7FgLgoKU1K9vYNeuLOrVs2HlymyaNjUQ\nFKTkyBEFQUEKkpPz5Xh5GUyGvX17A9b39B+qCN5ZHvdmWno9pKdDaqqMtDRxE48pcJx3HWJi5Fy7\nJiczU8x1FQoBpTI/UxOEylJVIWBmBpaWoFaLx2q1gFrNA4/FPSQnw/nzCm7fFn8f1aoZadbMgLOz\nkJth52fs+Rm8rEDGD8nJMmJi5GRkiLq0sBCwtRUzTo0m31DrdI+h65azCiRJBqdnloOuygaZTDT6\ncjmF9uImmIyD+JuVodGI6Tc3F3ByMmJlVdig5IW/95pMJspKTxf1nJYmyrG2FnB1FQuABQuh+QXR\nwoVQg6Gy/NafHO3b65k2rXTNlJIhrySM+/1/7Lqwg59H/MIVTQTzT8yhY40ubBiwBaW88KQWWoOW\nF3cMJjguiLdbTOHTdp8/UGZiooyRIy04d05Bnz46li3LwcLiwW1eRiOEh8s5ckTBkSNKjh1TkJ0t\n/qmVSoEWLcTSa+fOBlq2NDB8eNl5Z1u3ZpOZCZmZsgJ7GRkZ5O7F64X3Mm7ckHHxooLUVDGearWY\nmeXkFD8zsrAQTOmtU8eAlVWex5XvjRU8z78mFLgHqamwbp0agIkTtbi5GVGrxftqdf6zBc/F+0Kh\ncCtXqlEoxO9iMAiMGqUnJ0dMW94+O/tR55CdLSMxEYKCxOaURo0MKBSFPVzR480/Ls9Ci1IpoNeL\n8qtUMeYWKESjpVaTW4gQCxBmZvmFirzjvLBn07ZwcNVIAPq8sZYObkMKeU5Q2JN68Cawe7cSmSzf\ng+va1YDBkG/gCta6POhcNHxiQefwYVHHzz+vx9w877vlF2oEoeB5wfsyjEbxPCcHEhLEwpK9vdH0\n/QUhP4x4nudx5u/zrxf+fgqFqLsH/VZVqgf/tvPOs7MFgoPFdPXqpcPBQZSnUOTXROQVSPKO867L\n5aK8pCQZP/xgBsDUqRqqVRPu+UbCfd/tQd9v505loeuDBukf8a2F+7zpvLCbNhWcKVBg6FD9A3Qp\nK3TtQbqOi5MxZ04CAEFBjnh6PnomyaKQDHklIDgqiMEr+vNcrba83etdxuweQU0bd/YOPYyjxYOX\nCUzJSabflh5cvRvJd11/YpT3mEL3r1+XMXy4JdeuyRk9Wsv8+RqUueWBx+m8otHAyZOip374sJLT\np+UYjeK/QS4XTMf29kbq1BG9qzzvS6crXM0mHud7bZmZoueQl6mDAJTegFSrZsTJSaBKFQEbG4Eq\nVShwLMbR1pYCx3lh4dtv1SY5MhlMm6YtURzmzxflWFmZkZWlKbGc7duV+Prq7zsuaXyg6HQJgvi9\n8qqztVqZydAvW6bCYMj3BidM0BXKxPMzdTEDL5ix53mixYnL46SpIun4xo2bANSqVaNU6SqtHEEQ\n5cTElF18LCxUuLi4lkhOWX3z7duVODqKC5UkJbmX+FuVlZz589WsX78FgJEjh5Q4XXlIU7Q+4xiM\nBj7bJa6R/FrHN3hj/2tYKC34pc8fDzXiAPbmDvzR70/6bu7O1MOTcbetRYfqnQAIC5MzYoQFCQly\npkzRMGOGtthtdWZmYpW3j4+BGTO0pKZCSIhYDR8YqOD6dbFaPCVFzqlThZ+9NyNXKguX4u3swMbG\nyI0booymTQ24uICVlYC1tYCVlXict8+7Ju4FrK3zry9bJnquULqMwsvLWChTLyl5cpydzVi5suSl\n9IIZTEkzm4LxgaLTJZPl1xaICKZ9p06GQnK8vIqftrLUsaPjDezsLLh61bnEcnx99QQHx+Ueu5Uq\nPiEh4syLvXoNeapyZDLw9jYSGirK6dZtENnZegwGIzqdEb1eQK83oteL5wbDo67JOH8+GLVaga9v\nV6Ki5Fhbq7C2VmFhoXysBYXyvhWIhrOk+Prq8fM7CUBAwON9K0EQ0GqNZGfrTVvdunreeScEoxFm\nzxY4ckTI9bKNuXsBg0HAaBQ3QSh8bjAIRESksHHjdeLj7wKwbdtm2rdvhY9PyX9DxaVIj1wQBGbN\nmsXly5dRq9V89dVX1KyZv8ZsQEAAq1atwtbWFj8/P4YOze8tmpSUxAsvvMDq1aupXbs2Fy9eZOLE\niXh4eAAwcuRI+vbt+8gI/tc88nWnfmfy5jfwazqEcGPYfZ3biiI0Lpih232xUlmxa8h+Ei56MWaM\nBRkZ8NVXGl55RXffM6UdTjJ/vpqcHLEaT6EQePddbSGv7HEKDWVZUi8Lr6qsqShDdgCTsSptRlMW\ncsoqLn5+21GpFGzc2P+R4fR6Izk5erKy9OTkGMjJ0RfK2GfODMVoFHjnnRZotQa0WiM6nQGNRtzr\ndEY0GgM6nXjv3jAJCZlcvZpKaqr4+7W2VuHmZo2trfqR8bqXtDQtcXEZZGSI/1crKyXOzpZYWChN\nBsRgMJqMinguYDQaTccGg2CKc3nXuyoUslyjrsbGRoWVVf5x4etq1q69iFwu5513mj8iHfenR7xm\n5Pr1dI4fv01cnLhcqouLBZ6e9lhZqcnO1hf6pnnHWVni/knUPwcFDcfT075UMsq8an3fvn0cOHAA\nf39/zp49y7Jly1i8eDEAKSkpvPDCC2zbtg1ra2vGjRuHv78/bm5u6PV63n33XSIjI1myZAm1a9dm\n48aNZGZmMm7cuMeOYEXJ/J4EGZoM2n7bgvScNJ5v0Z5DcfuZ2OxNZvv4F0vO+kt/8M6B13GOnkTq\nusUIRvjP2CRpAAAgAElEQVTxxxwGD36wUSutkSkL41lRDXBZUZEMuZ/fdgACAnyfupw8GRs29C9k\nUMWMV5ebGRvuuZ6/RUXd5cSJeBISxL4ZdnZqqlWzwsxMWShcntHW6UrXdllclEpZiZe+FQQBvV7M\nns3NFSiVchQKGQqFHLlclnssbnK5/J5zMZxCIUOrNXDhgriUaMuWLtjZmaFUivdVKjlKZd4me8ix\nuN29m8Py5WEADB9eH5VKQXq6lowMHRkZOtLTtWRm6kzXnrSu85DJwMJCiaWlEgsLJebm4j5vMzfP\nv5edrWPLlqsAjBvXEFdXS+Ry2X1bnk7FzoT553nb7t3RyGRQrZoVDg7mTJvWulRpKPOq9VOnTtGx\nozhzWLNmzQgLCzPdi4mJwdvbGxsb8aVNmjThzJkzuLm5MW/ePEaOHMmyZctM4cPDw4mOjiYwMJBa\ntWrx8ccfY2lZ9HCp/wo/HllIQno87b06cChuPx2rd2Zmu9nFljPC639sW+/E/l8HI1dns2aNjp7d\nym8Sv7Ko9i2rqmOoWB5nWVLc+GRn60lJySElRUNKSg6hobfYvDmSqKhUAFq3XkvHjm7UqmULYDI4\n+Xbn3nPxODo6jcOHb3L9ulgwadnyD1q3dsXJyQKNRo9GY8zdGx66padrSUvTYjCIhqpmzRWlUY2J\nu3e1pKZqC2XgtrZqXFzyMnKF6bq5uRJzc4Upg8/I0LFihZi/TZ/empo1bVCr5ajVCtRqBSqVHDMz\ncV/w2r1hFi06g7iYlyy3dqlkmfr8+SdNx6WV069f7TKRM3VqK6ys1GRlaYuUk/edCxr5S5eS+eCD\nowB8+GFr3NxsHloAKWhE7y2wrF17yWRUVSoF77zT3PRd1Wr5Yxee8tKUp5v3329VIt1YWirx9a0L\nwPbtV0skozQUacgzMjJMhhpAqVRiNBqRy+V4eHgQGRlJcnIyFhYWhIaGUrt2bbZu3YqjoyM+Pj4s\nXbrU9GyzZs0YPnw4DRs2ZOnSpSxatIjp06eXT8qeMW7ejWFx0CLsLe0JSTtKzSruLO/1y3091ItC\nEMSOWvsXD0Vtk4p2RHe2CQ3oISx94I87ODgOOzsLGjUqXVVQRWLBgpMYjQKbNg1AqRS9l5LKAfDx\nKZ3nWhod63SG3IxQx6xZoRgMAu+/34q7dzUkJ+dw966mkLHO29+9qyEn59HDX27cSOePPy4/Mszj\ncPNmBjdvZjwyjFotx8xMiZmZuLe3N8fe3oyoqDQA2rQRCwIFPad7tzwv6l7v6o8/LqJSybG1NUen\n0zNjRpsSecEFM3WjUWD48AbFVwbQsKFDmWTqXl72FVKOs7MNK1eeKTK8mZkCMzMLnJzyF7Y5ciTW\npGO9XuDFF0um47i4jEJpqlrVqkRyyko3eTLuPX5SFFm1PnfuXJo3b06fPn0A6NKlC4cKrLJx8OBB\nVqxYgZ2dHY6OjnTp0oVVq1aZ/kiXLl2idu3aLFmyBLVabSoUXL16lS+//JLVq1eXU9KeLf738/9Y\ne3wt5s7mYAXB44NpWa1lsWQYDDB5Mvz0E3h4wLadObwa2pnjscf5qttXfNTxo/ue6dJlPQCHDo0o\nVfwPHbqRK6/kHViKiyAIJCRkceFCEuHhd9i37zqHD8eY2icLolDIClVN5h/ffz0nR09SUjZZWWLN\ngK2tmnr17HFzs8r14kRPrvD+YccKPvroKCDw2WftSUvTkJ6uIy1NQ1qa1uSZitfzjvOv5+QUr3bC\nzs4MBwdzHBzMcXS0uG9/6NANLCyUudWEMkaPbmjSpbjngef3Xlu79qJJryqVnEmTmmNmlp9mM7N8\nHajVigcWpmbNCjYdy2QyZs5sX6y05rFx42WGDfO87/hpyZF4OJKOy4ciDfnevXs5ePAg/v7+nDlz\nhsWLF7N8+XIADAYDS5Ys4a233kKr1TJhwgQWLVqEnV3+QgVjxoxh9uzZeHh4MHz4cD799FOaNGnC\n77//zu3bt5k6deojI1hR2hXLk1MxJ+i7pDtmFmZoHDT81GM5wzyLZ1g1GnjzTXO2b1fh7W1gw4Zs\nqlYViM+Kp++mbtzMiOHnXr8wqJ7Y+/XQoRg++OAo0dGiR6RUynB0tMDZ2QIbm7xOKmrTsbhXY22t\nuu+ajY2KV14JRKGQlaq99GFVx3kG+/LlFCIi7nLpUjIRESlcvpxCSormofJatXLBwkKJwSD2wjUa\nxX1+Z6D7j/V6sYONVmsgLe3+joHljZWVqoDuxb21tQqjUeDvv68D8NZbzfD0dMDe3ix3E73bKlXM\nUCof3YSyffvVQh5ISb2HspBTVnHJoyL1Q6jMSHouf8q8s1vBXusA/v7+hIeHk52dzbBhw/jxxx/Z\nv38/ZmZmjB8/nl69ehV6/qWXXuLzzz839Vr/4osvUKlUODs788UXX2Bl9egqkcr2g7l39jJBEOi/\nrCcnbxwHZ5jY5g1md5hbLJnp6TBunDhbW9u2etasyaZKlfz7F5LCGbClF3qjji2DdpJ01oWZM4+Z\n2koBPDxs0WoNpKfryMjQlrh3p0Ihw97eDCcni1yjVLAAkF84uLdAYGWlYtq0IGQymD69jclQi8Y7\nhbt3CxtsuVyGh4ctnp72eHra06CBuN+xI8pkzMqyffLdd1ug0RjIyclv583J0Rc4NpjahQuGuXEj\njaVLzwMweXIL6tatUqgXb0FdWFmpHtoMUFbtpZUZycA8GSQ9lz/ShDAVnHunD916dhMTN4wHC+jQ\ntBN/DgwoVrt4QoKMUaPE2dr69tWxdKk4W9u97L++l1Gr30a5dwi6SA8UChlNmzrRvr0bTk6WhTqv\nGI0CWVliu2x6ujZ3y+uNqr3velxcBvv3xwBQt24VdDojGRk60tK06PWl67mqUMioXbsKDRrY4eXl\nQIMGotGuV68K5ub366kieZyQb4Aft4NQecenMiMZmCeDpOfyRzLkFZTgYAVffGHG6dOiR+7gYKT1\n8xkcre5FlhCPnXEIS/2+o0HNKjg7i9NSFiXv9m0Z8+aZER0tZ8wYLfPm5c/WVpCkpGzmzTvJr79d\nQDCClddNNi9+jZtR2kKdV0prrKCwtygIQm7PVdHLz+u9mt+TNb9wcONGOps3RwIwdqw37du74elp\nT926dpiZKUoUr4pAntEtrY4likYyME8GSc/lj2TIKyAxMTK+/VbNunUqjMaY3Kvu0GwOtPkYzk2D\n4/MLPVOlioCLixFnZwEXF6HA3oiLi8Ds2WZERsrR6WS8956G6dPvn61NqzWwalU4X399irQ0LfXq\n2VF3+AX+Vi2kW60e/N7vT5RyZRmMIy+9t1jZq46lzK/8kXT8ZJD0XP5IU7RWIOLjZXz3nZo1a1Ro\ntTIcHIzIZMFYWEDn/lrWGj5DEFSM6N6RBn1ySEiQk5goIyFBxp074v7KlUd7o7VrG+nY0VDIiAuC\nwL59N5g5M5SrV1OpUkXNl1+25+WXGyJTCIzZFcb+G/v4NHgGA+oMwi7TkkZWJRs/CWUz9KKshoFI\nSEhI/NeQPPJyIDkZFi0yY9UqFdnZMmrVMjJoUBS7dx/nyhWxZ7bcJgNjo/20G6xi28vbHipLp4Ok\nJNGo5xn5CxcULFsmTvkYFJRZaKWdS5eS+eyzUA4duolCIWPs2IZMm9YKR8f8hvN0bRoDtvTmYnI4\ntW3r4G5fk439d5STNiRA8mKeBJKOnwySnssfqWr9KZKeDkuWqFm6VE1Ghoxq1Yy8/76WkSN1yOVG\nxo79m717bxR6RqGQ0aiRI61bu5q2WrVsHjmhxYPmJU9KymbBglP8+usFDAaBzp1rMHt2O7y8HB4o\nI+DKZt7c/xo6ozjE6vlq7Zjx3Cf4VO9YBpqQuBcp8yt/JB0/GSQ9lz9S1fpTIDMTVq1S8+OPalJS\nZDg5GZk+XcPYsTrMzcWFGt588yB7995AbpuBseZZyLKiZ+t2pFyz5dy5RM6du8OqVeEAODtb0KqV\naNTbtHGhWTNnLC3z180tuIJQfHx1li8/z4IFJ0lN1VK3bhW++KIdPXq4P7Iw4Ff/BYwYmbRvAgAX\n7oRx4EYgHra1qW5Toxy1JSEhISFRlkgeeSnQaGDNGhULF6pJTJRTpYrAW29pmTBBi7W1GEanM/D6\n6wfYvj0KM5dUNAMWgFyD+e3nWTf7M3yqd0SjMXD+/B1Onow3bXkr+wAolXIaNXKgTZuqJq/9nXcO\nkpKiQaczEhl5F1tbNVOntmL8+Eao1Y/Xy3v+8Tlk6jK5cPccJ2JPkKXPQiFTMLDuICY2e5NWrm3K\nQ23/SSQvpvyRdPxkkPRc/kgeeTlRcCIXnQ42bFDxzTdqYmPlWFkJvPeehtdf1xaaiEWrNfDaa4Hs\n2hWNZ1M1Ue2+A4M4sYlH83TInePEzExhMtB5xMVlcPJkPCdOiIb9/Pk7nD17x7SoQ0H69KnFwoWd\nC7WDPw5eDt741huMs7MNS4JXojNoWXr2JwIitxAQuYXWrs8xsdkb9K/jW+w53yUkJCQkngySR/6Y\n+PlZIAjw0ks65s8349o1OebmAi+/rOPtt7U4ORVWo0Zj4NVX97Fnz3Xa+1SDUasJidwPucl5ufur\nzOv+zWO/PydHn+u1J3DwYAyHDt0E4Ndfe9O3r0ep0lawhC0IAkdjj7D83GL2Ru9BQKC6dQ0mNJnI\naO+XsDOvPIurPEkkL6b8kXT8ZJD0XP5Ind3KmOBgBfPmqTl2LN8jVSgExozRMWWKlmrV7ldfTo6e\n8eP3ERh4g86da+Ax8RC/XlqG7JYMpUzJK+0nEZsZw4phv5UoTmU95vphf8you5H8fH4p6y7+QZY+\nE0ulFSO8RvFq00nUtatfqnf+15Ayv/JH0vGTQdJz+VNcQ15+i1RXAmJiZBw6pODSpXw19e2r49ix\nTObP1zzQiGdn63nppb8JDLxBt2416f3RbX6NWIaTwRlBEHi361Q+7/cVvl6DSxwvLy97PvigNR98\n0BpPz/LzkOvY1cO/49eceekCM9t9iYO5A6vCfqbd2laM/ms4R24eMq2IFRwbRHBsUKneVxYyJCQk\nJP5rSB75PRiNcOiQgtWr1ezbp8BolGFmJtC4sZHmzQ04OAhMm3b/MpkAWVk6xoz5m6CgWHr1cueV\n2ZaM+nswNnIbcmJzsFJbc3zqGazNilfaKm8et4StN+rZFbWDpWd/4mT8cQC8HRoxsdkbrL/0B3KZ\nnAC/Xfc9JwgCOqMOrVGLzqBFa9CajjUGLTqjeG3a4SnIZTL2DTuCXFa5ypiSF1P+SDp+Mkh6Ln+k\nzm4lJClJxrp1Sn79Vc3166IRadnSwLhxWpRKGDpUXBd6+/YHqywjQ8fo0bsJCblF374efPJ1PQZs\n7wZAO5sO7NLtYGbfLyucES8OSrkS33qD8a03mFPxJ1h+djHbIrfy7sE3TWFqLnPGUmmJTCYTjXSu\n0S4ODVa6M6fDAoZ7jSzrJEhISEhUOv7THrkgwKlTclavVrN9uxKNRoaFhcDgwTrGjdPRvPnjrdyV\nkaFl5Mjd/PPPbQYMqM3Xi57Db0dvLiVf5MOWn7Jgpz/u9rUIevc4KoWqaIFPmNKUsOMyYllw3J8/\nLont/a6WVbFSWaFWqFHJ1agV6vxjuQq1wgy1QoVKrsZMYYZKoUItV5OuTWftpTUmuWYKM95vPZ03\nm0+ukDorLpIXU/5IOn4ySHoufySP/DHIzIQtW1SsXq0iLEwcVla3rpFx4zS8+KIOO7vHl5WWpmHE\niN2cPBmPn19dfljUmVcC/8el5Iu81vR1wqPC0Bv1fNxrZqUwSPfiZl2datZuTG09AwCZTMa0Nh8W\nW87843NMMiJSLnPsVghz/vmCrVc2s7DrIlq6Vq5FVCQkJCTKikpvyAuO/46IkPPLLyo2bFCRni5D\noRDo31/Hyy/r7lt45HFITdXw4ou7+PffBF54oR6LFnVlzolZ7L2+h841ujLIfQj9d/WkZY1WDGg8\nqBxSVzHIG48OsD1ya5nI+Lrzd8w+NpM1F36h7+buvNp0EjOe/xRrlXWRsm4Hix3mqvpI081KSEhU\nfip91fqgQRYkJ8twdhY4elQst7i6GhkzRseYMboH9jx/HFJSchg27C/OnbvDiBENWLiwM5sjN/DW\n/onUtavHrsGBvPz7aEKuHSXglV20r9OhVOkoTypyVVlwbBDvH3qHqNSr1LCuyYLOC+leq9cjn9nj\n1w9Br6fvzr1PKJZFU5F1XFmQdPxkkPRc/kjDz3IJDlbg52dBaKiSy5cVHD2qpEkTAytXZvPvv5l8\n8MGDx4A/DklJ2QwZspNz5+4werQX333XhdOJJ3nv4NvYqquwpu8GTt04Qci1o/T07F2hjXhFx6d6\nRw6+GMK7LadyO+sWI/8ayqR9E7iTfee+sLeDg9jVrwfxIUdJOH6MAJ/WJu9cQkJCorJSaQ25j4+B\nuXM1pvPFi7PYvz+LgQP1qErRVJ2YKBrx8PAkxo1ryNdfd+JWZixjd49CL+j5udcv1K5Sh9l7ZiKX\nyfmk9+dlkJr/NhZKCz5q+xn7hh6hhUtLtlzZSId1rfnz8joKVigJgkBq5BXTeeqVCNKvRz+FGEtI\nSEg8OSqtIQdxqFitWmLP8ytXHm8hkYcRHBzHzp1RDBmyg4sXk3nllcbMm9eBbEMWL+0eSWJ2ArN9\n/Onq3p2Np9dzMf4CL7YchXfVhmWRFAmgkVNjdg3Zz2wff3L0Oby1fyLDd/gRfTeKc999zb6hvmhT\n7+LWrQf1x4xDYWFByLtvcnHlsqcddQkJCYlyo1J3dvPyMmJjI2BlJdCo0eMNJXsYX331D2FhSeTk\nGJg0qSmff94WgMkH3uD8nbOM9h7LK00mka3LZm7gl5grzfmg+0dlkQyJAijkCiY2e5O+tQfwwZEp\nhF4KZPmClnheNmLp5kaDl8bT7L0PAKhStz5hP33P8Q+nYcjOofFbk59y7CUkJCTKnkrtkfv66rlz\nR4aTk4Cvr75EMoKD4/Dz287Jkwnk5BioXt2KXr3Etb6/OTmP7Ve30rZae+Z2+gaZTMbK0OXEpcby\nSvtJVLeT1vUuL9xta7Go+sfM/s0Rz8tGLteFXyc7In+pj2mq10ZvvE2f7buxdKvOqS8+5cwCfyp4\n304JCQmJYlOpPXJBEGdsa9q05N64j48bsbFehITcAmDdun54eTmw42oA80/Mwd2mFqv6/I5aoSYl\nK5nvD32DnYUd73Se8kB50tCo0iMIApd/WcmJT2cg6HQ0mPIux1vFcTzyT3pt7ExVq2rUtHFn++A9\nVKlbnz7bdrP3BV/OLvDHkJNDy09mISvuWEMJCQmJCkqlNuRpaaDTye5bYrS4fPPNKQBGjvRkx44o\ndI4xvLV/IlYqa37rtx4nCycAvj/8Lak5d5nV9yvsLB68mMmZBf4A9Kkghvx2cBDZdpZYNGr1tKPy\nWOgyMgidOplrWzZi5uhIx8UrqN61O+0Ab6cmzDvxJbEZN4nNuEm3Pzsw28cfn1od6bN9N3tfGEjY\nooXos7N47st5yOSVukJKQkLiP0KlzsmSkkSvy9Gx5B75uXOJXLuWRvv21fj++y64esh5afdIcvQ5\nLOmxgoaOjQC4eTeGlaHLqGFXk/FtX71Pzu3gIPb49SM+5CjxIUfZ49evQgyNOrPAn5BZs552NB6L\nuxGX+atPV65t2Yhz6+cYGBhE9a7dTfffajmZ7X5/m87D7pwj8PpecvQ5WLlVp8+2Pdh7N+LSimWE\nTp2M0WB4GsmQkJCQKFMqtSFPTBSTVxqP/LvvTgPQc4yKgzf2s04+jdiMm3zcdiZ9avczhZsX+BUa\nvYbpPT7GXGV+n5yqPh2pPXio6bzN51891er1ggWLm4cPV5iCxcOI2rKRv3p1ITXiMt4T36B3wC6s\nqt/fB2Hf9T1MbT2DkV6jsTOz46cz39NrU2fOJ57FwsWFXlt34tC0OVd+/5XgtyZi1Jes74SEhIRE\nRaFSV63ne+QlM+QRESn89dc1WrRwZq98EYv3R5CYncAL9Yfzdov8NvDwW2H8eXodDas2ZmjzFx8o\nK/VKBMc/nm46D1v0HZ1X/FqieJUFVX06Uv9WHPEhRwGoO3xkhWy3N2g0nPjsQy6vXoHK2obOK3/D\nY6DfQ8MXnOrV53JHTsWfYHXYCnpv7sr7raczueX79N68ncCRQ4na/CcGjYaOS1eiUKufVJIkJCQk\nypRK7ZHfuSMa8pJ65Au/O4UgQGyL3wi9dZTE7ASsVdYM8xxRqLPUl3/PRBAEPuvzOQr5/ePVNXdT\nODDmRYxaDY3eFIdAZd6OK1GcypJLK/LHV4e89zZX1q55ROgnT8aN6+we2IvLq1dg792I/vsOPdKI\nAyYjDjDccyTzOn3LhgFbcbZwYd7xr+i/pQfRhnh6/hlAVZ+OXN+5jYPjRmHIySnv5EhISEiUC5Xa\nkBfHIzcKRiKSL7Ph0lpmHHmfLkv7s3lLBDjfJqHGQVO4Nf020M29h+n86NUj7I/YR4c6nehav8f9\ncvV6Dr8yjrSoqzR+ewqtPvsCG4/apISHo8/OLoNUlgzBaCQtKhK1nR3DAgNR5k6e8u9XnyMYSzfm\nvqTcDg4yVe/f3LeHHT06knTmNHVfHEW/3fupUrd+ieR2de/OkRHHGNZgBKcT/qXHxo6svPoLXf/4\nk+rdehAbuJf9/xuOLjOzLJMjISEh8USo1FXreR55rPAv0Mx0XRAEbmXGcTrhX07Hn+J0winOJJ4m\nXZtmCiP/aygYFXQeJWBRpx/VrNxwsHAgJO4oPtU7muTM/vszAD7r88UDhzSdnPkRt44cpEavPrT4\n6DNkMhm1BvoRtmghcYcO4N63fzlq4OEkHP8H7d271Bs1hlrduzNwfxD7Rw3j/PffkHYtig6LlqK0\nsHiicTqzwB8EAZe27Ti/8GvkZma0X/gj9UaNKfVwsSpmdvzUY3nuRDLv8lnwR+y5tovvFn2PfOpM\nYnbvJHDEELqv3YjaxraMUiQhISFR/lRqQ57nka+Jnk/NmAmcSfiXfxNOcTr+FPFZtwuFrW/XgL61\n+9PCpSXuNOHlOeG4eVizbvqr7Ire9sBlOref38rpm//i12QIzWu0vO/9EWt+4eLPS7Hz8qbjkhXI\nFWK1e62BgwhbtJDr27c+NUMevX0LAB6+Yrps69Sj765ADr08muvbt5IVe5Ouv63Hwtm53ONyOziI\nMwv8Te318aHBmLu60mPtJhybNCvi6eIxoK4vz1drx9TDk9l9bSddAzrzxftf4mFmRnTAZvYO9aXn\n+i2Y2TuU6XslJCQkyotKu4xpcGwQ40a6kJqaAaN7glV+7+RqVm60cGlFS9dWNHdpSXPnFtiaVTHd\n/+yzUJYuPce333Zi9GjvB8rX6rV0+K4NN+/GEDzlJLUd6xS6fzs0mL0vDERta0v/PQex8ahtuicI\nAlvaNEWTnMyLF6NQmJmVKI0lxWgwsKm5N0athuFhkbi6OZj0bNBoCJnyFlGbNmDtXovuf2zEztOr\nXOOjz8ri5OefcHn1CgCqduhE19W/o65iV27vFASBjRHr+SjoA9K0qfSs2YuXd1sTu2kL9g0b03Pj\ntjItxEhLP5Y/ko6fDJKey5/iLmNaaT1yn+odcRIUpLbqBZl6hrccSf86vrRwaUlVq2oPfS4pKZvf\nfruAm5sVw4c3eGi4NSd+ITr5GhPavnafEU+/Hs2h8aMB6LJyTSEjDojV6wMGEb74B+IOH6Bmr76l\nSGnxSTh+jOz429QfPRb5PUvBKczM6PDTcmzr1OXM/Dns6t+TLit/w61z1zKPhyAIRAds5tQXn5EZ\nexOlpRXVOnXBoUnTcjXiIH6D4Z4j8XHryLsH32RfzF5OtKjCLGNXUrYc5G+/vjSf8QnmDo4Vsje/\nhISERB6VtrNbcFQQ17x6Q9Vg0MLBE/uxMdo80ogD/PxzGFlZet58sxlq9YNXTMvQpPPNgblYqa15\nr9v0Qvd0GekceGkEmqQknvf/+qFGoNbAQQBc37GtBKkrHdHbCler34tMJqPZ1Bl0XLICQ042gSNf\nIOL3sh0ql3T2NHsG9ubIxPFkJybg3m8Aw8Mi6PbbunKvAShIdZsa/DkwgLmdvkEr6Hi3yUFu9q1P\n6pUIjrzxCoc+e++JxUVCQkKiJFRaQ97OoyMcXWw6T0xL4N0tb+G/9wsiEi4/8Jm0NA0rVoTh5GTO\n//73cGPyU9AP3Mm8w1udJuNsnV/9KhiNBL3xGncvXsBz/Kt4jh3/UBlOLVtjVb0GMXt2YdBqS5DC\nkmE0GLi+YxtmDg5U7dDpkWHrvDCcXpt2oLa1JfS9tzk1e2ape7Rnx8cTPPkNdvbqQsLxY7j398Xv\n6Am6/rIWlbVYnfSwAkZ5IZPJGN/4VQ4MP0qbas+zw+UKqXZyBI0WzfnL/NW7a4WeLEdCQuK/TaU1\n5KmpYKy1GbTinOcNqzYmKfMOCw99TYfv2tDjx04sOfoj8Wn5nd5Wr75AWpqWSZOaYmmpeqDc+PR4\nlhz9EWdrFyZ1eKvQvdNzvyRmz19U69iF52bPfWT8ZDIZ7gPE9bNvBR0qXWKLQcI/oeQkJlCr/yDk\nyqJbVlzbtqPfrv3Y1q1H2KKFHH5lLPqsrGK/16DRcP6HhWxp24LIdb9j792IXlt20nX17/c1PTwt\n6tjVY7vfHtr3G8eKUfkFlpsRZ7igi356EZOQkJB4BEUackEQmDlzJiNGjOCll14iJiam0P2AgAB8\nfX0ZPXo0mzZtKnQvKSmJLl26cO3aNQBu3LjBqFGjGD16NJ9//nkZJuN+kpJkkOIFynRsravwXtdp\nhH8UybIXV9HTszcXbocxc9dHNJvnxdBVg/gt5HeWLD2Lra2aceMaPlTuNwfmkqXNZFr3D7FSW5mu\nR23+k/PffY1N7Tp0XvHLfW3PD8JjoOh5PsnqdVO1+qDH93pt69Sl365AXNt34PrObfw9pD/Z8fGP\n9awgCNzYtZOADm3498uZKMzUtF3wHQP2B1GtiBqBp4FCruDbrj/wiWYIezvDxXpgnmng2vgpnDkS\n8MMLKykAACAASURBVFTjlrc8q4SEhERBijTkgYGBaLVa1q9fz/vvv4+/v7/pXkpKCj/88AN//PEH\na9asYceOHcTFiTOW6fV6Zs6cibl5/rzj/v7+vPfee/z+++8YjUYCAwPLIUkid+7IIbk5yPW4VnHF\nt8lgLNWWDG42lD/GbuTcjAj8B35Ny5qtORJ5kKlz15KcpKFq2yhCYw+g1d9f3X31zhXWnPiFuk71\n+F/rl/LfdfoUIVPeQmVjS7c1Gx576JJz6zZYVK1GzO6dGHW6Mkv7w8irVjd3csK1fYdiPWtm70DP\nPwOoO3wkd/49xV/9upNy6eIjn0m5EM7eob4cHDeKzNibeE98g8HHTuM5drxpKF5F5ZazkSZTP+D2\npwM51dYceaaWf0a9xNQfBhB+J+ypxGnBCX8WnPAvOqCEhMR/iiIN+alTp+jYUeyw1axZM8LC8jOx\nmJgYvL29sbGxQSaT0aRJE86cOQPAvHnzGDlyJC4uLqbw4eHhtG7dGoBOnToRGhpapokpyJ07MnA4\nB4CH0/1Vt07WTkxo9xq7JgUS9Pa/WEcMRKbSEeHyM2PWvEgT//pMC5jCP9ePIQgCwVFBTNnyDgaj\ngY97zUKlED3uzFtxHHhpJEatlk7LV2HXwPOx4yiTy6k1wBdNSsoTaYONDw0m504i7o9ZrX4vCrUa\nn0VLaT7jEzJjbrC7f0/iDh24L1xOUhLHPpjCjm4+3A46TPUevRh0+BjPzZ6Lmd2Dl3etaNT2HcyM\n5z/hl75/0O3bpdh++Q4qgwzPuUeY9FV7Xto9ktPxp55IXIJjgxiwpRchcUcJiTuKX0A/yTOXkJAw\nUWRunpGRgY1N/pg2pVKJ0WhELpfj4eFBZGQkycnJWFhYEBoaSu3atdm6dSuOjo74+PiwdOnSB8q1\nsrIiPb38xiImJcnA4TwAXq4PryoHOLFfR8b/2TvvsCavL45/kpCETZgiylIcOHEj7oGCE/dstdpq\nq3XUUVdt1bqtHdbaah3VVuseKOJAUZHhxgVOQFRAkb1JSH5/RFF/DmSP5vM8Psbkfe89ub55z3vP\nPfd74oV8/nlD+o31ZnfwDvZd28Pm8xvYfH4DNsa2ZCmyeJISQ1Ob5nSv2xMARUYGviOGkPEkhqbz\nFlG1U5d822nb04Nb69cScXA/Vu075v+L5oOIA2oxm/yE1f8fgUBAwylfY2Bnj/+kcfgM6Yfzsh8x\nrO6AUqEg8XYoV1csJTspEUOHGjRbsJiqnbsW1VcoMV7VbPdw6AsOfXlo14aTo4byyXYF/8i96Bru\nRQfrTnzVZDrOVi5FbkN4UhhHIw5zLOIIl55cyH0/TZ5GmjwVpUqJUFBh01w0aNDwgeTpyPX19Ul7\nRYP6hRMHMDQ0ZObMmUyYMAGZTEbdunUxNjZm48aNCAQC/P39uXXrFjNmzGDNmjW55wGkpaVhaJi3\nFGZ+N8a/ICMDMFY78g6Obd7ZjkKh5LffriGRiJg7txVWVvp0dmrL6pxf8L3tyw9Hf8An1AelSp38\npFBlE5JwmXY12+E1bCxxwVeoO3Ik7b6dVSAZUdPurvhVqsQj70OYbvyzQDPlD0GpUPDwsCe6FhbU\n6+X2Rmg7v+NsPnYUVevVYr+HB4HTJqFraUl2UhKKjAykRkZ0+OknnMaPR/QBuQLlBfOh/TGzMmNf\nz56M2JPOVVkt/uEEvg9P0Na2Ld+0+YbO1Tq/8zrIa4xzlDkEPgrk4O2DHLxzkNBnL5curAysqGFS\ng0fJj7gae4XhhwfhaObINJdpDKs/DKlWyYoKlVUKer/QkD8041y2yNNrNG7cGF9fX9zc3AgODqZm\nzZciKTk5Ody8eZOtW7eSnZ3N6NGjmTJlCh07vpxZfvTRR3z//feYmZnh6OjIhQsXaNasGWfOnMHZ\n2TlPAwuqIBQZKX0eWteiina1d7azZ89d7t9PZMSIOojFqteOczJ35p/huwl+dJkua9oD8GvfddQy\nqY3v3Pnc+vdfzJu1oNH3K3j2LLVAdgJYd+vJ7U3rueF5hMpt2hW4nfcRfeYUGbGx1Bo5mrj417PO\nC6rUJKnZgCYLlhA4ZSLpMersf51Kljgv+xGbbj2IT8wEKlZVMZ26TXDddQCfwf1ouC6UrnMmsrn6\nLXweHKPLgy40tmjC5CbT6Wrn/ppDf9cYp2an4PvwBEcjvDnx4BhxmXHqfrR0cLPrRhc7d1xtu3Iu\nOpDmT8xABnsdrxASd5O9d3cx2nM0s33m8FmDzxlRdxRG0uIV0inLaBTHSgbNOBc/+X1QylOiVaVS\nMW/ePG7fVu+9XrJkCTdv3iQjI4MBAwawevVqTpw4gVQqZdSoUXTp8np4+eOPP2b+/PnY29sTERHB\n3LlzkcvlVK9enYULF+Y5iy3oBfPJWDlepqYgkhD53SO0tbTfOEapVNG+/S7u3k0kKGgwtrZvjxAs\n91mc+1ogEDAouwG+I4agV6Uq3Y+eQueVPICCEH32DMf69qDWyNE4L/+pUG29i8Cpk7jz9ya67vN6\nQ6SmsD/MpxfO4d3dFYDefudLVNCltIi/eYPjA3qT+SyWJt9+j3JQO36+tJJDYeodCHVM6/FVk2n0\nqNaboOgAZDJd6uo1AeBhSiTHIrw5GuGN/2M/5Ep1oqOlXmVcbd3oaudGm6rt0dF6vWjNEY9uALjt\nPwxAVOpj1l37nS03N5EqT0FPrM/wOiMY22AcVQ2sS2ooygwaB1MyaMa5+ClyR17aFPSCcR0WzFXb\ntkgNdXk4M+atxxw+HM7IkccYOLAmq1e/W4LU8/o+etVXr5luO7wK1bglgAr3g8cwqd+gQPa9ilKh\nYFeDmiAQMuDa7SLP6FYqFOys54BApPXW9gv7wwxe/vJBB4EAp+mzCtxWeSLp3l2O9e9FetRjGkyZ\njtOMb7idcItfLq1k373dKFVKHGTq0qsG2vq0r9KJI+HehMbfzG2jvllDutq509XOnQbmTm99sI3x\n9+PK0oU8PadODq3k0hqn6bNyH8iSs5LYEvIX666tISYtGpFAhIdDP8Y3mkQ9s/olMBJlA42DKRk0\n41z8aLTWn/NErr5Zmhm9fSuYSqXi55+vIBDAxIlO722rV/0+xPj7kZ2UhGTuOtLS02i/4e8iceIA\nQi0tbNx7cufvTTw9F4hlPreG5UXM2TNkxcdTa9RnxbLtS1bbMVeNLcJzXx5HVxyMHGrg7nmEY/17\nce3HFchTU2n2/VJ+d13P9Oaz+MZvJicij6FC/ax8JeYKYqGYTjaudLXrRhc7N6z0q7y3j6R7d4n0\nPkT8jeu579Wb8NVrURVDqRFfNprEmAZfsPfuLtYEr2LP3Z3subuTdlU7ML7RJNpV7VDoUrAaNGgo\nm1TYlNdEofrGV8W46ls/P3XqEcHBsXTvbk/NmnlvibqybBFnJ3xO2sNInL6enauVXlTY9vIA4MHB\nohcdeeFc7Xr3LfK24XVJ1ZKWVy1t9G1scTt4FFltR0LX/U7glAkoc3KoZlSdbT12sbPny//PRa2X\nc3v0A/7tsYeR9Ua/04krFQoeeB3kWP/e7HdpQui630GlQuao3n3hP+Fz5Klv5mRIRBIG1x7G6UFB\nbOu+i1ZWbTj9yJeBBz3otKsNu+/sQJ4j1wjLaNBQwaiQM3KlEjJ1b4BKgIP52yuY/fzzFQC++urN\nOuKvEuPvR/DyxTwNCgBAamqGhXPRbzWydGmN1MSEB4c8ab5oOQJh0TxjKeVyIr080alkiUXzvJML\nNeQf3UqWdN13GJ/Bfbm7dQvytFTa/PYnQrGYc9GBTGs6Ez09KYnpCeiL9d/ZTsaTJ9z55y/ubNlE\nerRaWKmSS2tqj/oMlSIH+779OTd7OrfWr+XshM9pv/Hvt86yBQIBnW270tm2K8FPL/PblVUcDNvP\nOJ/PWBy0AC2hFha6Fhzqe7zYxkSDBg0lR4V05AkJKpBdh4zK2BjZvPF5UFA0gYHRdOpkTf36Zu9t\ny7xpcwSvbKFy3b4H04aNitxmoViMjXsP7m7dwtPz56jk3LJI2o32O01WQgK1Px1b5tXUyjPapqZ0\n2ePJiWEDidi/F0V6Ou3Xb6G2iSO9HPpgbm7AhsAtb5ynUql4EhTA7U1/8uCQJyqFArG+gbrozshP\nMa7t+NrxzeYvJiHkJpFenlz/+QcafDX9vXY5WTTmz65/EZEUzryAORwJP4wSJRHJ4VRfX5U+Dv35\nvOF4HIxrFOl4aNCgoeSokKH10MgY0E6ArEpvDV++mI1Pnvz+2bg8LY2THw0i5swp9KxtqDdxCg+P\nHSkWm+GV0qaHii68nhtW71U8YXUNL5EYGtF5+16s2nfk0bEj+AwbgLula+7nr4rMyFNTuLVpPZ7t\nW3K0tzsR+/di5FCDFst+ZMC1WzgvXfmGEwf1A1/79VvQq2qtLtJzzPuDbLMzsucv920c6PPy+JTs\nZLaEbMTl3yY4b23Et/6z1Vn0OcUvF6xBg4aio0Jmra/e78OC833hWQd2zZ1MO+uXGelXr8bi6roX\nF5fK7N/f651tZCcncWLoAJ6eD8KkoRPdDh5DpK1NhOe+YlsHzsnOZmddB7T09Oh/+Wahw+tKuZwd\ndasj0tZhQHDoO9vTZKEWLTlZWZwe8wkPvQ9h3rQ59SdPxayKBTp1m5BwK5Tbm/7k/s7tKNJSEWhp\nYdujF7VHjcGiRcsPTkiLuxaMd48uCMUSuh/1xcjhw2bUy8+/3GGQocigpnEtjkZ4c+rhSdIVauEn\nI6mMTjad6WLnTkfrzsi0y4esruY6Lhk041z8aLLWgZsxL7b36LwxI//ll7xn45nPnnF8UB/ir1/F\nvm9/Wv+6NreaWXEmc4kkEqzdu3N/+1aeXb6IedPmhWov2u8U2YmJOI4ZUmRr7hryRiSV0n79Zvwn\nfkHYnp2cGTMKQxtrxCZmPAk4C4CuVRXqTZhMzWEj0KlUKd99mDZwwuXHX/Eb9xknPx5M9yMnkRga\n5Xnei1A/gOe9ffRy6MMQx+FkKjIJiPLjaIQ3xyKOsPfubvbe3Y1IIMK5sgtd7NzpaudGNZlDblsv\nEuZaVWnz1r40aNBQMlRIRx6W8NyRiwVU1quc+/6dOwl4eYXTqJE57dq9PWM4Leoxxwf0JunuHWp+\n9Aktlv9YomvLdj17c3/7ViIOHii0I8/VVteE1UscoViMw9CPiD57hownMcTfugWASQMnGnw1Heuu\n7oWW463WfxBx168R8vuv+I0fQ8fN/+b5wPZqeP/V19pa2nS0caWjjStL26zkZtwNjkV4cyzCG/8o\nP/yj/PguYDYOshp0sXPHza4by88vRiAQaBy5Bg2lTIUMrdeZ68KzzDC0RR2JXLot9/3x40+ya9dd\n/vqrC926vVkRLTnsPscG9CbtYSR1x0+iybcLSnzvbU5WFjvqVEcik9Hv4vUC95+fML0mVFZ8JISG\n4NlOvVug49ZdWLsWbQEZpUKBz5B+RJ/2peHUGTjNmFOk7QM8SX+CT8RRjj7w5sxDX9IVr0v8NrZo\nytyW80vdoWuu45JBM87FT35D6xUu3irPkROvuA0J9ahk9vLrRUQks3fvPWrXNsbNze6N8xJCQzjS\ny420h5E0mjW3VJw4qMOy1l3dSXsYSVzw5QK3E33Gl+ykROx6emjC6qXIg4P7aThtJi2/+65Q/5/v\nQqilRbt1m9C3tePqymU88DpY5H1U0q3EsDofs8X9X0JHhbOt+y56VX8Z5bny9BIbrq8jKDqQMj4v\n0KChQlLh7vD3Yu+iFMghvgFWlSS5769eHUxOjopJkxohFL7uoGMvX+SohzsZT5/QfPFyGnw1vVRV\nsGyfr8M/OHigwG0URclSDYVHVtsRp69n02revGLToJcam9Bx879o6epy9suxJNwKzfukAqKjpUNn\n267UNK7JV02m427fA3NdCw6FHaDXvq503d2e3Xd2kJ2TXWw2aNCg4XUqnCMPibmhfpFQH9tKavGN\n6Og0tm+/jZ2dIb17V3/t+Bh/P47160V2UhKtVv2O46efl7TJb1ClfUe09PSJOLi/QDOcnKwsIr29\n0KtqjVmTZsVgoYYPpaRU74zr1KXVr3+gSEvF9+PBZCUmFFtfoE6am9ViLpvdt7Go9TIOeHjTzb4n\nV2ODGefzGU3/qc/Pl34gLiOuWO3QoEFDBXTkoU9C1C9Sbakiq4S/fxTffONPdraSiROd0NJ6+ZUf\nHT+Cz5B+KLOzaPfnZhwGDyslq19HpK2NdVc3Uh9EEH/9ar7Pjzp9EnlyErY9PTT62v8h7Hp6UH/y\nNFIiwjkzdhTKnJxi6+vVRLneDn1padWKv9y3cm5YMGMbjCM1O5XF5xbQaIsjU09N4nb8rWKzRYOG\n/zoVzpHnzsizLaisZ8Xixefx8grHykqPgQNfyrWG79/DyRFDQSCg4987ilw7vbDY9nihvZ7/8Lom\nrP7fxWnGHKp07kKU7wmuLF5Q4v3bGdnzfeulXB0RyvetlmChZ8nfIZtos705gw724WTkcc06ugYN\nRUwFdOQhkF4ZcuLZMFXAhQtPUCpBKhVx4cITAO78/Rdnxo5CS0cX1x37qdKxcylb/SZVOnZGS1eX\nCM99+brx5WRm8vDIYfSsbTBr1KQYLdRQFhGKRLT9fT2G1apz49efCN+/p1TsMJAYMrbheM4NvcIm\nt620tGqF78MTDD7Ujzbbm7P55kbS5emaAi4aNBQBFcqRJ2YkEJX0COIagGkm07+rk/vZr792oFUr\nK26u+ZXAqRORmpjQdd+hItM0L2q0dHWp6upGSngYCSE38z7hOY9PnUSekqzOVteE1f+TSIxkdNiy\nHbG+Af6Txr1WArWkEQlFdK/WkwMe3vgMOMOAmoMJTwpj+unJNNriyJcnxrIwaF6h+/F/7MepiFOF\nbkeDhvJIhRKEuRXzPFs3oT7oxnLZVwd9fbUi2+nTjxCfXM+1H5ejW9kK110HkNWsVYrW5o1tz95E\nHNjLg4P7MKlb74POeXBgL6AJq//XkdWsRevf1uE7Ygi+I4fS/egptE1NS9WmBuZO/NZ5Hd+2XMCC\nwLnsu7uHhKwEHqc+wvJ3Y8x1zKhqYIO5jjmmOmaY6Zhj9vzvF/821zHHRNsUsUj8WtsrLixBLBax\nq3vRb7/ToKGsU6EceciT5zPX+AZoVX2Eg11jUlNDaN1ID9FlL66dWIm+rR1d9xxE38a2dI39AKp0\ndEWko0OE536cZnyT5wxbkZFB5JHD6NvYYur0/oIwGio+Nu7daTh9FldXLOH0mJG47thXaDW5oqCS\nniW/df6TMQ3G4bq7HQD2htVIladwNfYKCqUizzZkUhlmOuaIhWKepD8hPlOdHd9xRyu+dfme9tYd\ni/U7aNBQlij9X3UREvJCYz2+Pkb1w7CzU2tPa98+iWn6bmS1HXHduR9dy8rvaaXsINbXp0pHVyK9\nPEm8feut1bBeJcr3BIq0VOw++VQTVtcAQMOpM4i/cZ2H3oe4OP8bmn+/tLRNyuVohDfTms4E1DXU\npzebhUqlIikrkWcZz3iWEfvK37HEZT7jWfqzl68zYonLiEPFyxySG3HX+fjwYJpZtsClSmtaVWlL\nY4smSESSd5mhQUO5p0I58tCYmwgRoUx0pF72z+z5ahHQAIv0e2jp6dNo1rflxom/wK6XB5Fenjw4\nuD9PRx7hqQmra3gdgVBIm9/W4uXeidC1azCt14Dqg4aWtlnAmwVcQO3QZdrGyLSNP6hGeo4yh++D\nviNdnk66Kpn7cWFkKDLxe3wav8engUXoaOnQzNKZ1lXa0KpKG5zMG78RmtegoTxTYRy5SqUi9EkI\nRgIHEpRSVE7VyRLaQ3gMlYnGddc+LJq2KG0z801V164IpVIeHNyP0/RZ7zxOkZHBw6NH0Le1w6SB\nUwlaqKGsI9Y3oOPmbRzq0oGAaZNQZGZg5FATy1alq43+rgIu+UEkFNHYogm9HPpgbm7AhsAt9HLo\nQ1xGHIFR/vhHncH/sR9nHvly5pEvALpaerSo7EyrKm1pVaU1Dc0boSVU3wo1Fd00lEcqjCN/mBhJ\nalYKleXqveLWlbS5eD4SEUJsLcVE+Z4sl45crG9AlQ6deXjEi8Q7t9+ZoPf4pI86rD56jCasruEN\nDKs50HbtBk4MHcD5OTMwbeBEt8M+pW1WkfC2BwJTHVN6VO9Fj+q9AIhNjyUw6ixnH58hIOosvg9P\n4PvwBAB6Yn2cK7ekVZW27L+7Gz2xPgf6eJf8F9GgoYBUmO1nL9bHBclqR2dTSY+IOC0seErNQYOK\nTee6JHghVvPg0LvFYTRhdQ15oaWtg761DcrsbGIvnsfLrQMx/v+NPdzmuub0cujD8nY/cXbIBa6P\nvMs61018XGcUlnqWnIg8zoLAuVx7dpXAaH+ctjiy+86O0jZbg4YPosI48tDnjlz+zBFQYoghWQoh\nlYmmisy4WHWuixvrru4IJZJ3qrwp0tN5dPQIBvbVMKnXoISt01BesGzVho5/v3ROSffvIdT6b64V\nV9KthEeNfvzQ/mcCh17m2ojbzHWen/t5VOpjxvl8Rn/P3hy8vx95jrwUrdWg4f1UOEeeFV0fdOLJ\niFIXTLEimmoH95emaYVGYmiEVfuOJNy8TnLYvTc+f3ziOIr0NOx699WE1TW8lxdlVau6uiFPTuZo\nvx6E7dlZ2maVOpZ6lclQZDCt6UwmN55G92o9ca7swplHvow++jFOWxxZFDSfB8kRpW2qBg1vUGEc\neUjMTQykhqTH1AS9p8SeeghAXaLRvXwRk8Z1EfudLmUrC45tj+fh9bfMyiM8n2url+Oog4aS4UVZ\n1U5bd9Jg8jREUm38vviUqz8sLRUN9Bh/vzIT3q9t4sjXzWcz2/lb+jj0x7PPEfwGn2dMgy/IVmbz\ny+WVNP+nIYMO9sEr7OAH7XfXoKEkEKjKeAWD2NiUPI/JlGdiP78yjao05eK8ALA5Swfz6/hezGAf\nC/BA3UZ2x84k/74elbFJcZtd5GQlJrCjTnWM69Sjp8+Z3PflaWnsrFsd3cpWeARcKtCM3Nzc4IPG\nWUPBKatjnHj7FieGDSA18gHV+g/C5afViKTSEuvfu5cbORkZdPM+UWixmuIc4wxFBp739rElZBMX\nYs4BUEnXkmGOHzG8zkiqGlgXS79lkbJ6LVckzM0N8nV8hZiR3429TY4yh2qyeqASomOUwq07KeiR\nihMpKOrURWFfDclJH4xd26F1Lbi0Tc43UpkxVm3bE38tmJSI8Nz3H584hiI9HbvefTRhdQ35Rlar\nNt0On8CsSVPCdu/gWP9eZMYVfw3x6LNnONDWmadBAcRdvcJW+8oEfj2F7OSkYu+7IOho6TCo9lC8\n+h7n1KBARtcfQ4Yigx8vraDJ3/UY5jWAoxHeubN0TTEYDSVJhXDkLzLWK2urBVP0DNKJTtaiMtFY\nASk//krarG9Jmz4L4cNIZN1dkf77TylaXDBsn4fOHxzyzH0vt2Rpr76lYpOG8o+OhQVd93ph26sP\nT88Fcti9I0n37hZbfwmhIVz/eSWJt0Jee//OX+vZ7VSH83NnkvIgotj6Lyx1TOuypM0PXB1xi186\nrKFxpSYcf3CUjw4Pounf9VlxYQkLg+ax4sKS0jZVw3+ECuXItXPsADAkEQAHYhBWd0DRqAnZHn1J\nnz6L5K07UWnrYDhpHPpTJ0JmZmmZnW+s3bohEImIOKh23vLUVB75HMWoRk1kjnXyOFuDhnejpaND\nu3WbqD95GikR4Rzu1qnI164z4+II+vorDnZwIfqML/p29tT65FMaTpuJ42df0HjOd2jp6RG6dg37\nWjjh+8lwngQFltn65XpiPYY4Dse730lODDzLiLqjic+MZ8WFJVx6coGAqLN03d1BMzPXUOxUCEce\n+rxYSnayFQBGCY8BcCKKrAGD4ZWQc3bnriQcP428XgN0/v4LWa+uCB89LHmjC4C2iSmWrdsSd+Uy\nqQ8jeeRzlJyMDOx6acLqGgqPQCik8exvabXqdxRpaRwf6MG97VsL3W5OdjYha39jn3Mjbv+1AYNq\n1em0bRdNvpmH87Ifcfp6NmZOjag/aSr9Lt2g9W/rMK7XgEgvT4706oqXWwfC9u5CKS+7W8DqmzVg\nRbufCBl1n+nNXiowXn16hb13dxGdGlWK1mmo6FQMRx4TQlWZNU+fqpNllHHJALQimsz+g944Xmln\nT6LXcTIHDUUcfAXjzm0Qn/YtUZsLil1PD0AdXn8RVrfVZKtrKEIcBg/Dded+tPT08J/4BZeXLECl\nVOa7HZVKxaPjR/Bs58yFuWrn1mzhUnqfDqJq566v7bJ48VokkVB9wGB6HD9N1wPeWLv3IC74Cn6f\nj2ZPswZcX/UTWYkJRfNFiwF9sT4qlYppTWfSu3pfZNrG/B3yF87bGrEwcB5JWYmlbaKGCki5z1qP\nS4vDcZE9rrW6orj6Lb7/uGAnmcKDbEueNtmPyvvou09WqdDesgn9OV+DQkH6zG9InzgFhGX3+SYj\nNpZd9Wsgc6xL8v276NvY0tvvfKFm5Jos1OKnPI5x0r27nBjan5SIcOw8+tLql9/R0tH5oHMTboVy\n8dtZRJ06iUAkouaIUTh9PRttk/zXRE8Ou0/o+j+4t+0fFOlpaOnqUn3wMOqM+QLDag65x5WVMfa8\nty9XKnbf3d2ky9NZfmEx0WlRyKQyJjaeyuj6Y9DR+rCxLGuUlXGuyOQ3a73cO/Kz98/Qd0MPJrab\nwsmtfbl7pC4CfsWEZG6ttCHzo5F59qF1+SKGoz5CFPWYLLdupPz6ByojWRF9g6LnaL+exDzfE99w\n2kycvp5dqPY0P8zip7yOcWZcHL4jh/L0XCDmTZrRYct2dMzN3318fBzByxdzZ/NGVDk5WLXvSNMF\nS/Ks3PchZCclcuefLdxa/wdpjx+BQIB1V3fqjB2PSqVCZqyHTt0mhe6nOMhQZLD++lpWXf6RpKxE\nrPSq8HXz2QysNSS3YEt5obxey+WJ/9z2s5CYGwDUsaxLfJwW1viSiQ61BTFk9fL4oDYUjZuS9Dw9\n+wAAIABJREFU4ONHdpt2SI8cRtalPaKQm8VpdqF4IQ4DmrD62xD7+yEuIyIj5R1tU1O67PakWv9B\nxF66wGH3jiTevvXGcUq5nJB1a9jXohG3N/6JgZ09nbbupPOOfUXixAEkRjLqjZ9I3wvXaLtuE2aN\nm/DwyGGO9unOyeGDODZmDI9OHCP28kVSIsLJTknOd6JccQnU6GjpMKHRZC4Mu8qERl8RnxnHZN/x\ntN/RksNhh4o9oU+zHa5iU+5n5F/t/ZKtF7dwemIQPfpJqX13Jxcw4SvrEGZd+iV/nSkU6C1diO6q\nH1Hp6pKychVZ/QYWwvqiJ8bfj8uL5hN78TwAlVxa4zR9VqFKUla0J2wjj24AJO0/XMqWvKS8j7FK\npeLaymUEL1+M2MCQ9hu2IBSrddoVGelc+HY2yffuIjGS0XDaDGp98hkiiaTY7QrdsI6rPywlK+7Z\nWz8XisVIjU2QmpoiNTZB28QUqYkpUhMTpCYv/m2C1MQUbRNTzn45FoGWFm7FfO1EpT7mhwtL2Xbr\nb5QqJU0rNWduy/m0tGpVLP19uswFgPUzAgrdVnm/lssDRR5aV6lUzJs3j9u3byORSFi0aBHW1i9V\njPbv38/GjRsxNDTEw8OD/v37o1Qq+eabbwgPD0coFDJ//nwcHBwIDQ1l7Nix2NnZATBkyBDc3d3f\na2BeF0zXNe25EX2diHkx2DZMoFnstwSqGvHPl0Z0+XbwBw7D60gOH8JgwucIU5JJ/3QsafMWQQnc\nlD6UhFuheLZVl2Tt7Xe+0JXdKsoPU+zvh+6KJUgCzgIgb+5M2qy5yEu57jZUnDEO27MT/0njUOXk\noFelKtnJSWQnJiIQCp+vg89B2zT/6+CF4dXfg+OYcQhEIrLi457/iSfz+d/ZSR+eaCY1NcNh8DAc\nx3yBXmWr4jKduwl3WHxuAV5ham2IzjZdmOM8j7pm9QrcZkp2MuFJYYQnheEbeYLjD47Sb81TAK7N\nac30ZrMKVW+9olzLZZkid+THjx/n5MmTLFmyhKtXr7J27VrWrFkDQEJCAv369ePAgQPo6+szcuRI\nlixZQkhICL6+vixatIjz58/z119/sWbNGnbt2kVaWhojR478YAPfd8EolUqqzbfCzrQavhP8sbV9\nRs3M77hGQy4FDcC6WsGlWEX372L4yXC0boUib9aC9M/HozIxLRNOIXj54pf/EAhwmj7r3Qd/ABXp\nhym6FYrJ85t6yoLFZH7+ZSlbpKYijXHo+rVc+HYWKoVaxUxiJKPp/EXUGPpRqdjz4vegqyclPT37\nnb8HpUJBVkKC2sEnxJMZp/47Kz6OzLg4UiLCeOjt9cZ5stqOWLXvhFWHTli2bIVIW7vIv8OlJxf4\nPvA7AqLOIkBA/5qDmNF8Dg9TIgHecLxJWYm5zjos6X7u6/Ck+zzLeBmdqBYO7ifB7vkOW4FTDbp8\n97MmglfGya8jzzPL4tKlS7Rpo/5Pb9iwITdu3Mj97OHDhzg6OmJgoO60fv36BAcH061bNzp27AjA\n48ePMTIyAuDmzZtERETg4+ODra0tc+bMQVdXN18Gv0pEQjjp8nTqWNYlJiUO+8ybxGCJnjCbqvbG\nBW4XIKd6DRK8T2Iw5Uu09+3BMPgyOTVrk+DrX6h2iwJZbcfc7TovCqZoUKO9ZdPL1/t2lxlHXpFw\n/HQsBvb2nBjSHwC3g0eLbB28ILz4PZibG3Bhw5Z3HifU0kLH3PydyXrByxdjUrc+KiA7IR4D+2pE\nnfQhJtCfkD9WE/LHakQ6Oli2bIVVh05YdeiMUY2aRaLh0KRSM/b19uJk5HEWBs1n153tHLi3F1Md\nM/TF+vSp0T/XYUckhRGX+aaMrkggwsbQlgbmTtgbVcPesBr23apx9+JEIAaAfTbhuNSxLLS9GsoW\neTry1NTUXEcNoKWlhVKpRCgUYmdnx71794iPj0dHR4fAwEDs7e0BEAqFzJw5Ex8fH1atWgWoHwQG\nDhxInTp1+OOPP/j111+ZMWPGe/t/35OJ38MwAJpVb8zTtDTsOMUtKtHUXgsLC8O8v31emBvAhPFw\n/SqCe/fQunkd8y5t4aefoH37wrdfULNGf/zW14VqM59PgGWWjJczBXHs0zL1vcqSLYXlzq3rtPzu\nOwCenfSmZpvmpWbLq7+BZoX4Pdg0b0ytAQMAuL1rl/r1nBkoMjN55OdHxNGjRBw9yuOTPjw+6QPM\nwsDaGruuXbF3c8OmUye0ZerdLpGnTqnbzOd9YrBFPwY26cPck3NZGbiS6DS1kMzyC+qog5ZQC3uZ\nPS2sW+Bg7ICDiQM1TGvgYOKArZEtYtHr9eWD//iDqJsx6Fpakv70Cd29FEx07M3huZcx13v37oO8\nqEjXckUgT0eur69PWlpa7r9fOHEAQ0NDZs6cyYQJE5DJZNStWxdj45cz4aVLlxIXF8eAAQM4fPgw\nnTt3zn0ocHV1ZeHChXka+L4QTtCdiwDY6Ffn4sX7yLiKCjfquDgUXeinXlNEG7fmhmuVYWEkahuS\nU0FCS2J/P2QyXWLL6Lad/CILCUVLJEJRrwHiq1d4FhqOysystM2qcOFIiXW116JCZeG7FXaMTdq7\n5Z7/6msAPSdn6jo5U3fGd6RFRxF16iRRJ32IOn2S6+vXc339egQiEWaNm1KlQycivb0Q6+vjdsC7\nQLZMbjCTjpXd6bxLHQ1d2W4Vbaq2o6qB9du3q+VAYnwm8FJyOvHObXynTEFLV5duR0/x9FwgZ8Z8\nQpc/HtHXuAvbPj6Gtlb+lwkq2rVcFiny7WeNGzfm9Gn1nuXg4GBq1qyZ+1lOTg43b95k69at/PTT\nT4SHh9O4cWMOHDjAunXrAJBKpQiFQoRCIaNHj+b69esABAYGUrdu3XwZ+/+80FivY1mPR6fPo0Bd\nOaleg0qFavf/kXruI23aTLLcuiFMTsZw6AAEJVAhqiTQXbEE5s0rbTOKBGHkA8RXLiNv047sbj0A\nEAeW/lJIReRtqmz/FfQqW1FjyHDa/fkXg0LD6eZ9Qi0z27gpsRfPE7x8MfHXr/Ik0B/vnl0LvJ3t\nSLgX05rOZFrTmcSkR2NnZP/Be85zsrLw+3w0ORkZtF69Dr3KVth79KPRrLkYJ0GjVcFM9v4UpSr/\nin0ayh55XhWurq74+/szeLA6A3zJkiUcOnSIjIwMBjwPQ/Xp0wepVMqoUaOQyWR06dKFWbNmMXz4\ncBQKBXPmzEEikTB//nwWLFiAWCzG3NycBQsWFMr40JibyHRkWBpWJu1iMDFUBqBOnaKtN66o7Uj2\n85uVwchhaB8+iNHIoSTu9oQSrN1clIj9/dBdvhjJc0dn5NGN9OmzykQyX0GRPq8Kl9XTA0XN2ugB\nkgA/snv2fv+JGjQUEKFIhHmTZpg3aUbDaTPJTkrk3r9bufCtOuFOoCXCwtmlQG3XNnHMVYjzvJe/\nXJgrS74n/sY1agwfgW2PXrnv1588jYT7d2HndpJ+8GSJ6QLmuMwrkH0aXufFA1thEgkLSrndR56W\nnUa1+Va0tGuFp/taZrkOwzeuOfeoQVjYJ+jrF9N2MaUSg89Hob1/L5l9B5Dy+/rXirKUFwQpyRgO\nH5TryONPnCWnfoNStqpwyNw7ohV8hbgb91AZGGBWw5ocO3sSTgeVtmmacGQJUFbGOHj5YlRKJWG7\nd5IaGUHdcRNpOi/vZcSiIuq0L8cH9MawWnV6+Pgh1td/7fOc7Gy8B/QkLjCQUy7QefFqhtX58NyC\nsjLOZY0jz/UrikKD4D+j7Hbn6S1UKhWOleog3bMTWeoTorCikoV+8TlxAKGQlFV/IG/WAu29u9B9\ndStYOUEYdh+Zeyckgf6onmtn68+eXspWFQ7ho4eIL11E7tIGlakpSCTIm7ZAKzSkwiyDaCgfyGo7\n0mjmN/Q8cQYdS0turlnF3a3vzqYvSjLj43JFbdr8vv4NJw7qwjSum7ejY29H+wDY+eNETj8sH0Wj\nyhpKhYLbWzayt4UTTwLO8iTgLEc8uhWLOuD7KLeOPDQmBFBLs7J9K9pZqaSjR81aBc/E/GC0tUna\n/C85tnborVyGdMe24u+ziBD7ncbYrQNad26T1bkLcddug7094vNBaF26UNrmFRjpoQMAr8nyylu1\nBjTr5BpKlhc5AxIjGW77vZEaGxM4fTIxz4WKiguVSkXAVxPIeBJDo5nfYNbo3QmsUpkxbtv3IzI2\novchJQtXD+FWfGix2lcRyE5K5NGJY1xZ+j1H+/bgX4eqBE2bTEp4WO4xzst+LPHwerl15C801uul\niIm+f4/o5+vj9esXbv/4h6IyMyNp226URjIMpkwo+9reKhXaG9ZhNNADQVoaKT//RvK23eriMJvU\ne68NvhwL6emlbGjBkB48gEooJKtbz9z35C4vHHnx3kA1aHgXhtWq037TVgQCAac+GUZy2P1i6+vu\nP5t56H2ISi6tqTt+Ut622Vejy5ZdiERa9NuWzoQNvXmS/qTY7CurvEtfX6VSkRwexv0d2wicOokD\n7Zz5t6YtJ4b059qPK4jx90Pf1o6aH32CtXt3an86lgbTZpaKtkf5KrvzCi9m5A1PXuKKCKJz1I68\nceOSk4fMqVGT5L+2YjTQA8NPhpF4+AQ5DjVKrP8PJjsb/dlfo7NlI0ozM5I2bkXh3PLl5+3akTFm\nHLprf0NvyQLSvl9aerYWAGHUY8QXzpHdui2qV8Q+5I2aoNLWRuJ/lrT3nK9BQ3Fi6dIa5xU/EzB5\nPCc/GkS3wz5Iiri6YtK9u1yYOxOJkYw2v61DKBJ90HkWLZxp8+ta/D4fTbd1MYwx7cu/Hx1HV1xw\noa68KM2ksLcRvGIJAK5NmxN3LZin588Re+EcTy+cIzP2ae5xWrq6WLZqg0XzFpg3a4FF0+a5/48R\nnvtKVaSrXDpylUpFSMwNbI3tMN/kyQORkKicKgDUq1eyOs/yVm1IWbkKw4lfYDSkHwneJ8vEvuUX\nCOLiMBz9EZKAsyjq1ifp7+0oq1q/cVza7G+RnDiGzrrfyXbvkTubLQ/khtV7/l+1O6kUebMWSPxO\nI4iPQ1WAWtgaNBQFNYZ+RNKd29xcs4pTn46g8797EGoVze03JzubM5+PRpGeTrv1v6NXpWq+zq/W\ndwAp4WEEL1tE01+v86XJJ/zZaxsi4Yc9DOSX0/Ono8zIZOCJ8yVSWOddxPj7cWXZIp4GqQvJ/GNj\nAa/kfutWtsKud18smrfAorkzxnXq5RYK+n9KeztmuQytP019Slx6HHVF5mQ9iyUlW0kk1UAgwta2\n5BWHsgYPI23K14geRGA0YghkZuZ9UgkgCrmJcdf2SALOktWjNwmHjr3ViQOgo0PKr3+AQIDBxHEI\nUstPVqr04AFUAsFrYfUXyFuqq0mJgwJL2iwNGl6j8dz5WLt1I/q0L+dnTy+y0qXBSxcSfy0YhyHD\nC+xEGkz5GrsBg7B5DMY/ebPAf26R2PYqj0/6sKdZQzKDQ8i+Hca26lW4vGQBKmXJ72VXqVRkxj0j\nNfJB7ntGDjWpNeoz2vyxgX6Xb9I/OJR2f/6F42dfYNqw0TudeFmgXDryF+vjDSNTeATkICQeQ6Q6\nMkSi0vlK6TPmkNl3AOIL5zCY+DmUwsX5KhJvL2TdXRFFPiBt+iyS128GPb33nqNo0oz0iVMQRUag\nN6/of8jFgTAmGq3zQchbtkJV6U0hoBf74sUBZTyHQUOFRygS0WbNeozr1OP2Xxu4tWFtoduM9jvN\njd9+wcDOnuaLlhW4HYFAQOsfV2PaogUNQiHix9VsurG+0PaBulb9nS2b8J34GakPwnPfl8uzuP7T\nD+xq14wHx72LvSb7C56eP4d3d1dOfzqC9OgoTBs1oe64idh59MV56Uqq9R2AflXrItHQLynKZWj9\nxfq408X7PDA0IjZZGxUCjIyLdt0pXwgEpPz8G6LHj9Dev5cc+2qkz/q25O1QqdD9ZSW6S75XZ9dv\n2EL2/4ec30P61BlIj3qjs2UjWd16IO/YuRiNLTwSL08EKhVZ7xB90ayTayhLiPX16fjPDry6duDC\nNzMxrFadKh1dC9RW7lYzoZA2f2xArF+4aKRIKqXz5u14urWjo38ku3+eis1cGzrZdilQeyqlkvD9\ne7iydCGpEeEoxEIeWkOENcjFoJ0JehnQ6NpdTg0bxNMaBmSO6kyt1m40smhCdZkDQkHRTcySw+5x\n6ft5RHqphaNse/SmUksXHD/7AijfBajKpyN/opZmbfBETqC2No9Tq4ISKlcuWkW3fKOtTdJf2zB2\n74jeTz+QY1eNrCHDS67/jAwMvhqP9t7d5FSpSvKWf1HUb5i/NqRSklevxbhrewy++pKEM0HqzPYy\nitRzPyqBgOzuvd5+gLY28ibNEAecRZAQj8q4lK8RDf959Kta03HzNo706c7pzz6h22EfZLVq56sN\nlUpF0LTJpEdH0WjWXMwbNy0S27RNTHHbvh/Pru3ocyiFRWbDqTTtBPXM6ufLtodHvQlYOIusO+Hk\nCOFcM/Bpq6TJU1O0OzlTS+YAp69i28uDWxdPoLf5FNY3UmDWPi7U3seCjpBexYAG5g1xsmiMk3kj\nGlo0ws7QPnem7P9YHWXLq7Z65rNnXF25lNubN6JSKDBv2pym8xZh0bzFa8eVZ6nhcunIQ2Juoq0U\nUiVZSRxPua/fAVKgZvWi1VgvCCpTU5L+3Y3MvRMGUyeirGqNvE27Yu9XGB2F4cdDEF+9grxZC5I2\nbUVlYVGgtnLqNyB92kz0li5Ef84MUlYXPgRYHAiePEEcFICiuTNKy8rvPE7u0hqJvx/ioECy3buX\noIVqxP5+INOFMlKY5sVWyfIsx1veMW/anFa/rMHv89GcGDaQ7kdOop2PJNl72/7mwaEDWDi7UG/i\nlCK1zbCaA65/7+JIvx4M3JrJBBMPto3zo7K+VZ7nXj++l/MLv0Er9BFK4HJDuN6tMu6tPsan1hCu\nx159KTtrsU/9uu4oGAGR/qcIWjCLelduUve2gDvNBexpeZaAqJfbR2VSGQ3NG+Fk0Zgj4V7oSwzw\n7nfirbYoMjIIXbeG66t+Qp6SjIGdPY3nzse2R+9yFTb/EMqdRKsiR4H9PEvqPsnmn5BaeN25zQ8G\nU3mSYsm8eZ8yblzxZFrmF3GgP0b9e6HS1SPR6zg5NWsVW19aly5gOGIooqdPyBgynNTlP+VLA/6t\nkosKBbJunRAHXyFp87+l4gDzQnvjnxjMnErqomVkPA+PvQ1xwFlkHt1IHzuuVLbWGXl0QyIWEbvr\nYIn3/TZkPVxRibRIKmBlrrJKeZQODV62iKsrl2HRoiVddnsi+oDfbdL9uxzq1AaBlphepwLQf1cC\nayEJ270Dv3GfES8Dnxl12PGxD/pi/TfGOVORyaHDvxLx42rMQxIACHEUIh/piofreFpXafvBIXKV\nSsWjY0e4vHg+iaEhCKVSjAZ253HvOgRnhhIce4XwpLDXzpGKpLS0aoWHQz+crVyw07cjbNd2rixd\nSHrUY6QmJjScOoOaI0aXapZ8fsivRGu5c+R3nt6m9c/NGHkHBqnaccPvNLMki1Bkm7Bx4wh69FCU\nkqVvIt21HcPxY8ixsSPB+8Rre5wLy4tZlTDqMQZTJoBcTtq8hWSMHZ9v7fd33QBFt29h3LkNKgND\n4v3Oq6VPyxBGfXsgOXuGuKu3UFZ+z2whMxOzGtYoatYm8UTJJb2J/f3QXbEEyXNFL3mzFqTN/rbU\nZsJin2MYTJ2IKFpd4zrb2YX0GXMqzMy8PDpylVLJmbGjiDiwl+qDhtJq1e/vnS3mZGfj3cOVuOAr\ntF23CXuPfsVqX/CKJVxdsYQHVeHu3M6MaToJExN96ug25srTS+w9vhrFhoM43pQDEONoSOVJn+HR\nfTKGUqMC96vMySF89w6uLF9M2sNIxAaG1PtyEo5jxpEmyuZQmCdTTk0AwFBsSLI8GYAa98HDRwuL\naAUqsRZWI4bQdsZCtI1KRiisqMivIy93ofXQF4puySIeZz4lU2qMIksCmGNmVraeSbIGDCYtIhy9\nFUsw+ngwiXsPwXNt88Kiu3wxogcRiKIeozQ0Innzv0WemJZTqzZps75Ff94c9GdMIWX95iJtvzAI\nYmMRB5xF3qzF+504vFwnD/RHkJiASlYyP2p5qzakaWkh6dkVAFFoCKJbocidXeADBTuKCsmRw+jP\nmpbrxAHIyUFeRGurGgqGQCik1arfSYmM4P6ObRjVqEX9iV+98/irK5YQF3yF6gOHFLsTB2g4bSZJ\nYfdgzy4SVvmwxOUS2hJtMkx1cDgQRuNrIFRBVk1LGs+Zxwj3oUXSr1Akovqgodh59OP25g1c+2kF\nV5Z8T+j6tTScOoOoWjHMkgwBQN7Alk459bi+aCGC87dQCRRcagBHOipIlP2N8e5DtLByoWXlVrS0\ncqGeWYPXysF+6Fp7WabczciX/TOelSF/s+9pc+55niemTjdWhnQAmhMQ0BgHhzL2dVQqDMaPQXv3\nDjJ79SFzxCgQCj98FqRSIUiIRxT5AGHkAySnTyE55o3oSYz6Y21tUn74hayBQwps4ntnMjk5yHq7\nIz4fRPK6TWSVwM3jQ9D+awMGX39F6vdL1FGIPNBdvhi9H5aStGU72W7dSsBCNYbDByI9dgSqVUP5\n+DHCrCzk9RuSumwliqbNi71/YdRj9Gd/jfTwQVRiMfImzVA0a4HEyxOtsPtkt+tA0uZ/Qbf4lLxK\nivI4I39B+pMYvLp2ID06ig6btmLTrccbx8T4+3G0bw/0bWzpefIsEgPDErEtJyuLnT3bkh0cSqIB\nCAC9NNBSglZ1G1p9uwRbtx7Fuu6cnZJMyO+rufn7ahRpqQitzDHQM0FsaEhyZR3kh8+iUiqp3KY9\njb9bQLKtAUFRAQREnSUoKoDIlJf7xfXE+jS3bEFLq1Y4W7VicdB8hAIh+z0KX7WsqKjwofVPZjfA\niwh8dMZy5de1XGk9mW1nqwDduX27KsZlMYKSlYXRgN5IggLIqVKVHFs7kl4tdZeaiijywfM/EQgf\nRiJ68CDXeQvfI86ScPg4iqYt3vn5h5DXDVAYdh+Tjq1QSaUknDmHspJloforCoz69ULid4q4KyEo\nP0DJSnz2DLK+PUj//EvSFpRcxTpZu5aIQ29CeDjJew8iOR+E9vMiOxnDPibtm/nFs2SRk4POxnXo\nLv4eYVoq2c4upP7wC6JbIWT36gNZWch6uCK+Gkx2m/Yk/b293Dvz8uzIAeKuX+XI8+iN28GjmL6y\n4yQrMQHP9i5kPInB/eBRzEvgIfBVIr298B0zArKyARBIJdQbNxGnr+d8sBxsUZARG0vQ15OJPHzo\nNRU2PRtbnJetpEpH17c+UDxKeUhQdACBUQEERflzN/HOG8dUM6rOdy0X4l6t9POBKrYjVyhoMdWM\nVJGKjeJPubXpT/a6LCAwQAeB8COio3QRllGJG4m3F4ZjP0HwXPVNaWqG0tgYYUI8wneU2VTq6aO0\nsSXH1pYcaxv1axs7JCePozKSoZJIQCAgffqsQtn2ITfAF4llWV3cSP57R6nWYBc8e4ZpPQcUjZqQ\n6P32jNU3yMhQr5PXrkOiz5niNfA5gthYTOvXQNGoMeKLF3LHWBwUgP6MqWiF3kQpk5E2Zx6Zw0cU\nWbhd61ow+lMnIb56Rd3+vEVkDh7GGz+O7GwMPx2B9IgX2a3bkvT3jjxFg8oy5d2RA0QePoTvJ8PQ\nrWxF96O+6FayRKVScfqzkTzw3IfTjDk0nDqjVGz7+bdRGM/fDUDcr6OYMujnUrED1CpxPoP7AuA0\nYw71J0/L1wNFbHosQdEBHA47yJ67O3PfFwlEtKnaDg+HfnSz74FMu3RmhhV6jTzL5xDheko6qKx4\nEhCASEeHB7FiQIChTA+hsOw+k2S7dydp4z/IhvYHQBj3DEFKMjlVrVHUb0iOjR05NrYobW3Jee6w\nVSYmb3eY8mz1rAqQlJCIQebI0Ui9DiI9dgTpjm1kDR5WIv2+Dan3IQRK5Zva6u9DR0e9Th4UgCAp\nsUT2xksPHVDb2bsvr4o7yp1dSDjhh86GteguW4zB9Mlob91M6rIfUbyn9GSepKait2wROn/+jkCp\nJHPAYFLnLXp3kqVEQvL6zRh+NhKp9yGMhg8k6Z+d5dqZl3dsuvWg8Zx5XF74HSc/Hkyjr+cQE3CW\nB577sGjuTP1JU0vNtsoPFdSaNhNdPSlXgq/CoFIzhdiL52k4bSagThjMb1TAXNecntV7Exp3k2lN\nZ5Kcnczt+FskZSVw6uFJTj08yfTTk+lg3YneDn1xs++GgaRkljIKQrly5PcObgQjcLBpTMKGQ1Rq\n3Z6nF4QgMMbMXACUXUcOIL58kfTxkxDExaGSyUibt/DNWdIHkP2KcEF2SYkYCIWk/PIbxm2d0Z8z\nA3nrtu/WbS9mpM8fXt6l5vYu5C1bIQn0R3wukOwu7sVh2mtID+wFIKtXH/T//0MtLTLGjifLox96\n381Be+8uZG4dyfzoE9Jmz813gReJtxf6s6cjevwIhX01Ulf8jLxt+w848bkzH/MJUi9PjIb2J2nr\nLtB/w2INJUS9CZNJunub+zu2ceaL0WQnJyM2MKTNmj+LrNBKQWjh0ge7Xn0wNzdAsmFLqdkBIKvt\nWCTVxmqbOL7c135Pva89PCkMz3v72H9vL8ceHOHYgyNIRVI62XSht0Mfuti5oycuWw+7ZTQQ/SaC\nlGRu3VJv47GUqMU/lHXbocgSgsoSC7Oy/1UUtR1J++57UletQd60WYGceGmirGpN6qJlCFOSMZj8\nZanoyQvi4xCfPYO8UWOU1jb5OjdXd92/+OuTC2OiEQf6I2/ujNKqyjuPU1ayJOWPDSTu8yKnZi10\ntmzExKUJ2lu3fND4Ch8/wnDEUIxGDEH49AlpU74m4XTQhznxF4jF6kTGHr2RBPpjNLQ/pKZ++Pka\nihSBQIB9v4GIDQzJTkwEpRJdS0tSH0aWql2lXeHrVYrKlhdO/NXX9kbVmNRkKr6D/AkT0YjKAAAg\nAElEQVQYcomvm83GztCew+EHGXt8FHU2VePToyM4eP8AGYqM3PP9H/vlZsCXNOXGk0gOeXJDX71H\n3PjeMwASjOs+/9QcS4uyH1wolZl0EZM1eBhZXdyQnPFF+68NJd6/1NsLQU4OWT3zP37yJs1QSSSI\nA4rfkUsOHUCgUpHp0feDjpe3akPCSX9Sv1uIIDMLg6++RNa9M1rXgt9+Qk4OOuvWYNy6OVLvQ2Q7\nu5DgG0D6zG9AWzv/BovFJK/dSGavPkiCApAN6VciFfDE/n65mggaXlKlfUc6bd2V++/2G/8pM/W7\n/0s4GNdgWrOZ+A05z+lBQUxpMp3KelZ43t/H6KMfUWdTdT4/PpqjEd4sO7+IFReWlIqd5caRa+/a\nzjUTEAqESIJCEeno8DDzRSJC2dtDXmERCEhduQqlTIb+grkIw8PyPqcIkR7cD+Q/rA6Ari6KRk3Q\nun4VQXJSEVv2Otr796o14POzji8WkzF+IvEBF8n06Iv40kVkru3QnzEFQWJCrtPTunoFmVtH9L+Z\nCRIxKT//RtL+w4VXDxSLSfljg7rvc4EYDeqLICW5cG3mge6KJeiuKJ2bX1kn+owvDafNpOG0meW6\noEdFwdG0DjNbzCVw6GVODPBjQqOvMNU2Ze/dXXx0eBBB0ertbh77u5X4zLxcOHLh40do+Z/huoUI\nO5ktGTdvYdHMmZu34p8foXHkJYmykiWpy35EkJ6O4cQvICenRPoVJMQjPnMKecNGKG3tCtRGdqvW\nCJRKxOeKrz658PEjxOeDkLu0LtBWPaVVFVLW/UXirgPkVHdAZ9N6TFyaoD9tEgbjPkPWtQPiq1fI\nHDiEeP9LZA79qOiWabS0SFmznsy+/RFfOFdszlzs76eWrg04iyTgLEa93DQz8/9DVtsRp69n4/T1\n7HwXVdFQfAgEAuqbN2Ruy/lcGH6NI/1OMrDWSx2PZW1/LHFxmXLhyKV7dhKlA4miHOwE6sIClq3b\ncONmLEjkgC6mphpHXpJkefQjq6cH4nOB6KxdUyJ9So4cRqBQ5C9b/f+Qu7yoT+5fVGa9gdTzedSg\nkMsn8nYdSDgVSMbwkQji49G6f0+tzCaRkDp/MSmr16LKR6GND0ZLi5TV68jsNxDxxfMYDexTpBEM\nQUoyont3EcQ9y31P7tS4wkjFFhVlaU1aw9sRCAQ0rtQUGwNbpjWdybSmM/G8X/LRk7LvyFUqtHdt\n52ol9Rq45TN1ApCBkwuPH2aAfg4g0DjykkYgIGXZjyjNzNFbsgDp9m3FPqMqVFj9OfKmzVGJxYgD\nis9W6f/au+/oqMqtgcO/MzW9EqQXESQgRUTp6FVAQAigBgEBleinKIggIEUkFI3XDgqKoF4EBAXp\niiUqLaLUUIIg2IAEhBDSZjJ9vj8mGQglBWaSSdjPWq6bZE5559yQPW/be+1KnCoV5l5X3043nY7c\nt2aT9fn5Pw7n1n9P3vAR137tomg05Lw3D1PsALS7dhDavy9KVubVX8/pRLNzO0HPPUNks0YEj3sO\nze+HsTW4CadWh/+nn0B+jgUhKprGEdGMv2MS4++YxM3hZT964vOBXLMvGc3hQyTf0QiA0MOn0AQE\ncFqfv2LZz7VDV4bWy56zShVy3piFYjYTNHEsAa95L2OakpWJbtNPWJu1wFH/xqu/UME8+d5krwwZ\nq479g3bXTqwd7/RskZxft2EYOwHD2Anovy2jVJJqNTmz38fUfyDa3buuKpgr5zLwn/8+4Xe1I7xn\nF/w/W4SjShSGiVPIff1tzm3bTd7wEaiMBvyWLvbSGxHCuy63+r0s+Xwg1y9fBsDeG10L20L2pRJ1\nexsO/Z7/R1jj2u9apUrZb4US4AwNxREVhcqQ69q61LenV3rmum++RrFasVxDb7yAe558+y8eaFlh\n+jX5e9xLuFq9pGyNozGOn4Rx/CRsZTlfqlaTM2supgEPo92zm9DYPiiZ54o+x+lE+/NWgoc/TmTz\nmwma/ALqo0cwxfQj84vVZGzfi3H0OExDhwFg/L+ncfr5ETBnFlitZfCmhKhcfDuQ22z4rVyBIyKC\nA8o5/FV6InKgesfOHDxYkNbU1euRHnn5sHboRNbCz9zfW+682ytznZ4YVi9gbdcR8M5+cv2alTg1\nGsyXKXpxLcp166JaTc47c8gbNARt8h5CH+zjWnh40dYx5cwZ/N+bRXj72wjr2xO/L7/AXqs2uVNn\ncjb5EDkLFmK96+5LFuY5q1bF9PBQ1Mf+Qb9y+cV3F0IUw7c3X3/3Har0M2QNG8aR9E+50R6OijPc\n0L4jB6efAsUJ9ppotE5CfDd7XqWn+/EH8uL+D7/FCwn870ys7Tpga9vOY9dXsrPQbfwRW5NbsDdo\neM3Xs97eBqdG4/F5ctWff6Ddl4zl7i6lzszm81Qqct96F1Qq/BcvJPSBGPD3x6nRYHxuLP6LF6L7\n5isUqxWnnx+mBx/CNORRV8nWEuTlNz4zCr+FHxMw+y3MsQMqXLIkIcqTbwfyN94A4EC3dtgSP6bq\nKQuagAAiW9zKwYNL8LshG5OxGlUineVZw+O6Z2scjSWmH+YevQjt35fQxwZxbsOPOOrV98j1dd9u\nQLFYMMdc/Wr1QgIDXfPku3ei5ObgDCpdgYIr8cvf62vykVKvHqdSkfvGLFT/nkL//bfuH+u2uXYA\n2KKbkjfkEcwPPlTqmu+OWrUxxQ7Af+lidF+vx9IrxqNNF6Iy8+2PvZs2YbuxAfsjXFE68u8sqt7R\nlrR/zeTkWOCGUyjGqrJivZwVDPVaO99F7n/fQnX2LKFDHvLYYjL9ujUA17Tt7GLW9h1R7HY0Hpwn\n169eiVOnw9Kj/Msgeo1KRfaizzFdMLxv6hXDuQ0/cG7jz5gef6rUQbxA3sjROBWFgFlvFipRKYQo\nmm8HcocDxWrl0K5vAKieAdUumB83hx/HaQ6W+XEfYnpkGMYnnkJz+BDB//cY2GzXdD0lJxvdT4nY\noptgb9jIQ60ES3vXPLnOQ/Pk6iO/ozl4AMt/7imTymrlSqXC3uhm8gYOwfjsaOzRTbHddvs1l7a1\n39TQlZtg7x60P5WwPK0QwscDOZD9wUekaFw9u2oZUK19Rw4edGV0c4YaAaRH7mMM017BcncX9D98\nT+C0F6/pWrrvvkExmz3aG4cL58k9E8j1q78Erj0JTEVhaxxN7qw5GF6c5tFV9HmjxgC4euVCiBLx\n7UA+dSq6jT9y8FQKYWYNoerA/Pnx/BXrga4AHhUlgdynaDRkf/gJtpsbEzBvLn6ffnLVl/LGsDoA\nQUHYWtyKJnm3Ryp96deuwqnXY+ne0wON833eWkVva9YCc5du6LYlofnFe2l0hahMfDuQx8eT3qA2\naVmpVD1to2qbtqi0Wg4ezMA/SAFcNWGlR+57nCGhZC36HEdkJEETnke7ZVPpL5Kbi+7H77Hd3Bi7\nF/ZOWzt0QrHbr3k/ufq3g2gOH8JyTzecwbJ94loZR40FIGC29MqFKAnfDuTA3ltdK5+rn4NqHTqT\nl2fjjz+yuKG+A4xVAdlD7qsc9eqT/ckSUBRC4oag/uNIqc7XJ36LYjJ5JtXpZVjadwDOr7q+Wvo1\n+cPqHk4Cc72ytWmLpV0H9Infod6/r7ybI4TP8/lAfvBUCpC/0K1DR37//RwOh5Pg2gYwupLBSI/c\nd1nbtifnzdmoMjMJGfxQ8VnBLuCp4iNXYrujLU61+toy0TmdrtXq/v6Yu9zrucZd54yjngdkrlyI\nkig2kDudTqZOncqAAQMYOnQox48fL/T66tWriYmJYfDgwaxYsQIAh8PBpEmTGDhwIA8//DBHjx4F\n4NixYwwaNIjBgwczbdq0EjXwt38PAlArz5/I5i3d8+Oa6qfBUNAjl/Ssvsw84GGMI55D88dRQuKG\nliwNp8GA7ofvsN3UEHvjaK+0yxkUjK1l/jy5wXBV19Ac2Ifmzz8wd+0OQUEebuH1y/qfe7C2uBX9\nutWoj5ZuJEd4jzZpC2zcWN7NEBcpNpAnJiZisVhYtmwZzz//PAkJCe7Xzp07x+zZs1myZAmLFi1i\n3bp1pKWl8eOPP6IoCkuXLmXUqFG8/fbbACQkJDBmzBgWL16Mw+EgMTGx2AYeOL4HlQOa3dzOPT8O\nYIk87h5alx657zNMnoq5e090WzYRNHFcsfuEdT98h5KX50oC48VsP9Z2HVFsNrQ7fr2q89251fvI\nsLpHKQrGUc+jOJ34v/t2ebdG5At4PQHi48u7GeIixQbyXbt20amTK3d2ixYtOHDggPu148ePEx0d\nTXBwsKvYerNmJCcn06VLF2bMmAFAamoqIfn5U1NSUmjdujUAnTt3Ztu2olelOhwODv37G1FZULvD\nXQDuHnlW2GH0plqArFqvENRqsucuwNa0Gf6ffoz/gg+KPNy9Wr2Xh1erX8TaIT/v+tVsQysYVg8I\nxNKlm4dbJiw9e2Fr2Ai/5ctQnThe/AnCa7RJWwjt0wPdz1th0ybC72qH3ycLUP9xBOXMGbBYSnUt\nb5c8vt4Um6I1NzeX4ODzKSw1Gg0OhwOVSkW9evU4evQoGRkZ+Pv7s23bNurXdy1OU6lUTJgwgcTE\nRGbPng24hukLBAYGkpOTU+S9/zn7D0aHiUYZ0LjXvVSpEsTBg+e48cZQTtj/QWuqjlMH9esHS4rW\naxQV5Zk0pUXfJBi+Xg933EHQlIkE3doMevS49DijEb7/Bho2JOKudl7tkdOzK6jVBO7YRmBpn8GO\nHXDsbxg4kKg6VYs9vEyecWXz4mR45BEiP34f3n232MPlGXtJ357w9++QvzBUczCF4BfGFD7G3x/C\nws7/Fxpa+PuC/2bNch27a1c5vJHKqdhAHhQUhOGC+cOCIA4QEhLChAkTGDlyJGFhYTRt2pTw8PPp\nGV999VXOnj1LbGwsX331lfs8AIPB4O6pX8n+1P0A1MjVoardkJSUfzl7No+WrcP5025BnVuFKlUc\npKdf3fymcImKCubMmaI/VHmMfziaT5YQ1u8+nP0fIvPrxEvmwHXr1xJqNGK4rw/G9Gvf4100hbDm\nLdBs307636cgMLDEZwZ+sogAIKt7DJZinl+ZPuPKpEsvImrXQbVgAWefeg5n1St/YJJn7F1hnyxE\nC9CxIxZU2Jq3RMnJRsnKQpWViZKd5fr6zBmUI0dQisnqaLuxAblvveuVaokVXWk/kBY7tN6qVSs2\nbXLtAU5OTqZRo/NpMu12OykpKSxZsoS3336bv/76i1atWrFmzRo+/PBDAPR6PSqVCrVaTZMmTdix\nYwcAmzdv5rbbbivy3jt/c336a3JDE1QaDSkprvnxGje6emjWnDCZH6+AbK3vIGfWXFS5OYQOfggl\nPb3Q6/p1rnlnT9QeLwlr+04oVivandtLfpLTiX7tKhzBIVju7uK9xl3vtFqMz4xCMZkI+HBuebfm\nuqb69xSOoGD46SfyHo3DED+T3Ddnk7NgIVnL15D57UbO/bKHswf/JD31LGf+PsXZfYfJ2LKdc+u/\nJ+uz5eROOb/IWZ2WiqN69XJ8R5VHsYG8a9eu6HQ6BgwYwKuvvsrEiRNZv349y5cvR61WA9CvXz+G\nDh3KkCFDCAsLo1u3bhw8eJDBgwfz+OOPM3nyZHQ6HS+88AKzZ89mwIAB2Gw2unfvXuS9dxzYDECr\n5vcA5+fHw+uaweKPzeQngbyCMt8fi2HMeNTH/ib0sYfBbHa9kJeH/ttvsNerj+2W5mXSFvc8+baS\nz5Nrdm5HnXrCVSBFr/dW0wRgGjQER1RV/D6ej5KVWd7NuS6pTp1E/e8prG3bgUZTfDY/RYGAABzV\nqmO/uTG2O9pg6XIvSl4ehrETMPfug2I2EzziKbDby+ZNVGLFDq0rinLJVrGCeXCAESNGMGLEiEKv\n+/v7884771xyrXr16rFo0aISN+7g6UP4WaBFZ1c1qYIV6/oaGXDKtYdcksFUXMbxk1AfPYLf2lUE\nj3uOnFlz0f30A4rR4ErJWkYLH6xt2uFUqdAlbcVYwnP0a1YCkgSmTPj5YRw+kqDpU/D/eD7G0ePK\nu0XXHe1WV6fK2qEz1/KxtaDkMUBor67otv+K/5xZ5D07ppgzRVF8OiHMcUcm1bPURDZvCbh65AEB\nGszBJ8EgyWAqPJWKnNnvY215K37LlhA09jn8P5oH4Lna4yXgDA7B1rwFmt07XQvtiuNwoF+7GkdY\nGJbO//F+AwWmR4fhCA3Df96cq97zL65ewSpza8drm8++sCefvehz7FVvIPC/L6NOOVDEWaI4Ph3I\nnSq4UV8dlUaDxWLnyJFMGjeO4JQp1Z0MRraeVXABAWR/ugx79Rr4LfoE7dbN2OvUxZb/4a2suOfJ\nd+0o9ljtr9tQnzqJuWdv0OnKoHXCGRRM3uNPosrIwH/x/8q7Odcd3dbNOELDPDrd5QyPIPed91Cs\nVkJGPFmqLWyiMJ8O5AD71KdYt3YOR49mYrU6aNIkgpOGk5KetRJR/3EUR1RVFEBxOsFm81h50ZKy\n5uddL8n+VvewuiSBKVN5TzyFMyAQ/7nvnl9TIbxOdeI46n/+xtquPeSvi/IUS5d7yRv8CJqU/QS8\n+apHr3098flA/urdM+kd84x7frxJk0hO5qYSYHHN00t61orP2qETOe/Nc3+f88Y7Zb4lpWCevNgP\nEHY7+nVrcEREYO10Z9k0TgDgjIgkb+hjqE+m4bd8WXk357pxfn7cO/8mDdNfwV6nLgGz3kJTghEx\nX1WeiW58OpA/FnwnG/euB+C331yBPDo6nLTcNAIs9QDpkVcW+rWrMIydgGHsBLR7dpf5/Z2hYdia\ntUC7eyfk5V3xOO3PW1GdOY35vj6gKXatqPCwvKdH4tTpCJj9FhSzT/lqSNaxS+nyn4elQ2evXN8Z\nFEzOrLkoDgfBI54s2ToVHxTweoIrhW058OlA/vFbG4mu3QI4v/WsVgMNRpsBXV5NQFatVxa2xtEY\nx0/COH4SNi/UHi8Ja7sOKBZLkfPk+tWyWr08OapVxzRgMOq//0K/dpXHr1+ef4wvp9w/WDidaJO2\n4IiIwN6kqdduY+3QCeOTT6P54yiBr5SsoJav0CZtIbRvT3Q/b0X381ZC+/Ys8//PfDqQAzz+mOsf\n1cGDGdSoEYhR6wroivEGQAJ5ZXHhatZi96h6ScHQ4RX/Edps6L9agyOqKtb2HcuwZeJCxhGjcKpU\nrhKnDs9MrfnCH+PLCXx5GgGvziy3+6v++Rv1ieNY23UElXfDhWHSVGw3NSTgw/fdw/kVgfW223Fe\nkKU0979vlfnUoM8HcoCMDBMnTxpc8+OGVADsuZH4+TlLk1FTiCJZ27bDqSho8/NJX0y7ZROqjAzM\nvft4fNGPKDlHvfqY+z2I5reD6L7/1gMXdKAYclGys90/Mo4ZX66pQ7VJWwjr1Q3tzu3oft1Wbh8s\ndPlrRizXuO2sRPz9yXlvHk61muBRT6PkZBd/TjlTnTpJWL+e6L/5Gnu1ahifesYrI0XFtqPM73gV\nCubHmzSJIC03DQBLTgiRkU4pliI8xpm/vUa7aweYTJe8LqvVfYcxP4FIwDuvF1sS94qsVvRfLCX8\nrnaEDn4I7YF9OCIiAfCf/Zanmnp1TevQCcud53MUGF6ML5cPFhcmgikLtlatMY4ag/r4MQKnTCyT\ne14tza4dhHW9E+2unVjatidj+z4M0xPKZWqwQgTygvlxV4/cFchzMwNkWF14nLV9RxSz+dJ5cosF\n/VfrsFerjrVNu/JpnHCzRzfB3KMX2l07Sz8MazTit+ADItq0JGTEk6iP/I4pdgA58S+T8ctunDod\nmqO/X/0HBA/x++x8Fkz/ucVXfvO4gvnxKlHYyzA4Gce8gLVZC/w/W4Tuuw1ldt/S0H/+GWF9e6I6\nc5rcaa+QtWYD+PkB5TM1WEEC+fke+cncNLAEYDGpZcW68Dj3PPlF29B0m35ElZXpyjjn5blCUTLG\nUQW98jdLdLxyLoOAN14l8ramBE8aj+psOsbHnyTj12Ry5nyI6emROMPCsXTrgTotDc3+vd5sfpFU\n//yNOvUE9tp1XN+fPlXmbVD/9Qfqk2lYOnQqs3TJAOh05Lz7AU6djqAxz6JknC27exfHZiNwykRC\nRj6F08+frM9WkDd8RNk+n8uoEH+RDh48i06nokGDUNIMqe70rNIjF57mnie/KJDr17jmvWRY3XfY\nWrXG0vk/6LZsLHL/sSotlcApE4m8tSmBr70CdjuGMeM5uysFwyuv46hTt9Dxpv4DAdCX4151vxWf\nA2AYOwF77TpoDh0q88xn2q35aVnLYUjf3qQphvGTUZ/+l6AXni/z+1+Oci6D0IEPEDBvDrZGN5P5\n7Y9YfaTyoc8HcrvdwaFD52jUKBytVs3J3DQCLTcCsodceJ4zLBxb02aF58lNJnQbvsJeqza21neU\nbwNFIcbnXH/kA2ZdOqet/v0wQaOeJuL25gTMm4MjNJTc6a9wdvdBjBNexFmlymWvabm7C46ICPxW\nrvDKXvViOZ3ov1iK098fS+8+mO/tgSo764qLML1Fm5Q/P96xbObHL5b3zLNYb2+D35qV6FetKJc2\nFFAf+o3we/+DbtNPmLt1J3PDD9hvvKlc23Qhnw/kf/+dTV6ejSZNXItQ0gxphDtcNdGlRy68wdqh\nI4rJhHbPLgB0P/2AKie7TCuyiZKxduiE9bbb0X/zFXz8MeBahBTyyCAiOt6O/9LF2OvWI3vWXDJ2\n7CPvqREQFFT0RXU6zH0fQHXmNLpNP5bBuyhMs2sHmr/+xNyjF86gYCzdXdUfdd9+XXaNcDrRbd2C\nveoN2BuUU8BSq8l+9wOcAQEEvTAG1b9lP70AoPvma8J63IP6778wPDeW7E+X4QwOKf7EMuTzgfzC\n+XGD1UCWOZMgSwNA0rMK77C2y69Pnr/dR7/mS0CSwPgkRcE4eqzr6+efJ7TffYT3uAf9hvVYW91G\n1idLOLd1B+aBg0tV4MYUOwAon+F1vy+WutqQP8RvbdcBR0go+m++LrMFeOojv6M6c9pV7awcP7w6\nbmxA7pTpqDIzCRo9omwXIDqdBLz1GqFDB6A47GR/+AnGSS/55BoZ32vRRVJSzq9YP5W/Yt3P7FoA\nIj1y4Q3Wdu3P7yfPy0P/zQbsdetha9mqvJsmLqJN2nJ+RXdmJrqkLVhbtiJz1VdkbvgRy329r+oP\nr61Va2w3NkD/9fqy3c9sNqNf/SX2qjdg7XyX62daLZYuXVGfOF5m5T7LettZUUyPPY6l83/QJ36H\n35JPy+amBgPBTzxK4KszsdeqTeb67zD3faBs7n0VfD6QX9gjL9hDrsmrDsgcufAOZ3gE9ia3oN3x\nK/qv16EYDa5FbjKs7nOsHTqR++r5VetZH31K5ncbXQu0ruX/L0XBHDsAxWRCt36tB1paMrrE71Bl\nZmJ+oH+hXP4Fw+v6b74qm3a486uXX1IcN5WKnFlzcISEEjhlIqp//vbu7Y79Q3ivbvitXYWlbXvO\nfbsRW7MWXr3ntaoAgfwsVar4U7VqAGm5rqxuUsJUeJulfQcUk4nAhBkAmPuUT9pYUbyCgjtMnYrm\n0G8eu67pwYcAyrTSmntYPX9ov4Dl7i44tVp035bBvmqHA+3PW7DXqImj/o3ev18JOGrWIvfl/6Iy\n5BI86mmPpea9mPbnrYTfexealP3kPRJH1oq1OKOivHIvT/LpQJ6dbebYsRyaNIkAcCeDsWaHAzK0\nLrzH2t7VE1Ef+wfbjQ2w3dK8nFskrqSg4A7x8R7NquWoWw9L2/Zok7agSj3hseteiZJxFl3it9ia\n3IL9lmaFXnOGhGJt3xHt3j2o0lK92g71od9QnT177aMaHmbuPxBz9/vQ/bwV//nve+y62qQtaLdu\nxu+TBYQ+GIOSlUXOa2+T+/rbpVpXUZ58OpAfOJAOcH7Fen6PPC87CH9/ybMuvMfarr37a3NfGVb3\nZd4suGOOHYDidKL/8guPXvdy9KtXolitl/TG3W3p3hPA671yXf62M0s5bTu7IkUh583ZOCIjCXx5\nGuojv3vksgH/fZng4Y8T/MIYnKGhZH25DtOjcR65dlnx6UC+b98ZgEt65Dnn/KQ3LrxGm7SFkGFD\n3N/rfkz0iUpYouyZY/ri1Otdw+teXjHtt3wZTpUK8wOxl33dcq8rkHt7nrw8E8EUxxkVRc7rs1BM\nJkIeGYh288aiT7BYUB0/hubXX9CvWYn/++8ROGUiwU88SninNlSpHYXul59R/3sKR0AgOa+8jrVd\nhzJ5L56kKf6Q8nNpID+JvzqAcxlqGjeWrWfCO6wdOpEbWYWIzm0AyJn9AfbG0eXcKlEenKFhWLr1\nQL9uNZp9ydha3OqV+6j/OIJ21w4sd92No1r1yx7jqFUb6y3N0W7djJKT7Z29zA4H2m1bsdepe0nG\nO19h6RWD6YH++H35BcGjniZn9vuo0lJRn0xD5f7vJOq0VFRnTl/xOk61GkdkFdSn/wUgc/VX2Cvo\nzhQfD+TpqFQKjRq55sTTclOppm3IXyZFeuTCq9wLqAD9utUYJZBft0yxA9CvW41++TKvBXL9cldK\n1oK941di6d4T7YF9aH/6wSvFOTQp+1FlZpLXo5fHr+0p2qQtqI8fA0CdeoKwB3pfcozTzw979RrY\nGt2Mo1p1HDVqYq9eHUf1mjhq1MBRvQaOqKoEvPlf9zn677/FKIHc8/bs+ZebbgrFz0+D2W4mPe8M\n9XR38xeyYl14l61xtPsPpa4c6gsL32G5uwuOyEj8Vq7AEP9yoW1hHuFw4LficxyBQZiLCaCW7j0J\nfONV9N987ZVA7svD6gWsHTqR88Ys94iZ8dE47M1a4KhRA3u1Gjhq1MAZFl6idS2V5d+5Twdyo/F8\natZThpMAhFgbArJiXXiXNxdQiQomP2Wr/0cfotv4A5Yu93r08tpft6E+9g+mhwZR3ApeW7MW2GvU\nRJf4LVitoNV6ti3lnF+9pC4cMUNRMA159KquU1n+nfv0YjeA3btPk5SU5ipfCnIU850AACAASURB\nVARa6wMQGSlz5EKIsuHNlK0F1yxuWB0ARcFybw9UmZlot//i2YbYbGi3/Yyt/o04atT07LU9rGDL\noXH8JI9uOayofD6QT5zYmg4darjKlwI6Uy1AeuRCiLJju/U2bA1uQr/hK8+mbM3LQ79mFfYaNUs8\nnG0uKKLi4dXrmv17UeVk+3xvHCpPT9pTfDqQT5hwB3/+6fpHU5CeVWW8AZBALoQoQxekbNWvW+Ox\ny+q/2+CqrPfgQyXOCW9t3xFHUDD6DZ4tolIR5sfF5fl0IE9I6MzNN7tWrBcUTHEaXHPmEsiFEGWp\nIGWrJ4fX9VdIyVr0SXos93RFfexv1B5MSVuQCEYCecXj04EcICbGVbK0oEduyg4FZNW6EKJsOerU\nxdKuA7qkLahOHL/m6ylnzqD7MRFri1uxl3Ke13JvDwD0nqpRbrWi/WUbtoaNcNxQzTPXFGXG5wN5\ngZOGVLQqLYZMP0ACuRCi7JkLFr15IGWr36rlKHY75v6l6I3ns3TphlOt9tg8uSZ5N4rRIL3xCqrC\nBPK03DSqB9YgPV1FQICTgIDybpEQ4npj7t3HYylb9cs/x6lWY+r7YKnPdYaFY23XAe3uXaj+PXVN\n7YALypZWgIVu4lIVIpDbHDb+NZ6ielANzp6VrG5CiPLhDA3DfG9PNL8fRrMv+aqvoz70G9q9e7Dc\n0/Wqy2RaPFhExb3QrV3Ha76WKHsVIpCfNv6Lw+mgekAN0tMlkAshyo97eD1/odrVKKhxbi7NIreL\n23FvQSC/xnlyiwXtjl+wNY6uELW3xaUqRCAvqHpWRX0jFosi8+NCiHLjTtm6aoUru1pp2e3ov/wC\nR0go5m49rrodjrr1sEU3Rbd5I+TmXvV1NLt3oeTlyfx4BVZsIHc6nUydOpUBAwYwdOhQjh8vvFpz\n9erVxMTEMHjwYFasWAGAzWZj/PjxPPzww/Tv358ff/wRgN9++43OnTszdOhQhg4dyoYNJRsSKlix\nHmS5EZCtZ0KIcqTVYur3IKr0dHQbfyj96UlbUKelYo7pC/7+19QUc/ceKGYzuk0/XfU13PXHO8j8\neEVVbCBPTEzEYrGwbNkynn/+eRISEtyvnTt3jtmzZ7NkyRIWLVrEunXrSEtLY+3atYSHh7NkyRLm\nz5/PjBkzADhw4ADDhg3j008/5dNPP6VHj5J9Gj2Z68rq5m9xldWT9KxCiPJkvoaUre5h9ZKkZC2G\nJT/L27XUKNcmbcGpKFjbV7w63MKl2KIpu3btolMn15BLixYtOHDggPu148ePEx0dTXBwMADNmjUj\nOTmZHj160L17dwAcDgea/GpBKSkp/P333yQmJlK3bl0mT55MQAmWn6flD61r8moA0iMXQpQvW8tW\n2G5qiP6br8nNzsIZElqyEw0G9OvWYK9TD+sdba+9HS1uxX5DNXTffwN2O6jVpbuAyYR2x6/Ym9yC\nMyLymtsjykexPfLc3Fx3oAbQaDQ4HK4ecb169Th69CgZGRnk5eWxbds28vLy8Pf3JyAggNzcXEaN\nGsXo0aMB1weB8ePHs3jxYmrXrs27775bokYW9MgVY1VA9pALIcrZVaZs1W9Yj2I0YHqwf4lTshZJ\npcJyb09UGRlod/xa6tO1u3agmM1YOsr8eEVWbI88KCgIg8Hg/t7hcKDK/wUMCQlhwoQJjBw5krCw\nMJo2bUp4uCul6smTJxkxYgSDBw+mZ0/X6souXbq4PxR07dqVmTNnFtvAqKhgzlj+RaWo0Npdgfym\nm/yRxZWeFRUVXPxB4prIM/a+Mn3G/zcMEmYQvHo5wc89U7JzVi8HIPCpxwm8sK0bN7r+9667St+O\nhx6ATz8mbHMi9C5lidU9ruAf0PNeAkrx7OR32bcUG8hbtWrFTz/9RPfu3UlOTqZRo0bu1+x2Oykp\nKSxZsgSLxUJcXBxjxowhPT2duLg4XnrpJdq2PT98FBcXx5QpU2jWrBnbtm2jadOmxTbwzJkcjmWe\n4IaAapw4agfUaDQGzpyReXJPiYoK5syZnPJuRqUmz9j7yvwZB0YS2q4Duk2bOLs7BUftOkUerjp1\nkojERGy33U5mWDW4oK2hk6cAkLX6KraSNbudKgGB2Feu4ty4KexJ3s3q1V8ybdorhQ5LTT3BrFlv\nYLPZMRoNtGzZivHffs+iiAgSP11M7ofzSU9Pp169+iiKwjvvzOXOO9vQp88DjC2o/Q3MmzeLxMQf\nWL58baHrx8bG8NlnX6K9oEb6hg3rWbDgA2rWrIXT6cRgyKVZsxaMHj2+1G9z69bNLFy4AI1GQ8+e\nMfTu3bfQ61lZmUyb9iIWi4XIyCpMmjQVvV4PgMlkYvToZ5g48SXq1Klb6nuXtdJ+UCo2kHft2pWk\npCQGDHAt7khISGD9+vXk5eURGxsLQL9+/dDr9cTFxREWFsbLL79MdnY2c+fOZc6cOSiKwoIFC5g2\nbRrTp09Hq9USFRXF9OnTi22gw+ngVG4azaKac+aMAsgcuRDCN5j7D0S3LQm/L7/A+NzYS14PjH8R\n/brVACjZ2SgOB+o/jxJx2y2uA0wmVNlZKGYzAFVqR+EICQU/vyvfs3dfDPEXjGb6+WH5zz3ov1qL\n+ugR170U5ZLz5s2bw4MPDuCO/Ln5yRPGsOXQQR6pdyN93v+IPXt2sWbNSuLjX3afExoayt69u90j\nsQ6HI3+d1KXXv/zPoFu3Hjz55PkRi+HD4zh8+BA3lyK/vM1m47333uajjxah1/sxfPgwOna80z0C\nDPDJJwvo2rU7PXr0YvHi/7FmzZf07z+IQ4d+4403Ejhz5nSJ71fRFBvIFUVh2rRphX5Wv35999cj\nRoxgxIgRhV6fPHkykydPvuRa0dHRLF1auiQKZ/POYnFYqBboyuoGMkcuhPAN5t59CJo4Fv3yZRhH\nPQ+XCaAFFKMBJ+D0v2CBr58fDrUK9SlXmlVHeARc0KMtcTu690T/1Vp0G76CTpffRhYREcnXX6/D\n39+f6OimJNx7H5EfL8BYxP5xtVrNrbfexo4dv9KmTTu2b/+F9u3bs3Ll6hK3zXlBKtvc3FwMhlyC\ngoIKHTN//vvs37+30M/eeus990Lpf/75m1q1ahMY6DqvefOW7N27m7vuusd9/L59yTzyyDAA2rbt\nwIcfzqV//0HYbFYSEt5gxoyXStzmiqbYQF7eThpcC91qBNbg53SFoCBnUR9WhRCizDhDQjHf2xO/\nNSvR7N2DrWWrQq8b4mdiiJ+J+sB+Iu7ugLlnb7L/t6TQMQGvXTAErigYx00sdTssXe7FqVK5qqFd\nIZCPGPEcq1atYN68Ofz55x90Cg5mmkqFo5iFbl27dmft2lW0adOO77//hjFjRpUqkH///TekpOwn\nPf0MgYFBPPJIHDVr1ip0zBNPDC/yGgZDrjuIAwQEBJJ7URIco9HoPiYgIACDwfX6Lbc0Bwp/oKhs\nfD6QFySDqR5Uk7NnJaubEMK3mGMfwm/NSvRfLL0kkBfwK6LuuK1xNJaYfgDo1q66qjY4IyOxtmmH\n9pefUTIzL3vMrl07iI0dQGzsAEwmEx/2uJu5VaoQ17Z9EVdWaNasBW+++V+ys7PIycmmRo0aQMn/\nDhcMrZ88mcbYsc9Sq9alawnmz3+ffRfkrlcUpVCPPDAwCKPx/KJro9FQaDeV65hAjEYjOp0Oo9F4\nSa+/MvP9QJ7fI6+eP7TevLkschNC+A7Lf7rgqFIFv9VfYpj2yqVD4zYb+pXLcYSHY+nS7dLz84P4\nxV+Xuh339kS3LQntzu2X7X3OnTsbvV5Py5at8LPZuPHUSTKqV8cZVNTCKtd12rZtzxtvvEqnTncV\ne+yVVK9eg9Gjx/Piiy+wePEX7oVoUHyPvG7depw4cZycnBz8/PxITt7DwIFDCx3TrFkLtm3bSo8e\nvfjllyRatLi1yGtWJj6fa/1kfo881FEXq1UKpgghfIxWi6nvA66UrT8lXvry5p9Qn/4Xc98H4ILg\n5Wnm/Gpo2u2/sHPnrzzxxFAef3woTzwxlBMnjjNjRgILF37EE08M5en/e4TftFoe7Xx3MVd1zfl3\n69adpKTN3H13l0I/v/jY4cPj3Pf84ovPLjmides7uP32O/joo3mlem8ajYaRI8cwZswzDB8eR+/e\nfahSpQrZ2dm8+KJrBfwjjwwjMfE7nn76cVJSDvDAA/0Lt66I9QsVneL08YmDh5YN4ovDS/my4yEe\n6HIzDz9s4e23zeXdrEpFtkZ5nzxj7yvPZ6xJ3k14t7sw9bmfnPn/K/Ra8FNx+K1czrmvE7G1vsOr\n7QjvdAfqY/+Q/ttfUETWzMDpLxHw3jtkfr4K63/uueJxlyO/y95X2u1nFaZHrhhuAGTFuhDC99ha\n3IqtYSP033yFkp3l/rmSk41+w3psNzbAdtvtXm+H5d6eKHl5ropoRdAmbcap1XokTawofz4fyNMM\nqVTxr0L2OdeQlAytCyF8TkHKVrO5UMpW3fq1KHl5riIrZTC0WzC8XlSNciU7C83eZGy33gaBgV5v\nk/A+nw7kTqeTk7lpVA+sSXq67CEXQvguU/6crP6L87kyCiqdmR58qEzaYGvVGkdUVfTfbnAVUbkM\n7S8/ozgckl+9EvHpQJ5pysRoM1Ij6HwyGOmRCyF8kaN2HSztO6LbloTq2D+oThxHt3UzlrbtcdSt\nVzaNUKkw39sDVfoZNLt3XvYQ7dYtAFjbSyCvLHw6kJ/IPgG4tp4V9MglkAshfFVBnXK/L79A/+UX\nrp95oO54aVjudQ2v67+5/PC6NmkLTp0O6+1tyrJZwot8OpCn5uRndctPBgMytC6E8F3m3n1w+vnh\nt/Bj/P/3EU69HnNM32LPS0rdQlLqFo+0wdL5Lpz+/pedJ1fOZaA5sA/rbbeDv79H7ifKn08H8oIe\nebXA6u6CKRLIhRC+yhkSirl7T9RpqahTT2Dufh/OkNBiz3t9RwKv70jwSBv2HDrIc42j0fx+GPWf\nR90/T009wfjRz/B4jRo87LDzwQfv4XQ6+eyzRYwc+SSPPTaI3r27MXLkkzz77FM4HA46dbqdN954\ntdD1Z86cSWxszCX3jY2NwWq1FvrZhg3reeCBXjz77FOMHPkkw4Y9zNtvv3ZV72vr1s088cRQhg8f\nxrp1l6aIzcrKZMyYEYwY8X9MnToJs/n8NmWTycTw4XEcO/YPAKdP/8uqVSvYseNXzp075z5u06af\nmDbtxULXnTXrTU6eTGPt2lXYr7DuoLz5dGa3gkBe0CMPDnZ6M5+CEEJcE23SFjSHD7m/n+y/ieXz\nb7piNTOTzUS2JQuz3RV0as+LIkQXip/mygUlejfoS3z7mVd8HcBZoybs2Y3umw3kPT0ScFU/e9g/\ngHtSU8mcM5/xX61h69ZNDBo0hEGDhlxX1c/++ecv1q5dSUhIKE8/PYrw8HBmzXqTHTt+4aabGhW6\n98mTqVSvXoNFiz6hR49eqNXqEre7rFSIHnmN/FXrMj8uhPBl1g6dyJ4z3/29pUu3IkuS+mn8CNef\nD0bh+ogig3hJOapVx6ko6L75yv2ziIhI1h/Yx66QEPJa3sr06cWlXC1c/QxwVz8rjZJWP3v22acK\n/Wez2dyvX1j9TKPRuKufXWjfvmTa5ueNb9u2Azt37gBwVz+re8GCw0aNGtO1aw8aN25CgwY3Aa4U\nr88/P6HQNf/++y/q1q3P+vVrOHv2LFOnTirVey8rFaJHXjWgOhkZCnXqSJ51IYRv03+9jry4/wPg\n1cORvDSu6HSkr20/X/1MURTG3V766mcXc+r12G5vg3b7Lyhnz+KMjGTkgMF8N3c2b9auw5EHY2jX\nrgOjR48vtrhIZax+FhoaxqBBQwqdf/fdXdizZ1ehn/388xbat+9EixYtWbjwY6ZP98z0h6f5fI88\nVB+G3RiEzaZQpYoEciGEb7M1jiY34Q1yE97AVoLh48YR0Yy/YxLj75jEzeElH24ujvnenigOB7rv\nvwEg+fMlDM3MZH7vvqxc+RX+/v4sXPhRMVdxVT87cuT3a6p+9u6783jrrffIyzNesfrZyJFPuv+7\nuEdemupnrtc9U/1s//59NG/eIv87p8+WQvX5HnmNwJqyh1wIUWGUtppZzE39Lvv1tXA6nVh63Acz\nXkL/7QbMAx5mzldrifT356YOnfHz86N27TpkZWUVdyXg+qx+lpOTQ1BQkLvYSsEaAV/k0z3yLHMW\n1QKrk57uaqYEciGEKN7Onb8y7L8zuL9hQx5O2ceJP47yltHI3KgoHvtwDsOHx/H774cZMuSxYq50\n/VY/++WXJNq0aef+vnnzlowbN6pU1ygrPl39TJmm8HD0UO4xfMCwYf7MmGHiySetxZ8oSkWqGXmf\nPGPvk2d8qcBpUwiYM4vsWXMJGfU0lrvuJuuLks9vX448Z++rdNXPqgdKelYhhLga5vwsb4EJMwCw\ndOxcns0RXuLzgXzVkRXs/vMYIMlghBCiNGy334EjMhL1qZOAa3ucqHx8PpDP6JhAoLUeID1yIYQo\nFbUaS9fuADhVamzXuABM+CafDuRT75zKntO7pWCKEEJcBW3SFjR7XIlTFIed0Adj0CZ5Jqe78B0+\nHcjj74rn5vDG7jnyiAgJ5EIIUVKuTHMfur/P/e9bMrxeCfl0IAfXvsr0dIXQUCc6XXm3RgghPC8p\nSU1SkndyeOu/+QrD2AkYxk5Av3aVV+4hypdPJ4QpIHnWhRCV2euvu3opHTrkXfO19uzZxerVXzJt\nmiv1q61xNJaYfqSmnmD2xLFYx4zEaDTQsmUrnnzyGZYuXcy2bVvJzc0hPT2devXqoygK77wzlzvv\nbEOfPg8wduz5HOQzZ84kMfEHli9fW+i+sbExfPbZl2i1WvfPNmxYz4IFH1CzZi2cTicGQy7NmrVg\n9OjxpX5fW7duZuHCBWg0Gnr2jKF378LlYbOyMpk27UUsFguRkVWYNGmqO+mMyWRi9OhnmDjxJerU\nqcvp0/+SlLSFWrVqc9NNjdzFVzZt+omNG39g6tTzRWlmzXqT/v0HsmPHr9x3XwxqtZpjx/7h8ceH\nsnTpl0RGVsFgyGX69CkYDAbsdhvPPDOaW25pVur3eLV8PpA7HJCRoVC/vm+WjxNCiCuJj9ezbt2V\n/8yaTJCdrWA2u6YPa9cOIiTEWVSdFXr3thEfb77yARROflKQXW7evDk8MOI57rijLQCTJ4+T6mdX\nWf1s8eL/8fjjT7J48UJGjXqeZcuW0Lp1G2JjB3Ds2D/Ex0/m448Xl/j9XSufH1rPzAS7XXrkQojK\nx88PwsPP/20LDy86iF+LiIhIvv56Hfv378Vms0n1s6usfpaWlkp6ejr9+w/iyJHDZGScZcCAh+nT\n5/78+9kKpZ8tCz7fIy9Izyp7yIUQFU18vLnY3vNrr51f/KMoMG6cxSttGTHiOVatWsG8eXP4888/\npPrZVVQ/mzbtFQ4ePOAeYRg+/FlOnTpJkya3AHD2bDozZ77EqFHjin4oHubzgVyyugkhKrPGjR3E\nxLh6n2vXeu9P8q5dO4iNHUBs7ABMJhPvvfc2Cxd+xDPPFJU/3FX97M03/3tN1c+efPIZTp5MY+zY\nZ69Y/WzfvuTzd1UU3nrrPTQa1/MoTfUznU7n0epnAwcWBHzXe76wGEvTpre4v/7jj6NMmzaZESNG\n06JFy2u+d2n4fCCXPeRCiMqsIIhf/PW1uFwJjblzZ6PX62nZspVUPyuB0lQ/++uvP3nppQlMn/6q\ne6i+LFWYQC5D60IIUTI7d/7KE08Mxel0DddPnfoyM2Yk8PbbrzNnzjtoNFpq1KjJ2LETi7nS+epn\nTzzxCC+8MLnQzy8+dvjwONdXimtIPjg4pNARF1Y/e/rpZ0v8fi6sfuZ0Uqj62WuvzWTmzNd45JFh\nzJwZz7p1qwkNDSM+fmaha3iq+tns2R9ccuyHH87BYrEya9YbOJ1OgoKCSUh4o1T3uxY+Xf0MYPx4\nM6+/rmfFCiOdO8vKdW+QakbeJ8/Y++QZlw15zt5X6aqfFcyRS49cCCGEuJTPB3KZIxdCCCGuzOcD\nueRZF0IIIa6s2MVuTqeT+Ph4Dh8+jE6n4+WXX6Z27dru11evXs3HH39MSEgIffv25cEHH8RmszFp\n0iRSU1OxWq089dRT3H333Rw7dowJEyagUqlo2LAhU6dOLbaB6ekK4eFOLsj6J4QQQoh8xfbIExMT\nsVgsLFu2jOeff56EhAT3a+fOnWP27NksWbKERYsWsW7dOtLS0li7di3h4eEsWbKE+fPnM2PGDAAS\nEhIYM2YMixcvxuFwkJiYWGwDz55ViIy8/JJ/IYQQ4npXbCDftWsXnTq5yt61aNEiP8+uy/Hjx4mO\njiY4OBhFUWjWrBnJycn06NGDUaNcSQYcDod7U39KSgqtW7cGoHPnzmzbtq3Ie9vtrjzrMj8uhKjM\nTiVt4ZTUCRdXqdih9dzc3EIZdDQajTuBfr169Th69CgZGRn4+/uzbds26tevj7+/v/vcUaNGMXr0\naKBwkoLAwEBycorewpCRAQ6HIivWhRCVWvLrrpHO7h6oFX5x9bMCqaknmDXrDWw2+3VV/exK5w0b\nNtid/a169RpMnPhSqdvkK4oN5EFBQRgM51PjFQRxgJCQECZMmMDIkSMJCwujadOm7mo0J0+eZMSI\nEQwePJiePXsCrgT8BQwGAyEhhZMFXOzMGdf/1q6tJSpKJsm9qbT7FkXpyTP2Pl97xhvHjeP35cuv\n+LrNZMKcmYnd7MrHvrh2FPqwMDRFVE5pFBvLXa+/fsXXw8IC8PfXXfIsXn55HnFxj9GxY0cARo4c\nyb592xk16mlGjXqa7du38/nnn/Pmm29ecK0wUlL2EhkZWKj6mVqtuuT6arWKKlWC0OnO544PDvaj\nb98+jBkzxv2zgQMHcvr0MZo2bXrF93Axm83G++/PYuXKlej1egYOHEjfvvcRERHhPmbevFk88EA/\n+vbty4cffsgPP3zFww8/fNnzgoKC0GrVLF26pMRt8GXFBvJWrVrx008/0b17d5KTk2nU6HyJN7vd\nTkpKCkuWLMFisRAXF8eYMWNIT08nLi6Ol156ibZt27qPj46OZseOHdx+++1s3ry50GuXczq/6lxA\ngJkzZ7xTSEBIgoeyIM/Y+3zxGecZLdgdVx5RVHR6dOHh5J06BYAuPAJFqy3ynDyjpcj3mZlpxGSy\nXnJMYGAoS5d+gcUC0dFNmTx5Bmq12n3c5c5TqVQ0a9aSr79OpE2bdvzyy8+0b9+elStXX3J9u91J\nenpuoR55To4Jg8HsPjY3N5fMzCysVlWh8+fPf5/9+/cWut6Fudb/+OMo1avXJC/PSV6eiSZNmvHD\nD5u566573Mf/+usO+vcfwpkzOTRr1poPP5zLzTc3v+x5VaveQE5OLkOGPILd7uD//u/pQnnTy1tp\nP5AWG8i7du1KUlISAwYMAFwL1tavX09eXh6xsbEA9OvXD71eT1xcHGFhYbz88stkZ2czd+5c5syZ\ng6IoLFiwgBdeeIEpU6ZgtVpp0KAB3bt3L/LeBT3yqCgZWhdCVDyt42fS+qJUoRdLfu2CIXBFoeW4\n4tKmXp3rsfqZ0Wi47Hl16tRj0KAh9OrVl+PHjzF27LMsXbrSPdpc0RQbyBVFYdq0aYV+Vr9+fffX\nI0aMYMSIEYVenzx5MpMnT+Zi9erVY9GiRSVuXEGPXObIhRCVVVjjaOrF9APg77WrvHaf67H6metn\nl55Xu3Yd94eJ2rXrEBISytmz6URFVS3x+/IlPl00paBHLqvWhRCVVUEQv/jrayHVz1zVz+rUKXze\n3r3JDBw4lK++WsMff/zB88+/QHr6GfLyjERGVimyDb7MpwO59MiFEKL0pPqZq/rZxef16hVDlSpV\n6NWrL6+8Mo2nn34clUrFhAkvVdhhdfDx6mexsbBiBaSk5Mo8uRf54iKhykaesffJMy4b8py9r1JV\nPzt9GhTFKXnWhRBCiCvw6UB+5gyEhzu5YPu5EEIIIS7g04H89GlZ6CaEEEIUxacDeUaGLHQTQggh\niuLTgdzplB65EEIIURSfDuQgPXIhROWX9OcWkv6U6mfi6vj0PnKQHrkQovJ7/QdX9bMON0r1sysp\ni+pnaWmp/O9/Cxg27EmqVasGuGqKTJ06iZiYftxxh6s+iMPhYPLk8UyaNJVffkmia9ei0417m88H\ncumRCyEqqvgNL7Ju/5XzkpusJrJNWZjtrupntadEEeIXip/2ytXPejfrS3yPovO3K8qlCVvmzZvD\ngw8OcAejyZPHsXXrJgYNGsKgQUPYs2cXa9asJD7+Zfc5oaGh7N272131sqD62ZUSwlxOQYrWAsOH\nx3H48CFuvrlxke/hQjabjffee5uPPlqEXu/H8OHD6NjxTne1TYBPPllA167d6dGjF4sX/481a1Zy\n//2xlz0vMDAQgNmzPyh0nw0b1rN162ZCQkJ54onhpKefYebMqaSnnwHOZ93bv38vzZq14OjR39m6\ndXO5B3KfH1pfuFBLUpLsPxNCVD5+Wj/CA84Ho/CAiCKD+LWIiIjk66/XsX//Xmw2G9OnF5dy1VV6\n+tZbb2PHjl8B2L79F9q3b1+q+16Ycyw3NxeDIfeSQi3z57/Ps88+Veg/m83mfv2ff/6mVq3aBAYG\nodFoaN68JXv37i50jX37kmnb1tW2tm07sHPn9iued/To75hMeYwZM4JRo54mJeUA4Mq7PmXKNKpW\nvQG9Xo/JZGLixCnceutthe6VlLSFDh068emnH7Nnzy7WrSt5ERlv8Pke+dy5Jm65xVHezRBCiFKL\n7zGz2N7za4nnh8AVRWHcPVL97GJlVf2sW7ceALRr5zq+QYObLtueY8f+pm7degwdOow1a1ZeMsxf\n1nw6kE+dChs2aLjlFqlFLoSonBrfEE1MM9ew7dr9Uv0MfLv6WVpaKjVq1Czx+y8LPh3I4+Pho4+k\nNy6EqLwKgvjFX18LqX7mvepnP/+8hXbtOgK41w2UN58O5AAxMbbiDxJCjjbE3QAAB5FJREFUCOEm\n1c+8V/0sOXkPffs+CEDNmrX4888/WL58GbGxA0r8fjzNp6ufAVJlpwxINSPvk2fsffKMy4Y8Z++r\nVNXPhBBCCFE0CeRCCCFEBSaBXAghhKjAJJALIYQQFZgEciGEEKICk0AuhBDlLCkpjaSktPJuhqig\nfH4fuRBCVHavv74TgA4dYq75WlL9rPyqn82f/z5//nmUhIQ3Adi5czsLFnyARqMhPDyCF1+cVigR\njqdIIBdCCC+Jj9/GunV/XvF1k8lGdrYFs9mVHax27fmEhOjw87vyn+bevW8kPr5dkfeV6mdlX/0s\nNzeXvXv3UKNGTY4cOUzDhjfz9tuvMWfOAsLCwpg3bw7r16/mgQceKvH7LikZWhdCiHLi56chPPx8\nDy083K/IIH4tpPqZd6ufLV++lN69+zJw4BA++WQBAO++O4+wsDAA7HYbOp3ne+MgPXIhhPCa+Ph2\nxfaeX3ttp/trRYFx41p7pS1S/cy71c9WrlzOPfd0Q6PR0KZNOywWCxERkQBs2vQje/bs4oknni7B\nEys9CeRCCFGOGjcOJyamAQBr1/7htftI9TPvVj+7//5Y99d9+tzv/vqLLz5j48YfefPN9wqtH/Ak\nCeRCCFGOCoL4xV9fC6l+5hvVzxYu/IgjRw7zzjtz0el0Jbr+1ZBALoQQlYxUPyv/6mfnzmXwv/8t\n4Oabo3n++ZEoisLdd3elb98HSvy+S0qqnwmpZlQG5Bl7nzzjsiHP2fuk+pkQQghxHZFALoQQQlRg\nEsiFEEKICkwCuRBCCFGBSSAXQgghKrBiA7nT6WTq1KkMGDCAoUOHcvz48UKvr169mpiYGAYPHsyK\nFSsKvbZ3716GDBni/v63336jc+fODB06lKFDh7JhwwYPvQ0hhBDi+lTsPvLExEQsFgvLli1j7969\nJCQkMHfuXADOnTvH7NmzWbNmDUFBQTz66KO0b9+eGjVqsGDBAtasWeNOTg9w4MABhg0bxqOPPuq1\nNySEEEJcT4rtke/atYtOnToB0KJFi/zKNy7Hjx8nOjqa4OBgFEWhWbNmJCe70uzVrVuXOXPmFLpW\nSkoKGzduZPDgwUyePBmj0ejJ9yKEEEJcd4oN5Lm5uYVy2mo0GndKunr16nH06FEyMjLIy8tj27Zt\n5OXlAdC1a1fUanWha7Vo0YLx48ezePFiateuzbvvvuvJ9yKEEEJcd4odWg8KCsJgOJ90vqAuLUBI\nSAgTJkxg5MiRhIWF0bRp00L1YS/WpUsX94eCrl27MnPmzGIbWNoMN+LqyHP2PnnG3ifPuGzIc/Yt\nxfbIW7VqxaZNmwBITk6mUaNG7tfsdjspKSksWbKEt99+m7/++otWrVoVOv/CDLBxcXHs378fgG3b\nttG0aVOPvAkhhBDielVsj7xr164kJSUxYIArIXxCQgLr168nLy+P2FhX2bZ+/fqh1+sZNmyYu4h6\nAUU5n1x/2rRpTJ8+Ha1WS1RUFNOnT/fkexFCCCGuOz5fNEUIIYQQVyYJYYQQQogKTAK5EEIIUYFJ\nIBdCCCEqMAnkQgghRAVW7Kr18uB0OomPj+fw4cPodDpefvllateuXd7NqnTuv/9+goKCAKhVqxav\nvPJKObeoctm7dy9vvPEGixYt4tixY0yYMAGVSkXDhg2ZOnVqeTevUrjwGf/22288+eST1KtXD4CB\nAwfSo0eP8m1gBWaz2Zg0aRKpqalYrVaeeuopbrrpJvk99rDLPefq1auX6nfZJwN5UfndhWdYLBYA\nPv3003JuSeV0ca2BhIQExowZQ+vWrZk6dSqJiYl06dKlnFtZsV38jKWWg2etXbuW8PBwXnvtNbKz\ns+nTpw+NGzeW32MPu/A5Z2Vl0bdvX5555plS/S775NB6UfndhWccOnQIo9FIXFwcjz76KHv37i3v\nJlUqF9caSElJoXXr1gB07tyZbdu2lVfTKo3LPWOp5eA5PXr0YNSoUYAr+ZdarebgwYPye+xhFz5n\nh8OBRqMhJSWFn376qcS/yz4ZyIvK7y48w8/Pj7i4OD766CPi4+MZO3asPGMPurjWwIXpGgIDA8nJ\nySmPZlUqFz9jqeXgWf7+/gQEBJCbm8uoUaMYPXq0/B57wcXP+bnnnqN58+a88MILJf5d9slAXlR+\nd+EZ9erVIyYmxv11WFgYZ86cKedWVV4X/v4aDAZCQkLKsTWVU5cuXWjSpAngCvKHDh0q5xZVfCdP\nnuSRRx6hX79+3HffffJ77CUXP+fS/i77ZHQsKr+78Iwvv/ySV199FYB///0Xg8FAVFRUObeq8mrS\npAk7duwAYPPmzdx2223l3KLKR2o5eFZ6ejpxcXGMGzeOfv36ARAdHS2/xx52uedc2t9ln1zsdrn8\n7sKzHnzwQSZOnMigQYNQqVS88sorMurhRS+88AJTpkzBarXSoEEDunfvXt5NqnTi4+OZMWOG1HLw\nkHnz5pGdnc3cuXOZM2cOiqIwefJkZs6cKb/HHnS55zxx4kReeeWVEv8uS651IYQQogKTLpgQQghR\ngUkgF0IIISowCeRCCCFEBSaBXAghhKjAJJALIYQQFZgEciGEEKICk0AuhBBCVGD/D6nGPdRYS0mK\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18864d048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(0,25,1), test_lstm_lr_10_0_aucs[0,0:25], color= 'r', marker='*', linestyle='-', label =\"LSTM LR = 0.01\")\n",
    "plt.plot(np.arange(0,25,1), test_lstm_lr_10_1_aucs[0,0:25], color= 'g', marker='*', linestyle='-', label =\"LSTM LR = 0.01*1/t\")\n",
    "plt.plot(np.arange(0,25,1), test_lstm_lr_10_2_aucs[0,0:25], color= 'b', marker='*', linestyle='-', label =\"LSTM LR = 0.01*1/t^2\")\n",
    "plt.plot(np.arange(0,25,1), test_lstm_lr_100_0_aucs[0,0:25], color= 'darkred', marker='*', linestyle='-', label =\"LSTM LR = 0.005\")\n",
    "plt.plot(np.arange(0,25,1), test_lstm_lr_100_1_aucs[0,0:25], color= 'darkgreen', marker='*', linestyle='-', label =\"LSTM LR = 0.005*1/t\")\n",
    "plt.plot(np.arange(0,25,1), test_lstm_lr_100_2_aucs[0,0:25], color= 'darkblue', marker='*', linestyle='-', label =\"LSTM LR = 0.005*1/t^2\")\n",
    "\n",
    "plt.legend( loc=4)\n",
    "plt.Figure(figsize=(100,100),dpi = 130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0434    \n",
      "LSTM LR = 0.01):  0.935102273316 0.92817221455 0\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0428     \n",
      "LSTM LR = 0.01*t^(-1):  0.937098841829 0.93118413258 0\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0442     \n",
      "LSTM LR = 0.01*t^(-2):  0.935706683115 0.930836170745 0\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0458    \n",
      "LSTM LR = 0.005:  0.932633121923 0.930094332318 0\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0471     \n",
      "LSTM LR = 0.005*t^{-1}:  0.931101049431 0.925428132602 0\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0472     \n",
      "LSTM LR = 0.005*t^{-2}:  0.935003569297 0.931529393547 0\n",
      "current learning rate:  0.004999999888241291\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0610     \n",
      "LSTM LR = 0.001*t^{-1}:  0.867028791885 0.86481795249 0\n",
      "current learning rate:  0.0010000000474974513\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0325     \n",
      "LSTM LR = 0.01):  0.943363832986 0.936329286233 1\n",
      "current learning rate:  0.009499999694526196\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0283     \n",
      "LSTM LR = 0.01*t^(-1):  0.953542200344 0.949484764403 1\n",
      "current learning rate:  0.0035355337895452976\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0280     \n",
      "LSTM LR = 0.01*t^(-2):  0.951920119978 0.946112280487 1\n",
      "current learning rate:  0.0024999999441206455\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0311     \n",
      "LSTM LR = 0.005:  0.947899786728 0.942937860228 1\n",
      "current learning rate:  0.004749999847263098\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0294     \n",
      "LSTM LR = 0.005*t^{-1}:  0.945622947544 0.941860213873 1\n",
      "current learning rate:  0.0017677668947726488\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0293    \n",
      "LSTM LR = 0.005*t^{-2}:  0.947346113676 0.944046116422 1\n",
      "current learning rate:  0.0012499999720603228\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0492     \n",
      "LSTM LR = 0.001*t^{-1}:  0.883766988502 0.879050626871 1\n",
      "current learning rate:  0.0005000000237487257\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0290     \n",
      "LSTM LR = 0.01):  0.951498329232 0.940684435978 2\n",
      "current learning rate:  0.009025000035762787\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0254     \n",
      "LSTM LR = 0.01*t^(-1):  0.95743441777 0.950005581794 2\n",
      "current learning rate:  0.001924500917084515\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0248     \n",
      "LSTM LR = 0.01*t^(-2):  0.955539211972 0.949365476064 2\n",
      "current learning rate:  0.0011111111380159855\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0280     \n",
      "LSTM LR = 0.005:  0.949242704211 0.944544426579 2\n",
      "current learning rate:  0.004512500017881393\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0272     \n",
      "LSTM LR = 0.005*t^{-1}:  0.950756110455 0.946616892669 2\n",
      "current learning rate:  0.0009622504585422575\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0268     \n",
      "LSTM LR = 0.005*t^{-2}:  0.949073932523 0.94446565126 2\n",
      "current learning rate:  0.0005555555690079927\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0454     \n",
      "LSTM LR = 0.001*t^{-1}:  0.893493267079 0.886206576794 2\n",
      "current learning rate:  0.00033333332976326346\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0274     \n",
      "LSTM LR = 0.01):  0.958890828259 0.948355801555 3\n",
      "current learning rate:  0.008573750033974648\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0237     \n",
      "LSTM LR = 0.01*t^(-1):  0.959374932148 0.951052168167 3\n",
      "current learning rate:  0.0012499999720603228\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0240     \n",
      "LSTM LR = 0.01*t^(-2):  0.957030185484 0.951195764319 3\n",
      "current learning rate:  0.0006249999860301614\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0264     \n",
      "LSTM LR = 0.005:  0.954706376036 0.946258577507 3\n",
      "current learning rate:  0.004286875016987324\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0259     \n",
      "LSTM LR = 0.005*t^{-1}:  0.951682222243 0.947343426177 3\n",
      "current learning rate:  0.0006249999860301614\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0261     \n",
      "LSTM LR = 0.005*t^{-2}:  0.950586064809 0.946810905025 3\n",
      "current learning rate:  0.0003124999930150807\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0431     \n",
      "LSTM LR = 0.001*t^{-1}:  0.897354023291 0.888428941062 3\n",
      "current learning rate:  0.0002500000118743628\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0246     \n",
      "LSTM LR = 0.01):  0.959649386927 0.939312845148 4\n",
      "current learning rate:  0.008145062252879143\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0228    \n",
      "LSTM LR = 0.01*t^(-1):  0.960780162774 0.951862428585 4\n",
      "current learning rate:  0.0008944271830841899\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0230    \n",
      "LSTM LR = 0.01*t^(-2):  0.958076160066 0.951763396756 4\n",
      "current learning rate:  0.00039999998989515007\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0246    \n",
      "LSTM LR = 0.005:  0.960450263144 0.949921854884 4\n",
      "current learning rate:  0.004072531126439571\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0252    \n",
      "LSTM LR = 0.005*t^{-1}:  0.952957287636 0.948636691833 4\n",
      "current learning rate:  0.00044721359154209495\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0254    \n",
      "LSTM LR = 0.005*t^{-2}:  0.951032337697 0.946985561159 4\n",
      "current learning rate:  0.00019999999494757503\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0420    \n",
      "LSTM LR = 0.001*t^{-1}:  0.902014824878 0.892566220783 4\n",
      "current learning rate:  0.00019999999494757503\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0227    \n",
      "LSTM LR = 0.01):  0.969314903266 0.943963289801 5\n",
      "current learning rate:  0.0077378093264997005\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0218    \n",
      "LSTM LR = 0.01*t^(-1):  0.96206830008 0.952278137193 5\n",
      "current learning rate:  0.0006804137956351042\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0229    \n",
      "LSTM LR = 0.01*t^(-2):  0.958371829009 0.951655812178 5\n",
      "current learning rate:  0.00027777778450399637\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0238    \n",
      "LSTM LR = 0.005:  0.960467876993 0.948972049617 5\n",
      "current learning rate:  0.0038689046632498503\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0248    \n",
      "LSTM LR = 0.005*t^{-1}:  0.953373705604 0.948683957024 5\n",
      "current learning rate:  0.0003402068978175521\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0251    \n",
      "LSTM LR = 0.005*t^{-2}:  0.951545410274 0.947245294638 5\n",
      "current learning rate:  0.00013888889225199819\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0409    \n",
      "LSTM LR = 0.001*t^{-1}:  0.90539059097 0.896169178774 5\n",
      "current learning rate:  0.00016666666488163173\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0203    \n",
      "LSTM LR = 0.01):  0.971678703904 0.943487486878 6\n",
      "current learning rate:  0.007350918836891651\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0213    \n",
      "LSTM LR = 0.01*t^(-1):  0.963426449664 0.952745162295 6\n",
      "current learning rate:  0.0005399492220021784\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0226    \n",
      "LSTM LR = 0.01*t^(-2):  0.958646893072 0.951393377832 6\n",
      "current learning rate:  0.0002040816325461492\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0221    \n",
      "LSTM LR = 0.005:  0.9664030793 0.948606081995 6\n",
      "current learning rate:  0.0036754594184458256\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 13s - loss: 0.0242    \n",
      "LSTM LR = 0.005*t^{-1}:  0.954627723001 0.949825974068 6\n",
      "current learning rate:  0.0002699746110010892\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0252    \n",
      "LSTM LR = 0.005*t^{-2}:  0.95181715097 0.94733982502 6\n",
      "current learning rate:  0.0001020408162730746\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0401    \n",
      "LSTM LR = 0.001*t^{-1}:  0.909511345313 0.900356424555 6\n",
      "current learning rate:  0.0001428571413271129\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 13s - loss: 0.0183    \n",
      "LSTM LR = 0.01):  0.975249884014 0.944536323975 7\n",
      "current learning rate:  0.00698337284848094\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0210    \n",
      "LSTM LR = 0.01*t^(-1):  0.964099265447 0.952268008938 7\n",
      "current learning rate:  0.0004419417236931622\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 16s - loss: 0.0224    \n",
      "LSTM LR = 0.01*t^(-2):  0.95903661332 0.951717031854 7\n",
      "current learning rate:  0.00015624999650754035\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 16s - loss: 0.0204    \n",
      "LSTM LR = 0.005:  0.967684680649 0.948719518453 7\n",
      "current learning rate:  0.00349168642424047\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 15s - loss: 0.0238    \n",
      "LSTM LR = 0.005*t^{-1}:  0.955111051438 0.950064100602 7\n",
      "current learning rate:  0.0002209708618465811\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0250    \n",
      "LSTM LR = 0.005*t^{-2}:  0.952191916063 0.947702641629 7\n",
      "current learning rate:  7.812499825377017e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0387    \n",
      "LSTM LR = 0.001*t^{-1}:  0.913173585697 0.903801831909 7\n",
      "current learning rate:  0.0001250000059371814\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0167    \n",
      "LSTM LR = 0.01):  0.97981020912 0.944612398425 8\n",
      "current learning rate:  0.0066342041827738285\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0204    \n",
      "LSTM LR = 0.01*t^(-1):  0.964874330175 0.952517839234 8\n",
      "current learning rate:  0.000370370369637385\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 14s - loss: 0.0222    \n",
      "LSTM LR = 0.01*t^(-2):  0.959263599331 0.951708479105 8\n",
      "current learning rate:  0.00012345678987912834\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 13s - loss: 0.0190    \n",
      "LSTM LR = 0.005:  0.971881318553 0.949241236133 8\n",
      "current learning rate:  0.0033171020913869143\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0237    \n",
      "LSTM LR = 0.005*t^{-1}:  0.955577984595 0.950203645452 8\n",
      "current learning rate:  0.0001851851848186925\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0251    \n",
      "LSTM LR = 0.005*t^{-2}:  0.952280262254 0.947655376438 8\n",
      "current learning rate:  6.172839493956417e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0383    \n",
      "LSTM LR = 0.001*t^{-1}:  0.916184224461 0.906557842691 8\n",
      "current learning rate:  0.00011111111234640703\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0146    \n",
      "LSTM LR = 0.01):  0.982287558153 0.942147181104 9\n",
      "current learning rate:  0.006302494090050459\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0201    \n",
      "LSTM LR = 0.01*t^(-1):  0.965403410307 0.952760017069 9\n",
      "current learning rate:  0.0003162277571391314\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0217    \n",
      "LSTM LR = 0.01*t^(-2):  0.959422567084 0.951814713249 9\n",
      "current learning rate:  9.999999747378752e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 10s - loss: 0.0171    \n",
      "LSTM LR = 0.005:  0.975419375765 0.946293688792 9\n",
      "current learning rate:  0.0031512470450252295\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0237     \n",
      "LSTM LR = 0.005*t^{-1}:  0.955719172331 0.950151878814 9\n",
      "current learning rate:  0.0001581138785695657\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0247    \n",
      "LSTM LR = 0.005*t^{-2}:  0.952438509944 0.947806625049 9\n",
      "current learning rate:  4.999999873689376e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 10s - loss: 0.0367    \n",
      "LSTM LR = 0.001*t^{-1}:  0.919616044687 0.910417158075 9\n",
      "current learning rate:  9.999999747378752e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0136    \n",
      "LSTM LR = 0.01):  0.982599179261 0.940980631175 10\n",
      "current learning rate:  0.005987369455397129\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0194     \n",
      "LSTM LR = 0.01*t^(-1):  0.966112949303 0.952502534315 10\n",
      "current learning rate:  0.00027410121401771903\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0219     \n",
      "LSTM LR = 0.01*t^(-2):  0.959619753566 0.951912394644 10\n",
      "current learning rate:  8.264462667284533e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0159     \n",
      "LSTM LR = 0.005:  0.978421595332 0.945990741424 10\n",
      "current learning rate:  0.0029936847276985645\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0232     \n",
      "LSTM LR = 0.005*t^{-1}:  0.95576143449 0.949755301354 10\n",
      "current learning rate:  0.00013705060700885952\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 10s - loss: 0.0248    \n",
      "LSTM LR = 0.005*t^{-2}:  0.952312000415 0.947612162549 10\n",
      "current learning rate:  4.132231333642267e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0356     \n",
      "LSTM LR = 0.001*t^{-1}:  0.922653935067 0.914039922431 10\n",
      "current learning rate:  9.09090886125341e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0122     \n",
      "LSTM LR = 0.01):  0.984862614196 0.944192413442 11\n",
      "current learning rate:  0.005688000936061144\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0195     \n",
      "LSTM LR = 0.01*t^(-1):  0.966407510456 0.952866701358 11\n",
      "current learning rate:  0.0002405626146355644\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0217     \n",
      "LSTM LR = 0.01*t^(-2):  0.959703890157 0.951994771119 11\n",
      "current learning rate:  6.944444612599909e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0139     \n",
      "LSTM LR = 0.005:  0.9817401995 0.946411176552 11\n",
      "current learning rate:  0.002844000468030572\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 10s - loss: 0.0234    \n",
      "LSTM LR = 0.005*t^{-1}:  0.956253514461 0.950320232923 11\n",
      "current learning rate:  0.0001202813073177822\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0247     \n",
      "LSTM LR = 0.005*t^{-2}:  0.952573438671 0.947830032572 11\n",
      "current learning rate:  3.4722223062999547e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 10s - loss: 0.0351    \n",
      "LSTM LR = 0.001*t^{-1}:  0.927053298398 0.918394171887 11\n",
      "current learning rate:  8.333333244081587e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0115    \n",
      "LSTM LR = 0.01):  0.98605027502 0.942216728457 12\n",
      "current learning rate:  0.005403601098805666\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0192    \n",
      "LSTM LR = 0.01*t^(-1):  0.966731317246 0.952725355929 12\n",
      "current learning rate:  0.00021334622579161078\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0216    \n",
      "LSTM LR = 0.01*t^(-2):  0.959800101651 0.952073546438 12\n",
      "current learning rate:  5.917159796808846e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0128    \n",
      "LSTM LR = 0.005:  0.98455597814 0.94573911055 12\n",
      "current learning rate:  0.002701800549402833\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0232    \n",
      "LSTM LR = 0.005*t^{-1}:  0.956308848533 0.950012784109 12\n",
      "current learning rate:  0.00010667311289580539\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0247    \n",
      "LSTM LR = 0.005*t^{-2}:  0.952557597285 0.947790419841 12\n",
      "current learning rate:  2.958579898404423e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0342    \n",
      "LSTM LR = 0.001*t^{-1}:  0.928862096637 0.920495897381 12\n",
      "current learning rate:  7.69230755395256e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0103    \n",
      "LSTM LR = 0.01):  0.988635744281 0.939716174779 13\n",
      "current learning rate:  0.005133420694619417\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 13s - loss: 0.0191    \n",
      "LSTM LR = 0.01*t^(-1):  0.967161361021 0.952815835009 13\n",
      "current learning rate:  0.00019090088608209044\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0217    \n",
      "LSTM LR = 0.01*t^(-2):  0.959880084032 0.952032583272 13\n",
      "current learning rate:  5.10204081365373e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0116    \n",
      "LSTM LR = 0.005:  0.985617904887 0.942593499551 13\n",
      "current learning rate:  0.0025667103473097086\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0229    \n",
      "LSTM LR = 0.005*t^{-1}:  0.956280766076 0.950009182951 13\n",
      "current learning rate:  9.545044304104522e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0247    \n",
      "LSTM LR = 0.005*t^{-2}:  0.952655415073 0.947921411942 13\n",
      "current learning rate:  2.551020406826865e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0334    \n",
      "LSTM LR = 0.001*t^{-1}:  0.93134265826 0.923032912778 13\n",
      "current learning rate:  7.142857066355646e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0096    \n",
      "LSTM LR = 0.01):  0.988648926973 0.941385311239 14\n",
      "current learning rate:  0.004876749590039253\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0190    \n",
      "LSTM LR = 0.01*t^(-1):  0.967512087088 0.952390898435 14\n",
      "current learning rate:  0.00017213259707204998\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0218    \n",
      "LSTM LR = 0.01*t^(-2):  0.959965826918 0.952061392532 14\n",
      "current learning rate:  4.444444493856281e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0105    \n",
      "LSTM LR = 0.005:  0.98824635637 0.943275468736 14\n",
      "current learning rate:  0.0024383747950196266\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0232    \n",
      "LSTM LR = 0.005*t^{-1}:  0.95669242055 0.950381002454 14\n",
      "current learning rate:  8.606629853602499e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0247    \n",
      "LSTM LR = 0.005*t^{-2}:  0.952761098165 0.948009190154 14\n",
      "current learning rate:  2.2222222469281405e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0329    \n",
      "LSTM LR = 0.001*t^{-1}:  0.933438484686 0.925379066832 14\n",
      "current learning rate:  6.666666740784422e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 10s - loss: 0.0087    \n",
      "LSTM LR = 0.01):  0.992240711963 0.942502570326 15\n",
      "current learning rate:  0.004632912110537291\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0187     \n",
      "LSTM LR = 0.01*t^(-1):  0.967619653421 0.952640278586 15\n",
      "current learning rate:  0.00015624999650754035\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0216     \n",
      "LSTM LR = 0.01*t^(-2):  0.960046363194 0.952067694557 15\n",
      "current learning rate:  3.9062499126885086e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0097     \n",
      "LSTM LR = 0.005:  0.990110100955 0.93995790247 15\n",
      "current learning rate:  0.0023164560552686453\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0232     \n",
      "LSTM LR = 0.005*t^{-1}:  0.956802756357 0.950406660701 15\n",
      "current learning rate:  7.812499825377017e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0245     \n",
      "LSTM LR = 0.005*t^{-2}:  0.95278724199 0.948051503753 15\n",
      "current learning rate:  1.9531249563442543e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0317     \n",
      "LSTM LR = 0.001*t^{-1}:  0.935013207063 0.926994636076 15\n",
      "current learning rate:  6.25000029685907e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0083     \n",
      "LSTM LR = 0.01):  0.991707533011 0.941461835834 16\n",
      "current learning rate:  0.004401266574859619\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0185     \n",
      "LSTM LR = 0.01*t^(-1):  0.968020894677 0.952687543777 16\n",
      "current learning rate:  0.00014266801008488983\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0214     \n",
      "LSTM LR = 0.01*t^(-2):  0.96014035911 0.952134766114 16\n",
      "current learning rate:  3.4602075174916536e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0090     \n",
      "LSTM LR = 0.005:  0.991286351549 0.942253190175 16\n",
      "current learning rate:  0.0022006332874298096\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0226     \n",
      "LSTM LR = 0.005*t^{-1}:  0.956789684444 0.950248209775 16\n",
      "current learning rate:  7.133400504244491e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0245     \n",
      "LSTM LR = 0.005*t^{-2}:  0.952761430502 0.947996135958 16\n",
      "current learning rate:  1.7301037587458268e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0316     \n",
      "LSTM LR = 0.001*t^{-1}:  0.935833303423 0.927800395047 16\n",
      "current learning rate:  5.8823530707741156e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0078     \n",
      "LSTM LR = 0.01):  0.992338308193 0.941308786644 17\n",
      "current learning rate:  0.004181203432381153\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0185     \n",
      "LSTM LR = 0.01*t^(-1):  0.968233700986 0.952537645599 17\n",
      "current learning rate:  0.00013094570022076368\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0215     \n",
      "LSTM LR = 0.01*t^(-2):  0.960161240937 0.952110008157 17\n",
      "current learning rate:  3.0864197469782084e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0084     \n",
      "LSTM LR = 0.005:  0.991721491155 0.941615785313 17\n",
      "current learning rate:  0.0020906017161905766\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0227     \n",
      "LSTM LR = 0.005*t^{-1}:  0.956966930719 0.950396757518 17\n",
      "current learning rate:  6.547285011038184e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0247     \n",
      "LSTM LR = 0.005*t^{-2}:  0.952811391795 0.948018193047 17\n",
      "current learning rate:  1.5432098734891042e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0313     \n",
      "LSTM LR = 0.001*t^{-1}:  0.936379997403 0.928282499995 17\n",
      "current learning rate:  5.555555617320351e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0069    \n",
      "LSTM LR = 0.01):  0.992533389875 0.938926170871 18\n",
      "current learning rate:  0.003972143400460482\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0185     \n",
      "LSTM LR = 0.01*t^(-1):  0.968420031133 0.952630825547 18\n",
      "current learning rate:  0.00012074512051185593\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0214     \n",
      "LSTM LR = 0.01*t^(-2):  0.96023490892 0.952144669297 18\n",
      "current learning rate:  2.770083119685296e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 10s - loss: 0.0076    \n",
      "LSTM LR = 0.005:  0.991949252619 0.94144698106 18\n",
      "current learning rate:  0.001986071700230241\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 10s - loss: 0.0226    \n",
      "LSTM LR = 0.005*t^{-1}:  0.957082916251 0.95039315636 18\n",
      "current learning rate:  6.0372560255927965e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 10s - loss: 0.0244    \n",
      "LSTM LR = 0.005*t^{-2}:  0.952847062608 0.948052404043 18\n",
      "current learning rate:  1.385041559842648e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0310     \n",
      "LSTM LR = 0.001*t^{-1}:  0.937364711241 0.929250761195 18\n",
      "current learning rate:  5.263157800072804e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0072     \n",
      "LSTM LR = 0.01):  0.992743759048 0.941497847408 19\n",
      "current learning rate:  0.003773536067456007\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0184     \n",
      "LSTM LR = 0.01*t^(-1):  0.96865676569 0.952504785038 19\n",
      "current learning rate:  0.00011180339788552374\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0215     \n",
      "LSTM LR = 0.01*t^(-2):  0.960277780363 0.952156373058 19\n",
      "current learning rate:  2.499999936844688e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0072    \n",
      "LSTM LR = 0.005:  0.993209473636 0.938495382416 19\n",
      "current learning rate:  0.0018867680337280035\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0228    \n",
      "LSTM LR = 0.005*t^{-1}:  0.956968980129 0.950216699647 19\n",
      "current learning rate:  5.590169894276187e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0244    \n",
      "LSTM LR = 0.005*t^{-2}:  0.952894697545 0.948135230663 19\n",
      "current learning rate:  1.249999968422344e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 11s - loss: 0.0311    \n",
      "LSTM LR = 0.001*t^{-1}:  0.938082115541 0.929979995571 19\n",
      "current learning rate:  4.999999873689376e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0068     \n",
      "LSTM LR = 0.01):  0.99306213767 0.940561096336 20\n",
      "current learning rate:  0.0035848591942340136\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 10s - loss: 0.0183    \n",
      "LSTM LR = 0.01*t^(-1):  0.968902805676 0.952435912902 20\n",
      "current learning rate:  0.0001039132839650847\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0214     \n",
      "LSTM LR = 0.01*t^(-2):  0.960320651805 0.952187207969 20\n",
      "current learning rate:  2.2675736545352265e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0068     \n",
      "LSTM LR = 0.005:  0.993647493494 0.940090695149 20\n",
      "current learning rate:  0.0017924295971170068\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0225     \n",
      "LSTM LR = 0.005*t^{-1}:  0.957191867321 0.950508393398 20\n",
      "current learning rate:  5.195664198254235e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0243     \n",
      "LSTM LR = 0.005*t^{-2}:  0.952900125712 0.948086164893 20\n",
      "current learning rate:  1.1337868272676133e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0307     \n",
      "LSTM LR = 0.001*t^{-1}:  0.938415892433 0.930257284691 20\n",
      "current learning rate:  4.761904710903764e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0062     \n",
      "LSTM LR = 0.01):  0.994214238459 0.940697490173 21\n",
      "current learning rate:  0.0034056161530315876\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0182     \n",
      "LSTM LR = 0.01*t^(-1):  0.96902056367 0.952322926589 21\n",
      "current learning rate:  9.690941806184128e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0214     \n",
      "LSTM LR = 0.01*t^(-2):  0.960333059045 0.952184732173 21\n",
      "current learning rate:  2.0661156668211333e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0065     \n",
      "LSTM LR = 0.005:  0.994244037989 0.939868323679 21\n",
      "current learning rate:  0.0017028080765157938\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0227     \n",
      "LSTM LR = 0.005*t^{-1}:  0.957216404852 0.950459777773 21\n",
      "current learning rate:  4.845470903092064e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0243     \n",
      "LSTM LR = 0.005*t^{-2}:  0.952939452229 0.948143783412 21\n",
      "current learning rate:  1.0330578334105667e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0304     \n",
      "LSTM LR = 0.001*t^{-1}:  0.938672456416 0.93060749725 21\n",
      "current learning rate:  4.545454430626705e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0057     \n",
      "LSTM LR = 0.01):  0.993878245989 0.940216285514 22\n",
      "current learning rate:  0.00323533546179533\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0181     \n",
      "LSTM LR = 0.01*t^(-1):  0.969214980678 0.952350835559 22\n",
      "current learning rate:  9.06584391486831e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0212     \n",
      "LSTM LR = 0.01*t^(-2):  0.960367511289 0.95218248145 22\n",
      "current learning rate:  1.8903590898844413e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0060     \n",
      "LSTM LR = 0.005:  0.995061032539 0.938275711814 22\n",
      "current learning rate:  0.001617667730897665\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0225     \n",
      "LSTM LR = 0.005*t^{-1}:  0.957296165676 0.95049804007 22\n",
      "current learning rate:  4.532921957434155e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0243     \n",
      "LSTM LR = 0.005*t^{-2}:  0.952950751679 0.948171242237 22\n",
      "current learning rate:  9.451795449422207e-06\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0297     \n",
      "LSTM LR = 0.001*t^{-1}:  0.939038414585 0.931078348581 22\n",
      "current learning rate:  4.347825961303897e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0054     \n",
      "LSTM LR = 0.01):  0.994901510892 0.93919265652 23\n",
      "current learning rate:  0.0030735686887055635\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0178     \n",
      "LSTM LR = 0.01*t^(-1):  0.969344813575 0.952239199679 23\n",
      "current learning rate:  8.505172445438802e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0214     \n",
      "LSTM LR = 0.01*t^(-2):  0.960399858735 0.952193284922 23\n",
      "current learning rate:  1.7361111531499773e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0058     \n",
      "LSTM LR = 0.005:  0.995000214911 0.937630204348 23\n",
      "current learning rate:  0.0015367843443527818\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0228     \n",
      "LSTM LR = 0.005*t^{-1}:  0.957437408801 0.95053270121 23\n",
      "current learning rate:  4.252586222719401e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0244     \n",
      "LSTM LR = 0.005*t^{-2}:  0.95296194035 0.948176193829 23\n",
      "current learning rate:  8.680555765749887e-06\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0299     \n",
      "LSTM LR = 0.001*t^{-1}:  0.939600673004 0.931760317766 23\n",
      "current learning rate:  4.166666622040793e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0054     \n",
      "LSTM LR = 0.01):  0.994330888664 0.939516310542 24\n",
      "current learning rate:  0.002919890219345689\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0182     \n",
      "LSTM LR = 0.01*t^(-1):  0.969563048051 0.952371542214 24\n",
      "current learning rate:  7.999999797903001e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0214     \n",
      "LSTM LR = 0.01*t^(-2):  0.960424340876 0.952213541432 24\n",
      "current learning rate:  1.5999999959603883e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 9s - loss: 0.0056     \n",
      "LSTM LR = 0.005:  0.995630657756 0.938724956201 24\n",
      "current learning rate:  0.0014599451096728444\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 8s - loss: 0.0227     \n",
      "LSTM LR = 0.005*t^{-1}:  0.957431205182 0.950537652802 24\n",
      "current learning rate:  3.9999998989515007e-05\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 12s - loss: 0.0245    \n",
      "LSTM LR = 0.005*t^{-2}:  0.95296509755 0.94815998862 24\n",
      "current learning rate:  7.999999979801942e-06\n",
      "Epoch 1/1\n",
      "6376/6376 [==============================] - 10s - loss: 0.0301    \n",
      "LSTM LR = 0.001*t^{-1}:  0.939885153276 0.932038507176 24\n",
      "current learning rate:  3.9999998989515007e-05\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 8s - loss: 0.0439     \n",
      "LSTM LR = 0.01):  0.936048186225 0.932048962261 0\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "6377/6377 [==============================] - 9s - loss: 0.0432     \n",
      "LSTM LR = 0.01*t^(-1):  0.937369244015 0.934923444378 0\n",
      "current learning rate:  0.009999999776482582\n",
      "Epoch 1/1\n",
      "5472/6377 [========================>.....] - ETA: 1s - loss: 0.0462"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6977819d52ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0madam_lr_10_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mlstm_lr_10_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/giancarlokerg/anaconda/lib/python3.5/site-packages/Keras-1.0.5-py3.5.egg/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1080\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/giancarlokerg/anaconda/lib/python3.5/site-packages/Keras-1.0.5-py3.5.egg/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[1;32m    799\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/giancarlokerg/anaconda/lib/python3.5/site-packages/Keras-1.0.5-py3.5.egg/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/giancarlokerg/anaconda/lib/python3.5/site-packages/Theano-0.8.2-py3.5.egg/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/giancarlokerg/anaconda/lib/python3.5/site-packages/Theano-0.8.2-py3.5.egg/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    949\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[1;32m    950\u001b[0m                  allow_gc=allow_gc):\n\u001b[0;32m--> 951\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/giancarlokerg/anaconda/lib/python3.5/site-packages/Theano-0.8.2-py3.5.egg/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(node, args, outs)\u001b[0m\n\u001b[1;32m    938\u001b[0m                         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                         \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m                         self, node)\n\u001b[0m\u001b[1;32m    941\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/Users/giancarlokerg/.theano/compiledir_Darwin-15.2.0-x86_64-i386-64bit-i386-3.5.1-64/scan_perform/mod.cpp:6635)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/giancarlokerg/anaconda/lib/python3.5/site-packages/Theano-0.8.2-py3.5.egg/theano/tensor/type.py\u001b[0m in \u001b[0;36mvalue_zeros\u001b[0;34m(self, shape)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mvalue_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m         \"\"\"\n\u001b[1;32m    631\u001b[0m         \u001b[0mCreate\u001b[0m \u001b[0man\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mof\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "folds = 3\n",
    "batch_size_nn = 16\n",
    "batch_size_lstm = 16\n",
    "hidden = 50\n",
    "dropout_probability = 0.25\n",
    "\n",
    "n_epochs = 25\n",
    "epoch = 0\n",
    "\n",
    "\n",
    "#-----------------------\n",
    "\n",
    "train_lstm_lr_10_0_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_10_0_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_10_1_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_10_1_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_10_2_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_10_2_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "\n",
    "\n",
    "#---------------------------\n",
    "\n",
    "train_lstm_lr_100_0_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_100_0_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_100_1_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_100_1_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "train_lstm_lr_100_2_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_100_2_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "train_lstm_lr_1000_1_aucs = np.zeros((folds,n_epochs))\n",
    "test_lstm_lr_1000_1_aucs = np.zeros((folds,n_epochs))\n",
    "\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(KFold(len(df_h),folds, shuffle=True)):\n",
    " \n",
    "    \n",
    "    \n",
    "    \n",
    " \n",
    "    \n",
    "    \n",
    "    #-------------------------------------------------------------------------\n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_10_0 = Model(input = sequence, output = output)\n",
    "    adam_lr_10_0 = Adam(lr = 0.01)\n",
    "    lstm_lr_10_0.compile(optimizer = adam_lr_10_0 , loss='mean_squared_error')\n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_10_1 = Model(input = sequence, output = output)\n",
    "    adam_lr_10_1 = Adam(lr = 0.01)\n",
    "    lstm_lr_10_1.compile(optimizer = adam_lr_10_1 , loss='mean_squared_error')\n",
    "    \n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_10_2 = Model(input = sequence, output = output)\n",
    "    adam_lr_10_2 = Adam(lr = 0.01)\n",
    "    lstm_lr_10_2.compile(optimizer = adam_lr_10_2 , loss='mean_squared_error')\n",
    "    \n",
    "   \n",
    "    \n",
    "    #---------------------------------------------------------------------------------\n",
    "\n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_100_0 = Model(input = sequence, output = output)\n",
    "    adam_lr_100_0 = Adam(lr = 0.005)\n",
    "    lstm_lr_100_0.compile(optimizer = adam_lr_100_0 , loss='mean_squared_error')\n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_100_1 = Model(input = sequence, output = output)\n",
    "    adam_lr_100_1 = Adam(lr = 0.005)\n",
    "    lstm_lr_100_1.compile(optimizer = adam_lr_100_1 , loss='mean_squared_error')\n",
    "    \n",
    "    \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_100_2 = Model(input = sequence, output = output)\n",
    "    adam_lr_100_2 = Adam(lr = 0.005)\n",
    "    lstm_lr_100_2.compile(optimizer = adam_lr_100_2 , loss='mean_squared_error')\n",
    "    \n",
    "   \n",
    "    # \n",
    "    sequence = Input( shape= (26, ),dtype='int32')\n",
    "    embedded = Embedding(input_dim = 21, input_length = 26, output_dim= 32, mask_zero = True)(sequence)\n",
    "    forwards = LSTM(hidden)(embedded)\n",
    "    backwards = LSTM(hidden, go_backwards=True)(embedded)\n",
    "\n",
    "    merged = merge([forwards, backwards], mode = 'concat', concat_axis=-1)\n",
    "    after_dp = Dropout(dropout_probability)(merged)\n",
    "    output = Dense(1, activation = 'sigmoid')(after_dp)\n",
    "    lstm_lr_1000_1 = Model(input = sequence, output = output)\n",
    "    adam_lr_1000_1 = Adam(lr = 0.001)\n",
    "    lstm_lr_1000_1.compile(optimizer = adam_lr_1000_1 , loss='mean_squared_error')\n",
    "    \n",
    "   \n",
    "\n",
    "    \n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        \n",
    "\n",
    "       \n",
    "        \n",
    "\n",
    "    \n",
    "        #----------------------------------------\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "        adam_lr_10_0.lr.set_value(0.01*(0.95)**(epoch))\n",
    "        lstm_lr_10_0.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_10_0_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_10_0.predict(X[train_idx]))\n",
    "        test_lstm_lr_10_0_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_10_0.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_10_0_aucs[i][epoch]=train_lstm_lr_10_0_auc\n",
    "        test_lstm_lr_10_0_aucs[i][epoch]=test_lstm_lr_10_0_auc\n",
    "        print(\"LSTM LR = 0.01): \", train_lstm_lr_10_0_auc, test_lstm_lr_10_0_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_10_0.lr.get_value() )   \n",
    "        \n",
    "        \n",
    "        \n",
    "        adam_lr_10_1.lr.set_value(0.01*(epoch+1)**(-1.5))\n",
    "        lstm_lr_10_1.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_10_1_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_10_1.predict(X[train_idx]))\n",
    "        test_lstm_lr_10_1_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_10_1.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_10_1_aucs[i][epoch]=train_lstm_lr_10_1_auc\n",
    "        test_lstm_lr_10_1_aucs[i][epoch]=test_lstm_lr_10_1_auc\n",
    "        print(\"LSTM LR = 0.01*t^(-1): \", train_lstm_lr_10_1_auc, test_lstm_lr_10_1_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_10_1.lr.get_value() )\n",
    "        \n",
    "        \n",
    "        \n",
    "        adam_lr_10_2.lr.set_value(0.01*(epoch+1)**(-2))\n",
    "        lstm_lr_10_2.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_10_2_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_10_2.predict(X[train_idx]))\n",
    "        test_lstm_lr_10_2_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_10_2.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_10_2_aucs[i][epoch]=train_lstm_lr_10_2_auc\n",
    "        test_lstm_lr_10_2_aucs[i][epoch]=test_lstm_lr_10_2_auc\n",
    "        print(\"LSTM LR = 0.01*t^(-2): \", train_lstm_lr_10_2_auc, test_lstm_lr_10_2_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_10_2.lr.get_value() )\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    " \n",
    "\n",
    "        \n",
    "        #-----------------------------------------------------------------\n",
    "        \n",
    "        \n",
    "        adam_lr_100_0.lr.set_value(0.005*(0.95)**(epoch))\n",
    "        lstm_lr_100_0.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_100_0_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_100_0.predict(X[train_idx]))\n",
    "        test_lstm_lr_100_0_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_100_0.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_100_0_aucs[i][epoch]=train_lstm_lr_100_0_auc\n",
    "        test_lstm_lr_100_0_aucs[i][epoch]=test_lstm_lr_100_0_auc\n",
    "        print(\"LSTM LR = 0.005: \", train_lstm_lr_100_0_auc, test_lstm_lr_100_0_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_100_0.lr.get_value() )\n",
    "        \n",
    "        adam_lr_100_1.lr.set_value(0.005*(epoch+1)**(-1.5))\n",
    "        lstm_lr_100_1.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_100_1_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_100_1.predict(X[train_idx]))\n",
    "        test_lstm_lr_100_1_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_100_1.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_100_1_aucs[i][epoch]=train_lstm_lr_100_1_auc\n",
    "        test_lstm_lr_100_1_aucs[i][epoch]=test_lstm_lr_100_1_auc\n",
    "        print(\"LSTM LR = 0.005*t^{-1}: \", train_lstm_lr_100_1_auc, test_lstm_lr_100_1_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_100_1.lr.get_value() )\n",
    "        \n",
    "        adam_lr_100_2.lr.set_value(0.005*(epoch+1)**(-2))\n",
    "        lstm_lr_100_2.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_100_2_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_100_2.predict(X[train_idx]))\n",
    "        test_lstm_lr_100_2_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_100_2.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_100_2_aucs[i][epoch]=train_lstm_lr_100_2_auc\n",
    "        test_lstm_lr_100_2_aucs[i][epoch]=test_lstm_lr_100_2_auc\n",
    "        print(\"LSTM LR = 0.005*t^{-2}: \", train_lstm_lr_100_2_auc, test_lstm_lr_100_2_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_100_2.lr.get_value() )\n",
    "        \n",
    "        \n",
    "        \n",
    "        #-------------------------------------------------------------------\n",
    "        \n",
    "        \n",
    "\n",
    "        adam_lr_1000_1.lr.set_value(0.001*(1+epoch)**(-1))\n",
    "        lstm_lr_1000_1.fit(X[train_idx],y[train_idx], batch_size = batch_size_lstm, nb_epoch=1)\n",
    "    \n",
    "\n",
    "        train_lstm_lr_1000_1_auc = roc_auc_score(measured_affinity_less_than(y[train_idx],500),lstm_lr_1000_1.predict(X[train_idx]))\n",
    "        test_lstm_lr_1000_1_auc = roc_auc_score(measured_affinity_less_than(y[test_idx],500),lstm_lr_1000_1.predict(X[test_idx]))\n",
    "        \n",
    "        train_lstm_lr_1000_1_aucs[i][epoch]=train_lstm_lr_1000_1_auc\n",
    "        test_lstm_lr_1000_1_aucs[i][epoch]=test_lstm_lr_1000_1_auc\n",
    "        print(\"LSTM LR = 0.001*t^{-1}: \", train_lstm_lr_1000_1_auc, test_lstm_lr_1000_1_auc, epoch)\n",
    "        print(\"current learning rate: \", adam_lr_1000_1.lr.get_value() )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17a076588>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFVCAYAAADCLbfjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbSIiIoXg0iYiIlIILm0iIiKF+A9IHfiw/+PW0QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x179fe5390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(0,25,1), test_lstm_lr_10_0_aucs[0,0:25], color= 'r', marker='*', linestyle='-', label =\"LSTM LR = 0.01*0.95^t\")\n",
    "plt.plot(np.arange(0,25,1), test_lstm_lr_10_1_aucs[0,0:25], color= 'g', marker='*', linestyle='-', label =\"LSTM LR = 0.01*1/t^1.5\")\n",
    "plt.plot(np.arange(0,25,1), test_lstm_lr_10_2_aucs[0,0:25], color= 'b', marker='*', linestyle='-', label =\"LSTM LR = 0.01*1/t^2\")\n",
    "plt.plot(np.arange(0,25,1), test_lstm_lr_100_0_aucs[0,0:25], color= 'darkred', marker='*', linestyle='-', label =\"LSTM LR = 0.005*0.95^t\")\n",
    "plt.plot(np.arange(0,25,1), test_lstm_lr_100_1_aucs[0,0:25], color= 'darkgreen', marker='*', linestyle='-', label =\"LSTM LR = 0.005*1/t^1.5\")\n",
    "plt.plot(np.arange(0,25,1), test_lstm_lr_100_2_aucs[0,0:25], color= 'darkblue', marker='*', linestyle='-', label =\"LSTM LR = 0.005*1/t^2\")\n",
    "plt.plot(np.arange(0,25,1), test_lstm_lr_1000_1_aucs[0,0:25], color= 'orange', marker='*', linestyle='-', label =\"LSTM LR = 0.001*1/t\")\n",
    "\n",
    "plt.legend( loc=4)\n",
    "plt.Figure(figsize=(100,100),dpi = 130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
